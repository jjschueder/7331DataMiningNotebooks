{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jjschueder/7331DataMiningNotebooks/blob/master/Mini-Project%20SVMLR%20Classification/(V2)Mini-Project%20SVMLR%20Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qhqdMtT3nSiG"
   },
   "source": [
    "# Mini-Project: SVM&LR Classification\n",
    "You are to perform predictive analysis (classification) upon a data set: model the dataset using\n",
    "methods we have discussed in class: logistic regression & support vector machines and making\n",
    "conclusions from the analysis. Follow the CRISP-DM framework in your analysis (you are not\n",
    "performing all of the CRISP-DM outline, only the portions relevant to the grading rubric outlined\n",
    "below). This report is worth 10% of the final grade. You may complete this assignment in teams\n",
    "of as many as three people.\n",
    "Write a report covering all the steps of the project. The format of the document can be PDF,\n",
    "*.ipynb, or HTML. You can write the report in whatever format you like, but it is easiest to turn in\n",
    "the rendered Jupyter notebook. The results should be reproducible using your report. Please\n",
    "carefully describe every assumption and every step in your report.\n",
    "A note on grading: A common mistake I see in this lab is not investigating different input\n",
    "parameters for each model. Try a number of parameter combinations and discuss how the model changed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jmTlKM_UnSiP"
   },
   "source": [
    "## SVM and Logistic Regression Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qN07sRSnnSiU"
   },
   "source": [
    "### Create Models [50 points] \n",
    "Create a logistic regression model and a support vector machine model for the\n",
    "classification task involved with your dataset. Assess how well each model performs (use\n",
    "80/20 training/testing split for your data). Adjust parameters of the models to make them\n",
    "more accurate. If your dataset size requires the use of stochastic gradient descent, then\n",
    "linear kernel only is fine to use. That is, the SGDClassifier is fine to use for optimizing\n",
    "logistic regression and linear support vector machines. For many problems, SGD will be\n",
    "required in order to train the SVM model in a reasonable timeframe.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6I6a7elv4W0h"
   },
   "source": [
    "### Load and Clean Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lPXTcIccnSiW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedShuffleSplit \n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mo0kRfD4nSik"
   },
   "outputs": [],
   "source": [
    "#read data from github repository\n",
    "#this data was produced from the Iowa Alcohol Dataset 2019 year data\n",
    "#It was cleansed and transformed in this notebook and exported as a csv to github for use here.\n",
    "#source python notebook: https://github.com/jjschueder/7331DataMiningNotebooks/blob/master/lab1/msds7331_clark_schueder_vela_washburn.ipynb\n",
    "# read csv from github directly\n",
    "url_dataset = 'https://github.com/jjschueder/7331DataMiningNotebooks/blob/master/Live%20Assignments/df1hotmerge2.csv?raw=true'\n",
    "#data = pd.read_csv(url_dataset)\n",
    "data = pd.read_csv(url_dataset, nrows=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "DQKPLfW1nSiv",
    "outputId": "35f2d8b4-4a32-4d02-c73c-9b3f986a852f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 68)\n",
      "['Unnamed: 0', 'pack', 'bottle_volume_ml', 'state_bottle_cost', 'state_bottle_retail', 'bottles_sold', 'sale_dollars', 'volume_sold_liters', 'volume_sold_gallons', 'counter', 'liquor_category', 'store_parent', 'month', 'year', 'monthyear', 'liquor_category_AMARETTO', 'liquor_category_BRANDY', 'liquor_category_GIN', 'liquor_category_LIQUEUR', 'liquor_category_Other', 'liquor_category_RUM', 'liquor_category_SCHNAPPS', 'liquor_category_TEQUILA', 'liquor_category_VODKA', 'liquor_category_WHISKY', 'store_parent_CVS', 'store_parent_Caseys', 'store_parent_Hy-Vee', 'store_parent_Kum&Go', 'store_parent_Other', 'store_parent_QuikTrip', 'store_parent_SamsClub', 'store_parent_SmokingJoes', 'store_parent_Target', 'store_parent_Wal-Mart', 'store_parent_Walgreens', 'month_Apr', 'month_Aug', 'month_Dec', 'month_Feb', 'month_Jan', 'month_Jul', 'month_Jun', 'month_Mar', 'month_May', 'month_Nov', 'month_Oct', 'month_Sep', 'year_2019', 'monthyear_Apr-2019', 'monthyear_Aug-2019', 'monthyear_Dec-2019', 'monthyear_Feb-2019', 'monthyear_Jan-2019', 'monthyear_Jul-2019', 'monthyear_Jun-2019', 'monthyear_Mar-2019', 'monthyear_May-2019', 'monthyear_Nov-2019', 'monthyear_Oct-2019', 'monthyear_Sep-2019', 'sale_dollars_trans', 'cost_per_liter', 'cost_per_liter_trans', 'state_bottle_cost_trans', 'bottles_sold_trans', 'volume_sold_liters_trans', 'grossmargin']\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(list(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "tzx9_JhrnSi7",
    "outputId": "c430fefe-7615-4b2d-b104-64b995bb797d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of not whiskey is 77.35499999999999\n",
      "percentage of whiskey 22.645\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(columns = ['Unnamed: 0'])\n",
    "count_not_whiskey = len(data[data['liquor_category_WHISKY']==0])\n",
    "count_whiskey = len(data[data['liquor_category_WHISKY']==1])\n",
    "pct_of_no_whiskey = count_not_whiskey/(count_not_whiskey+count_whiskey)\n",
    "print(\"percentage of not whiskey is\", pct_of_no_whiskey*100)\n",
    "pct_of_whiskey = count_whiskey/(count_not_whiskey+count_whiskey)\n",
    "print(\"percentage of whiskey\", pct_of_whiskey*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "jSmKpN1snSjB",
    "outputId": "a45a584c-2012-41bc-dc0b-01ab5b23e747"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sale_dollars_trans', 'cost_per_liter_trans',\n",
       "       'state_bottle_cost_trans', 'bottles_sold_trans',\n",
       "       'volume_sold_liters_trans', 'pack', 'bottle_volume_ml',\n",
       "       'liquor_category_WHISKY'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_vars=['counter', 'liquor_category', 'store_parent',\n",
    " 'month', 'year', 'monthyear', 'liquor_category_AMARETTO', 'liquor_category_BRANDY', 'liquor_category_GIN', \n",
    " 'liquor_category_LIQUEUR', 'liquor_category_Other', 'liquor_category_RUM', 'liquor_category_SCHNAPPS', \n",
    " 'liquor_category_TEQUILA', 'liquor_category_VODKA', 'month_Apr', 'month_Aug', 'month_Dec', 'month_Feb',\n",
    " 'month_Jan', 'month_Jul', 'month_Jun', 'month_Mar', 'month_May', 'month_Nov', 'month_Oct', 'month_Sep', \n",
    " 'store_parent_CVS', 'store_parent_Caseys', 'store_parent_Hy-Vee', 'store_parent_Kum&Go', \n",
    " 'store_parent_Other', 'store_parent_QuikTrip', 'store_parent_SamsClub', 'store_parent_SmokingJoes', \n",
    " 'store_parent_Target', 'store_parent_Wal-Mart', 'store_parent_Walgreens']\n",
    "data_vars=data.columns.values.tolist()\n",
    "to_keep=[i for i in data_vars if i not in cat_vars]\n",
    "to_keep=['sale_dollars_trans', 'cost_per_liter_trans',\n",
    "      'state_bottle_cost_trans', 'bottles_sold_trans',\n",
    "       'volume_sold_liters_trans','pack', 'bottle_volume_ml',\n",
    "       'liquor_category_WHISKY']\n",
    "data_final=data[to_keep]\n",
    "data_final.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sale_dollars_trans          float64\n",
       "cost_per_liter_trans        float64\n",
       "state_bottle_cost_trans     float64\n",
       "bottles_sold_trans          float64\n",
       "volume_sold_liters_trans    float64\n",
       "pack                          int64\n",
       "bottle_volume_ml              int64\n",
       "liquor_category_WHISKY        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 8)\n",
      "['sale_dollars_trans', 'cost_per_liter_trans', 'state_bottle_cost_trans', 'bottles_sold_trans', 'volume_sold_liters_trans', 'pack', 'bottle_volume_ml', 'liquor_category_WHISKY']\n"
     ]
    }
   ],
   "source": [
    "#getting smaller sample size for svm\n",
    "chosen_idx = np.random.choice(100000, replace=False, size=30000)\n",
    "df_trimmed = data_final.copy()\n",
    "df_trimmed = df_trimmed.iloc[chosen_idx]\n",
    "print(df_trimmed.shape)\n",
    "print(list(df_trimmed.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for logistic regression\n",
    "X = data_final.loc[:, data_final.columns != 'liquor_category_WHISKY']\n",
    "y = data_final.loc[:, data_final.columns == 'liquor_category_WHISKY']\n",
    "\n",
    "#for svm\n",
    "XSVM = df_trimmed.loc[:, df_trimmed.columns != 'liquor_category_WHISKY']\n",
    "ySVM = df_trimmed.loc[:, df_trimmed.columns == 'liquor_category_WHISKY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sale_dollars_trans</th>\n",
       "      <th>cost_per_liter_trans</th>\n",
       "      <th>state_bottle_cost_trans</th>\n",
       "      <th>bottles_sold_trans</th>\n",
       "      <th>volume_sold_liters_trans</th>\n",
       "      <th>pack</th>\n",
       "      <th>bottle_volume_ml</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.750136</td>\n",
       "      <td>2.735233</td>\n",
       "      <td>1.348073</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>2.014903</td>\n",
       "      <td>20</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.574900</td>\n",
       "      <td>5.570632</td>\n",
       "      <td>2.169054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.995732</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.000585</td>\n",
       "      <td>3.208825</td>\n",
       "      <td>2.803360</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>12</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.636261</td>\n",
       "      <td>3.745890</td>\n",
       "      <td>3.052585</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>6</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.121819</td>\n",
       "      <td>2.077296</td>\n",
       "      <td>2.231089</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>6</td>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sale_dollars_trans  cost_per_liter_trans  state_bottle_cost_trans  \\\n",
       "0            4.750136              2.735233                 1.348073   \n",
       "1            2.574900              5.570632                 2.169054   \n",
       "2            5.000585              3.208825                 2.803360   \n",
       "3            6.636261              3.745890                 3.052585   \n",
       "4            5.121819              2.077296                 2.231089   \n",
       "\n",
       "   bottles_sold_trans  volume_sold_liters_trans  pack  bottle_volume_ml  \n",
       "0            2.995732                  2.014903    20               375  \n",
       "1            0.000000                 -2.995732     8                50  \n",
       "2            1.791759                  1.791759    12              1000  \n",
       "3            3.178054                  2.890372     6               750  \n",
       "4            2.484907                  3.044522     6              1750  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zIfgUT054dBe"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j6-0y2G9nSjI"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics#### Logistic Regression model:\n",
    "\n",
    "### Models Using Grid Search to compare best possible model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Rq1Jn4krnSjK",
    "outputId": "18e33e6b-faf4-46b3-e985-4f42d82f114c"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "columns = X_train.columns\n",
    "# scale attributes by the training set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train) # find scalings for each column that make this zero mean and unit std\n",
    "# the line of code above only looks at training data to get mean and std and we can use it \n",
    "# to transform new feature data\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 751
    },
    "colab_type": "code",
    "id": "0VmHek3j7A0u",
    "outputId": "1166c538-2723-4a7d-f0a9-fd0ebb1ab879"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:   50.9s finished\n",
      "C:\\ProgramData\\Anaconda3\\envs\\ML7331\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=5, random_state=0, test_size=0.1, train_size=None),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=8,\n",
       "             param_grid={'C': [0.001, 1, 10, 100],\n",
       "                         'class_weight': ['balanced', None], 'max_iter': [100],\n",
       "                         'penalty': ['l2'], 'random_state': [0],\n",
       "                         'solver': ['lbfgs', 'saga', 'liblinear', 'newton-cg',\n",
       "                                    'sag']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logisitic regression 10-fold cross-validation \n",
    "\n",
    "#Divide data into test and training splits\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.10, random_state=0)\n",
    "\n",
    "regEstimator = LogisticRegression()\n",
    "\n",
    "\n",
    "parameters = { 'penalty':['l2']\n",
    "#              , 'l1', 'elasticnet']\n",
    "              ,'C': [0.001, 1, 10, 100]\n",
    "              ,'class_weight': ['balanced', None]\n",
    "              ,'random_state': [0]\n",
    "              ,'solver': ['lbfgs', 'saga', 'liblinear', 'newton-cg', 'sag']\n",
    "              ,'max_iter':[100]\n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "\n",
    "regGridSearch = GridSearchCV(estimator=regEstimator\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring='accuracy')\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "a2Gdgl8k62xQ",
    "outputId": "5f7f715d-9660-4f96-a091-94544d6f34e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Diplay the top model parameters\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.model_selection._search.GridSearchCV"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(regGridSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridresults = pd.DataFrame(regGridSearch.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['param_solver','param_C', 'param_max_iter', 'class_weight', 'param_penalty', 'mean_test_score', 'rank_test_score']\n",
    "gridresults = pd.DataFrame(gridresults, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_solver</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.839725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.839725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.839725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.839725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.832350</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>sag</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.832275</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.832275</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.832275</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.832275</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.832250</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.832250</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>sag</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.832250</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.832250</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.832225</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.832225</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>sag</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.832225</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.832225</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>saga</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.832200</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>saga</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.832150</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>saga</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.832125</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_solver param_C param_max_iter  class_weight param_penalty  \\\n",
       "5         lbfgs   0.001            100           NaN            l2   \n",
       "6          saga   0.001            100           NaN            l2   \n",
       "8     newton-cg   0.001            100           NaN            l2   \n",
       "9           sag   0.001            100           NaN            l2   \n",
       "7     liblinear   0.001            100           NaN            l2   \n",
       "39          sag     100            100           NaN            l2   \n",
       "28    newton-cg      10            100           NaN            l2   \n",
       "27    liblinear      10            100           NaN            l2   \n",
       "25        lbfgs      10            100           NaN            l2   \n",
       "37    liblinear     100            100           NaN            l2   \n",
       "35        lbfgs     100            100           NaN            l2   \n",
       "29          sag      10            100           NaN            l2   \n",
       "38    newton-cg     100            100           NaN            l2   \n",
       "18    newton-cg       1            100           NaN            l2   \n",
       "17    liblinear       1            100           NaN            l2   \n",
       "19          sag       1            100           NaN            l2   \n",
       "15        lbfgs       1            100           NaN            l2   \n",
       "16         saga       1            100           NaN            l2   \n",
       "36         saga     100            100           NaN            l2   \n",
       "26         saga      10            100           NaN            l2   \n",
       "\n",
       "    mean_test_score  rank_test_score  \n",
       "5          0.839725                1  \n",
       "6          0.839725                1  \n",
       "8          0.839725                1  \n",
       "9          0.839725                1  \n",
       "7          0.832350                5  \n",
       "39         0.832275                6  \n",
       "28         0.832275                6  \n",
       "27         0.832275                6  \n",
       "25         0.832275                6  \n",
       "37         0.832250               10  \n",
       "35         0.832250               10  \n",
       "29         0.832250               10  \n",
       "38         0.832250               10  \n",
       "18         0.832225               14  \n",
       "17         0.832225               14  \n",
       "19         0.832225               14  \n",
       "15         0.832225               14  \n",
       "16         0.832200               18  \n",
       "36         0.832150               19  \n",
       "26         0.832125               20  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridresults.sort_values(by=['rank_test_score'], ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.83965\n",
      "confusion matrix\n",
      " [[14901   625]\n",
      " [ 2582  1892]]\n"
     ]
    }
   ],
   "source": [
    "y_hat = regGridSearch.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "# now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "\n",
    "print(\"accuracy\", acc )\n",
    "print(\"confusion matrix\\n\",conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iuBdzdM8nSjo"
   },
   "source": [
    "ROC Curves and AUC in Python\n",
    "https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
    "\n",
    "When to Use ROC vs. Precision-Recall Curves? Generally, the use of ROC curves and precision-recall curves are as follows:\n",
    "\n",
    "ROC curves should be used when there are roughly equal numbers of observations for each class. Precision-Recall curves should be used when there is a moderate to large class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Skill: ROC AUC=0.500\n",
      "Logistic: ROC AUC=0.883\n"
     ]
    }
   ],
   "source": [
    "# predict probabilities\n",
    "lr_probs = regGridSearch.predict_proba(X_test_scaled)\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDI0MDSYnSj0"
   },
   "outputs": [],
   "source": [
    "ywhiskcnt = y_test.apply(pd.value_counts)\n",
    "ycnt = ywhiskcnt.loc[1:1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "egJSv8ZOnSj5",
    "outputId": "e3dc6c69-dfa9-48b5-e52b-0f854f15cf03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: f1=0.479 auc=0.653\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict probabilities\n",
    "lr_probs = regGridSearch.predict_proba(X_test_scaled)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# predict class values\n",
    "yhat = regGridSearch.predict(X_test_scaled)\n",
    "lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\n",
    "lr_f1, lr_auc = f1_score(y_test, yhat), auc(lr_recall, lr_precision)\n",
    "# summarize scores\n",
    "print('Logistic: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n",
    "# plot the precision-recall curves\n",
    "ywhiskcnt = y_test.apply(pd.value_counts)\n",
    "ycnt = ywhiskcnt.loc[1:1, :]\n",
    "no_skill = ycnt.values[0] / len(y_test)\n",
    "#no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "no_skill\n",
    "#no_skill = 0.2\n",
    "pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "pyplot.plot(lr_recall, lr_precision, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('Recall')\n",
    "pyplot.ylabel('Precision')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dC7CCKAznSkt"
   },
   "source": [
    "#### Support Vector Machine Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(XSVM, ySVM , test_size=0.2, random_state=0)\n",
    "columns = X_train.columns\n",
    "# scale attributes by the training set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train) # find scalings for each column that make this zero mean and unit std\n",
    "# the line of code above only looks at training data to get mean and std and we can use it \n",
    "# to transform new feature data\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 54.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ML7331\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=0, tol=1e-05,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#possibility to scale it?\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import preprocessing\n",
    "X_train_scaled \n",
    "X_test_scaled \n",
    "#X_train = preprocessing.scale(X_train)\n",
    "#X_test = preprocessing.scale(X_test)\n",
    "\n",
    "# all parameters not specified are set to their defaults\n",
    "#https://stackabuse.com/implementing-svm-and-kernel-svm-with-pythons-scikit-learn/\n",
    "from sklearn.svm import SVC\n",
    "#svclassifier = SVC(kernel='poly', degree=8)\n",
    "#svclassifier = SVC(kernel='rbf')\n",
    "#svclassifier = SVC(kernel='linear', C = 20, random_state=0)\n",
    "#svclassifier = LinearSVC(C=100)\n",
    "svclassifier = LinearSVC(random_state=0, C = 10000, tol=1e-5, max_iter=1000, dual=False)\n",
    "model = svclassifier.fit(X_train_scaled,  y_train)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "\n",
      "[[4379  225]\n",
      " [ 770  626]]\n",
      "\n",
      "Classification report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90      4604\n",
      "           1       0.74      0.45      0.56      1396\n",
      "\n",
      "    accuracy                           0.83      6000\n",
      "   macro avg       0.79      0.70      0.73      6000\n",
      "weighted avg       0.82      0.83      0.82      6000\n",
      "\n",
      "\n",
      "accuracy\n",
      " 0.8341666666666666\n"
     ]
    }
   ],
   "source": [
    "# Returns a NumPy Array\n",
    "predictions = svclassifier.predict(X_test_scaled)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"confusion matrix\\n\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(\"\\nClassification report\\n\")\n",
    "print(classification_report(y_test, predictions))\n",
    "acc = mt.accuracy_score(y_test,predictions)\n",
    "print(\"\\naccuracy\\n\", acc )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the analysis here is basically telling us what the original statistics of the data looked like, and also what the statistics of the support vectors looked like. We can see that the separation in distributions is not as great as the separation for the original data. This is because the support vectors tend to be instances on the edge of the class boundaries and also instances that are classified incorrectly in the training data.\n",
    "\n",
    "You can also look at joint plots of the data and see how relationships have changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# now divide the data into test and train using scikit learn built-ins\n",
    "\n",
    "cv = StratifiedShuffleSplit( n_splits=5,test_size=0.8)\n",
    "# use some compact notation for creating a linear SVM classifier with stochastic descent\n",
    "\n",
    "regularize_const = 0.01\n",
    "iterations = 500\n",
    "\n",
    "# use some compact notation for creating a logistic regression classifier with stochastic descent\n",
    "log_sgd = SGDClassifier(alpha=regularize_const,\n",
    "        fit_intercept=True, l1_ratio=1.0, learning_rate='optimal',\n",
    "        loss='log', n_iter_no_change=iterations, n_jobs=-1, penalty='l2', average = True, max_iter = 10000, tol=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ML7331\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\ML7331\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\ML7331\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\ML7331\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\ML7331\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.836025\n"
     ]
    }
   ],
   "source": [
    "for train_idx, test_idx in cv.split(X,y):\n",
    "    log_sgd.fit(scl_obj.fit_transform(X.iloc[train_idx]),y.iloc[train_idx])\n",
    "    yhat = log_sgd.predict(scl_obj.transform(X.iloc[test_idx]))\n",
    "    \n",
    "    conf = mt.confusion_matrix(y.iloc[test_idx],yhat)\n",
    "    acc = mt.accuracy_score(y.iloc[test_idx],yhat)\n",
    "\n",
    "print('Logistic Regression:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[59236,  2648],\n",
       "       [10470,  7646]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# use some compact notation for creating a linear SVM classifier with stichastic descent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "regularize_const = 0.01\n",
    "iterations = 500\n",
    "svm_sgd = SGDClassifier(alpha=regularize_const,\n",
    "        fit_intercept=True, l1_ratio=0.0, learning_rate='optimal',\n",
    "        loss='hinge', n_iter_no_change=iterations, n_jobs=-1, penalty='l2')\n",
    "\n",
    "scl = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ML7331\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\ML7331\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\ML7331\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\ML7331\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\ML7331\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 0.8405375\n"
     ]
    }
   ],
   "source": [
    "for train_idx, test_idx in cv.split(X,y):\n",
    "    svm_sgd.fit(scl.fit_transform(X.iloc[train_idx]),y.iloc[train_idx])\n",
    "    yhat = svm_sgd.predict(scl.transform(X.iloc[test_idx]))\n",
    "    \n",
    "    conf = mt.confusion_matrix(y.iloc[test_idx],yhat)\n",
    "    acc = mt.accuracy_score(y.iloc[test_idx],yhat)\n",
    "\n",
    "print('SVM:', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=8)]: Done 120 out of 120 | elapsed:   21.1s finished\n",
      "C:\\ProgramData\\Anaconda3\\envs\\ML7331\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=5, random_state=0, test_size=0.1, train_size=None),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                     class_weight=None, early_stopping=False,\n",
       "                                     epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "                                     l1_ratio=0.15, learning_rate='optimal',\n",
       "                                     loss='hinge', max_iter=1000,\n",
       "                                     n_iter_no_change=5, n_jobs=None,\n",
       "                                     penalt...\n",
       "                                     validation_fraction=0.1, verbose=0,\n",
       "                                     warm_start=False),\n",
       "             iid='warn', n_jobs=8,\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
       "                         'class_weight': ['balanced'],\n",
       "                         'fit_intercept': [True, False],\n",
       "                         'learning_rate': ['optimal'], 'loss': ['hinge'],\n",
       "                         'n_iter_no_change': [1, 50, 500], 'penalty': ['l2'],\n",
       "                         'power_t': [0.1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logisitic regression 10-fold cross-validation \n",
    "\n",
    "#Divide data into test and training splits\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.10, random_state=0)\n",
    "\n",
    "regEstimator = SGDClassifier()\n",
    "\n",
    "\n",
    "parameters = { \n",
    "              'alpha' : [0.0001, .001, .01, .1],\n",
    "#    1, 10, 100],\n",
    "              'fit_intercept' : [True, False], \n",
    "#              'l1_ratio' : [0.0, 0.15, 0.5, 0.75, 0.95],\n",
    "              'learning_rate' : ['optimal'],\n",
    "#    'invscaling', 'adaptive', , 'constant'],\n",
    "              'loss' : ['hinge'],\n",
    "#                        , 'log'], \n",
    "              'n_iter_no_change' : [1, 50, 500],\n",
    "              'penalty' : ['l2'],\n",
    "              'class_weight' : ['balanced'],\n",
    "#              'eta0' : [ 0.25, 0.5, 0.75, 0.95],\n",
    "              'power_t' : [0.1],\n",
    "#    0.5]    \n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "\n",
    "regGridSearch = GridSearchCV(estimator=regEstimator\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring='accuracy')\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(scl.transform(X_train_scaled), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridresultsgd = pd.DataFrame(regGridSearch.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_fit_intercept</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_n_iter_no_change</th>\n",
       "      <th>...</th>\n",
       "      <th>param_power_t</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.042399</td>\n",
       "      <td>0.011432</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>optimal</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.819583</td>\n",
       "      <td>0.796667</td>\n",
       "      <td>0.722083</td>\n",
       "      <td>0.778333</td>\n",
       "      <td>0.763833</td>\n",
       "      <td>0.044500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.276499</td>\n",
       "      <td>0.102482</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>optimal</td>\n",
       "      <td>hinge</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.772083</td>\n",
       "      <td>0.758750</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>0.759583</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.761750</td>\n",
       "      <td>0.006354</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.604701</td>\n",
       "      <td>0.420414</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>optimal</td>\n",
       "      <td>hinge</td>\n",
       "      <td>500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.767083</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.760167</td>\n",
       "      <td>0.007512</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.299399</td>\n",
       "      <td>0.084005</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>optimal</td>\n",
       "      <td>hinge</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.767083</td>\n",
       "      <td>0.772083</td>\n",
       "      <td>0.760833</td>\n",
       "      <td>0.752917</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.760167</td>\n",
       "      <td>0.008865</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.427723</td>\n",
       "      <td>0.105761</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>optimal</td>\n",
       "      <td>hinge</td>\n",
       "      <td>500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.764167</td>\n",
       "      <td>0.758750</td>\n",
       "      <td>0.765417</td>\n",
       "      <td>0.759583</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.759917</td>\n",
       "      <td>0.004855</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "15       0.042399      0.011432         0.001201        0.000399        0.01   \n",
       "22       0.276499      0.102482         0.001001        0.000003         0.1   \n",
       "17       2.604701      0.420414         0.001000        0.000003        0.01   \n",
       "16       0.299399      0.084005         0.001001        0.000002        0.01   \n",
       "23       1.427723      0.105761         0.000797        0.000246         0.1   \n",
       "\n",
       "   param_class_weight param_fit_intercept param_learning_rate param_loss  \\\n",
       "15           balanced               False             optimal      hinge   \n",
       "22           balanced               False             optimal      hinge   \n",
       "17           balanced               False             optimal      hinge   \n",
       "16           balanced               False             optimal      hinge   \n",
       "23           balanced               False             optimal      hinge   \n",
       "\n",
       "   param_n_iter_no_change  ... param_power_t  \\\n",
       "15                      1  ...           0.1   \n",
       "22                     50  ...           0.1   \n",
       "17                    500  ...           0.1   \n",
       "16                     50  ...           0.1   \n",
       "23                    500  ...           0.1   \n",
       "\n",
       "                                               params split0_test_score  \\\n",
       "15  {'alpha': 0.01, 'class_weight': 'balanced', 'f...          0.702500   \n",
       "22  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...          0.772083   \n",
       "17  {'alpha': 0.01, 'class_weight': 'balanced', 'f...          0.762500   \n",
       "16  {'alpha': 0.01, 'class_weight': 'balanced', 'f...          0.767083   \n",
       "23  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...          0.764167   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "15           0.819583           0.796667           0.722083   \n",
       "22           0.758750           0.765000           0.759583   \n",
       "17           0.767083           0.760417           0.765000   \n",
       "16           0.772083           0.760833           0.752917   \n",
       "23           0.758750           0.765417           0.759583   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "15           0.778333         0.763833        0.044500                1  \n",
       "22           0.753333         0.761750        0.006354                2  \n",
       "17           0.745833         0.760167        0.007512                3  \n",
       "16           0.747917         0.760167        0.008865                3  \n",
       "23           0.751667         0.759917        0.004855                5  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridresultsgd.sort_values(by=['rank_test_score'], ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDyKKT0mnSmE"
   },
   "source": [
    "### Advantages  [10 points] \n",
    "Discuss the advantages of each model for each classification task. Does one\n",
    "type of model offer superior performance over another in terms of prediction accuracy? In\n",
    "terms of training time or efficiency? Explain in detail. \n",
    "\n",
    "#### Logistic Regression\n",
    "* Advantages - There is less transformation needed in order to make the model return in a reasonable amount of time. Scaler transformation will increase the accuracy, but is not required for peroformance as the model performs well at scale regardless of whether the data is normalized or not. \n",
    "* Performance - There are many different setting that allow the model to have the best possible accuracy. These methods can be iterated with a grid search method. \n",
    "*  Training Time efficiency is very good at large scales and does not suffer as volume of data increases.\n",
    "\n",
    "#### Support Vector Machine\n",
    "* Advantages - From Tan book Chapter 5 - A classification technique that has received considerable attention is support vector machine (SVM). This technique has its roots in statistical learning theory and has shown promising empirical results in many practical applications, from handwritten digit recognition to text categorization. SVM also works very well with high-dimensional data and avoids the curse of dimensionality problem. Another unique aspect of this approach is that it represents the decision boundary using a subset of the training examples, known as the support vectors.  \n",
    " However, in order to get high accuracy scaling and high penalties must be set to achieve accuracy with unbalanced data. \n",
    "* Performance - Changing the cost to value 1000, after previously using 1, 10, and 100 the performance of prediciton accuracy improves over that of logistic regession.  In order to get a result in a similiar amount of time as logistic regression accuracy is sacrficed. \n",
    "* Training Time\n",
    "    * Slow with large data volume and features\n",
    "    * Transformation of data helps\n",
    "    * Very slow with high cost.\n",
    "\n",
    "#### Stochastic Gradiant Descent\n",
    "* Advantages\n",
    "* Performance\n",
    "   \n",
    "    \n",
    "\n",
    "#### Conclusion\n",
    "The logistic regression provides a way to quickly get to a model, though has less accuracy when compared to SVM.  SVM is very accurate while its performance degrades very quickly with large volumes of data with rows and also with a large number of features. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VX-oO4qOnSmF"
   },
   "source": [
    "###  Interpret  [30 points] \n",
    "Use the weights from logistic regression to interpret the importance of different\n",
    "features for the classification task. Explain your interpretation in detail. Why do you think\n",
    "some variables are more important? \n",
    "\n",
    "The two fields \"Average of cost_per_liter_trans\" and \"Average of state_bottle_cost_trans\" seem to have the highest coeficients on the logistic regression model. \n",
    "\n",
    "Type\t     Average of cost_per_liter_trans\tAverage of state_bottle_cost_trans\n",
    "Not Whiskey\t 2.675545886\t                    1.999205623\n",
    "Whiskey      3.545918698\t                    2.871239458\n",
    "\n",
    "Add a t-test to show they are significantly different averages? \n",
    "\n",
    "The model seems to point out that price is the largest differentiator of the available characteristics. Whiskey is more expensive than other liquors. A higher cost per bottle can be used to identify whether a trancation was Whiskey or not. Other numeric features that are present represent bottle size and quanities of bottles sold. Since bottle sizes are fairly standard across the different types of liquors and quantity sold are well balanced across the liquor types and Whiskey is in the middle of the pack for these measures they do not have as much impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "Ye0EUAwn19qH",
    "outputId": "db97e541-231c-4e5d-9c2f-4b74332eadab"
   },
   "outputs": [],
   "source": [
    "# interpret the weights\n",
    "# iterate over the coefficients\n",
    "weights2 = logisticRegr.coef_.T # take transpose to make a column vector\n",
    "variable_names = X.columns\n",
    "for coef, name in zip(weights2,variable_names):\n",
    "    print(name, 'has weight of', coef[0])\n",
    "    \n",
    "# does this look correct? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "NFTKvdcf2DyB",
    "outputId": "a4c1bc94-b802-4a61-d93e-8ce14fc34dc8"
   },
   "outputs": [],
   "source": [
    "# now let's make a pandas Series with the names and values, and plot them\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "weights = pd.Series(logisticRegr.coef_[0],index=X.columns)\n",
    "weights.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yVHNEFrTnSmG"
   },
   "source": [
    "### Insight into the data [10 points]\n",
    "Look at the chosen support vectors for the classification task. Do these provide\n",
    "any insight into the data? Explain. If you used stochastic gradient descent (and therefore did\n",
    "not explicitly solve for support vectors), try subsampling your data to train the SVC model—\n",
    "then analyze the support vectors from the subsampled dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "OXMl4cgmnSmH",
    "outputId": "bc4146c2-dd1d-4d79-f88c-389c870bd348"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04172852,  0.3721708 ,  1.1229617 , ..., -0.66089127,\n",
       "        -0.70389697, -0.26280584],\n",
       "       [ 0.68132163,  0.0737954 ,  0.68644563, ...,  0.13752377,\n",
       "        -0.02330599, -0.26280584],\n",
       "       [ 0.89149549,  0.04219618,  0.62906725, ...,  0.34659634,\n",
       "        -0.70389697,  0.27676159],\n",
       "       ...,\n",
       "       [ 1.02543744,  0.39064988,  1.14532376, ...,  0.13752377,\n",
       "        -0.70389697, -0.26280584],\n",
       "       [ 0.19106698, -0.39877606, -0.7808375 , ...,  0.64126757,\n",
       "        -0.02330599, -0.26280584],\n",
       "       [ 0.68979404,  0.08020147,  0.69774358, ...,  0.13752377,\n",
       "        -0.70389697, -0.26280584]])"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view support vectors\n",
    "model.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "L2A_wTYZ1p7X",
    "outputId": "5ae7f79e-61f6-41b0-f825-29892592380e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     9,    11, ..., 79980, 79984, 79987], dtype=int32)"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View indicies of support vectors\n",
    "model.support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qxAYjH4AWOmK"
   },
   "source": [
    "This chooses all the misclassified items as a support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mHkRqABz1zz2",
    "outputId": "cb2cae21-8a92-4d24-ca05-3d8fd61f835c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14457, 14435], dtype=int32)"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view number of support vectors for each class\n",
    "model.n_support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4XKEUr0WVPU"
   },
   "source": [
    "We used 14,000 instances of Whiskey and Nonwhiskey to build our decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "aPO1D6PsWd0P",
    "outputId": "b90b5917-1dc1-44b7-e458-93254fa3b913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.61779238  0.01725721 -0.26736576  1.74130624  0.93580436 -0.34449688\n",
      "   0.05279718 -0.32864875]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f55ad5f5438>"
      ]
     },
     "execution_count": 131,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAF5CAYAAAB5mJZQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3de3hMd+I/8HdGrkNCbipxv8ddVVS3\nqSjdUO2Dotgtvi2l37ZRtpawLdYqQStWKrRJN3VJt1rlq6hu1a3udEVQlzaJhMiQiNzEMCEzvz/y\nm6kxkWRkJp9zfN6v58nzJCfzzHkbzHvO53zO57iYTCYTiIhIShrRAYiISByWABGRxFgCREQSYwkQ\nEUmMJUBEJDGWABGRxFxFB7CXTqdz6PMFBwc7/DmdgTkdizkdRw0ZAblzBgcHP/B3PBIgIpIYS4CI\nSGIsASIiibEEiIgkxhIgIpIYS4CISGIsASIiibEEiIgkprqLxYgepE5BHpB/rVqPLbh8AXUMhqof\n6BeIMt+AGiYjUi6WAD068q+hdFFUtR5aWs2ndJ+5GGAJ0COMw0FERBJjCRARSYwlQEQkMZYAEZHE\nWAJERBJjCRARSYwlQEQkMZYAEZHEWAJERBJjCRARSYwlQEQkMZYAEZHEWAJERBJjCRARSYwlQEQk\nMYfdT2Dt2rU4evQorl27ho8++gjNmjWzeczXX3+NHTt2wNfXFwDQvn17vP76646KQEREdnJYCfTq\n1QuDBg3C3LlzK31cnz59MG7cOEftloiIasBhJRASEuKopyIiolpS67eXPHToEE6dOoUGDRpg5MiR\naNeuXW1HICKi/69WSyAiIgLDhg2Dq6srTp06hSVLlmDZsmXw9vau9nMEBwc7PJczntMZmLNyBZcv\nVPvewdXl7uEBX8Gvuxr+3tWQEWDOitRqCTRo0MDyfdeuXeHv74+srCx07Nix2s+h0+kcmik4ONjh\nz+kMzFm1OgaDw5+z1GAQ+rqr4e9dDRkBuXNWViq1OkU0Pz/f8n1mZiauXbummmYmInoUOexIIDEx\nEceOHUNhYSHmz58Pb29vxMTEIDo6GiNHjkTr1q3x73//GxkZGdBoNHB1dUVkZKTV0QEREdUuh5XA\n+PHjMX78eJvts2bNsnwfGRnpqN0REZED8IphIiKJsQSIiCTGEiAikhhLgIhIYiwBIiKJsQSIiCTG\nEiAikhhLgIhIYiwBIiKJsQSIiCTGEiAikhhLgIhIYiwBIiKJsQSIiCTGEiAikhhLgIhIYiwBIiKJ\nsQSIiCTGEiAikhhLgIhIYiwBIiKJsQSIiCTGEiAikhhLgIhIYiwBIiKJsQSIiCTGEiAikhhLgIhI\nYiwBIiKJsQSIiCTGEiAikhhLgIhIYiwBIiKJuTrqidauXYujR4/i2rVr+Oijj9CsWTObxxiNRiQm\nJuLkyZMAgKFDh6J///6OikBERHZy2JFAr169MG/ePAQGBj7wMfv370dOTg6WL1+OBQsWYMOGDcjN\nzXVUBCIispPDSiAkJAQBAQGVPubQoUPo378/NBoNfHx8EBoaiiNHjjgqAhER2clhw0HVkZeXZ1UU\nAQEByMvLs+s5goODHR3LKc/pDMxZuYLLF1Dq4Od09/CAr+DXXQ1/72rICDBnRWq1BBxBp9M59PmC\ng4Md/pzOwJxVq2MwOPw5Sw0Goa+7Gv7e1ZARkDtnZaVSq7OD7v/kf/+RARER1a5aLYGnnnoKu3bt\ngtFoRHFxMX7++Wf07t27NiMQEdE9HDYclJiYiGPHjqGwsBDz58+Ht7c3YmJiEB0djZEjR6J169bo\n06cPUlNTMWXKFADAiBEj0LBhQ0dFICIiOzmsBMaPH4/x48fbbJ81a5ble41Gg4kTJzpql0REVEOq\nOzFMpHZ1CvKA/GvVemzB5QvVO+HtF4gyX55fI/uxBIhqW/41lC6KqtZDqzvl1X3mYoAlQA+BawcR\nEUmMJUBEJDGWABGRxFgCREQSYwkQEUmMJUBEJDGWABGRxFgCREQSYwkQEUmMJUBEJDGWABGRxFgC\nREQSYwkQEUmMJUBEJDGWABGRxFgCREQSYwkQEUmMJUBEJDGWABGRxFgCREQSYwkQEUmMJUBEJDGW\nABGRxFgCREQSYwkQEUmMJUBEJDGWABGRxFgCREQSYwkQEUmMJUBEJDGWABGRxFwd9UQ6nQ5xcXEo\nKSlBvXr1EBkZiaCgIKvHfP3119ixYwd8fX0BAO3bt8frr7/uqAhERGQnh5VAQkICBgwYgD59+mDf\nvn2Ij4/H3LlzbR7Xp08fjBs3zlG7JSKiGnDIcFBRUREyMjIQFhYGAAgLC0NGRgaKi4sd8fREROQk\nDjkSuH79Ovz8/KDRlHeKRqOBr68v8vLy4OPjY/XYQ4cO4dSpU2jQoAFGjhyJdu3a2bWv4OBgR0R2\n+nM6A3NWruDyBZQ6+DndPTzg6+A/j1py2oP/Nh2rNnM6bDioOiIiIjBs2DC4urri1KlTWLJkCZYt\nWwZvb+9qP4dOp3NopuDgYIc/pzMwZ9XqGAwOf85Sg8Hhfx615Kwu/tt0LGfkrKxUHDIc5O/vj/z8\nfBiNRgCA0WhEQUEBAgICrB7XoEEDuLqW907Xrl3h7++PrKwsR0QgIqKH4JASqF+/Plq0aIEDBw4A\nAA4cOICWLVvaDAXl5+dbvs/MzMS1a9dUc3hGRPQocthw0MSJExEXF4eNGzeibt26iIyMBABER0dj\n5MiRaN26Nf79738jIyMDGo0Grq6uiIyMRIMGDRwVgYiI7OSwEmjcuDEWLlxos33WrFmW783FQERE\nysArhomIJMYSICKSGEuAiEhiLAEiIomxBIiIJMYSICKSGEuAiEhiLAEiIomxBIiIJMYSICKSGEuA\niEhiLAEiIomxBIiIJMYSICKSGEuAiEhiLAEiIomxBIiIJMYSICKSGEuAiEhiLAEiIomxBIiIJMYS\nICKSGEuAiEhiLAEiIomxBIiIJMYSICKSGEuAiEhiLAEiIomxBIiIJMYSICKSGEuAiEhiLAEiIom5\nig5ARFQTdQrygPxrVT6u4PIF1DEYqvekfoEo8w2oYTJ1cFgJ6HQ6xMXFoaSkBPXq1UNkZCSCgoKs\nHmM0GpGYmIiTJ08CAIYOHYr+/fs7KgIRySj/GkoXRVX5sFI7ntJ95mJAkhJw2HBQQkICBgwYgOXL\nl2PAgAGIj4+3ecz+/fuRk5OD5cuXY8GCBdiwYQNyc3MdFYGIiOzkkCOBoqIiZGRkYPbs2QCAsLAw\nJCYmori4GD4+PpbHHTp0CP3794dGo4GPjw9CQ0Nx5MgRDB482BExVMnhh7ISHcYSUc05pASuX78O\nPz8/aDTlBxYajQa+vr7Iy8uzKoG8vDwEBPz+BhUQEIC8vDy79hUcHFytx93ISMPda1erfFzB5Qvw\nqua+XQMbwbtlm2o+unpuGPS4e9OjWo9196j6ca5aLbyr+RpVV3VfS6D6r6ezXkv3uf906HO6BjZy\n/Ouplpwq+j/E1/Phqe7EsE6nq9bj6ly+WK1xQnu4z1yMGx5ahz4nPLRAk1ZVPiw4OLjaf/Yb1Xxc\ndT1qryUg9vVUS85H7e/dntcSeLRez8o+PDvknIC/vz/y8/NhNBoBlJ8ALigosPrUD9h+8r//yICI\niGqXQ0qgfv36aNGiBQ4cOAAAOHDgAFq2bGk1FAQATz31FHbt2gWj0Yji4mL8/PPP6N27tyMiEBHR\nQ3DYcNDEiRMRFxeHjRs3om7duoiMjAQAREdHY+TIkWjdujX69OmD1NRUTJkyBQAwYsQINGzY0FER\niIjITg4rgcaNG2PhwoU222fNmmX5XqPRYOLEiY7aJRER1RCXjSAikhhLgIhIYiwBIiKJsQSIiCTG\nEiAikhhLgIhIYiwBIiKJsQSIiCTGEiAikhhLgIhIYiwBIiKJsQSIiCTGEiAikhhLgIhIYiwBIiKJ\nsQSIiCTGEiAikpjD7ixGjzC/QLjPXFyth7p7eKDUYKjWcxKReCwBqlKZbwDgG1Ctx/oGB0On0zk5\nERE5CoeDiIgkxhIgIpIYS4CISGI8J0BEVBuqOcGi2pMr/v9z1hRLgIgqptA3LbWq7gSL2p5cwRIg\nogop9U2LHIvnBIiIJMYSICKSGEuAiEhiLAEiIomxBIiIJMYSICKSGEuAiEhiLAEiIonV+GIxg8GA\nlStX4sKFC6hTpw7Gjh2LJ554wuZxZ86cQXR0NIKCggAAbm5uWLhwYU13T0RENVDjEti6dSu8vLzw\n8ccf48qVK5gzZw4+/vhjeHp62jy2SZMmWLRoUU13SUREDlLj4aBDhw7hj3/8IwAgKCgIrVu3xokT\nJ2ocjIiInK/GRwJ5eXkIDPx9UaiAgABcv369wsdeuXIFUVFRqFOnDiIiItC3b1+79xccHFytxxVc\nvoBSu5+9cu4eHvCt5v6dobp/dtGY07HUkFMNGQHmrEiVJRAVFYW8vLwKf5eQkFDtHbVs2RKrVq2C\nVqtFbm4u5s+fDz8/P3Tt2rX6aYFqL1RVp7qrGtqh1GAQtlBWsEoW6WJOx1JDTjVkBOTOWVmpVFkC\nixdXvpRsQEAArl27Bh8fHwDlRwadOnWyeZxWq7V837BhQ4SGhuLXX3+1uwSIiMhxanxOoHfv3vjx\nxx8BlA/3pKeno3v37jaPKygogMlkAgCUlJTg5MmTaNGiRU13T0RENVDjcwKDBw/GypUrMXnyZGg0\nGkyaNAleXl4AgK+++gq+vr6IiIjA0aNHsWPHDtSpUwdGoxHh4eEIDQ2t8R+AiIgeXo1LwNPTE+++\n+26Fvxs1apTl+4EDB2LgwIE13R0RETkQrxgmIpIYS4CISGIsASIiibEEiIgkVuMTw4rlFwj3mZVf\n4wCUXwVcWt0Ly/wCq34MEZGKPLIlUOYbAPgGVPk4X5VcRUhE5AwcDiIikhhLgIhIYiwBIiKJsQSI\niCTGEiAikhhLgIhIYiwBIiKJsQSIiCTmYjLf6YWIiKTDIwEiIomxBIiIJMYSICKSGEuAiEhiLAEi\nIomxBIiIJMYSICKSGEuAiEhiLAEiIomxBIiIJMYSICKp3L17V3QERZGyBHQ6HUpLSwEAKSkp2Lx5\nM0pKSgSnsmY0GvH111+LjkGkauvWrbP6uaysDB999JGgNBW7fPlypV/OJmUJLFu2DBqNBrm5uUhI\nSEBOTg7i4uJEx7Ki0Whw4sQJ0TGqZe3atdDr9SgrK8OcOXMwduxY7Nu3T3QsG2rJeejQIej1egDA\nV199hQULFuDChQuCU1lTQ0YAuH79Ov7zn/8AKP9gtXz5cjRu3FhwKmvR0dEP/Fq0aJHT9y9lCWg0\nGri6uiI5ORkRERF44403kJeXJzqWjR49emDLli0oKiqCwWCwfCnN6dOnodVqcfLkSfj5+WH58uXY\nunWr6Fg21JJz48aN0Gq1SEtLw8mTJxEeHo7ExETRsayoISMAvP322zh69CiOHDmClStXon79+hg7\ndqzoWFbi4uIe+LVixQqn79/V6XtQoNLSUhQWFuL48eMYPXq06DgP9M033wAAvvjiC6vtX331lYg4\nVTp79ix69eoFPz8/uLi4iI7zQErP6epa/t/y1KlT6NevH8LCwhRXVmrICABubm6YNm0a5s6di7Zt\n22LChAmiI1XKYDDg+vXrMBqNlm1NmjRx6j6lLIEXXngBU6dORefOndG6dWvk5ORAq9WKjmVDqW/2\n9/Px8UFCQgJSUlIwdOhQlJWVWf0jVgq15ATKh1sOHjyIqKgoAMo8mankjBMmTLAq+NLSUhQUFOC/\n//0vAOCzzz4TFe2Btm/fjvXr16Nu3brQaMoHaVxcXJx+NMCbyqB8rNBoNFo+3SiJTqdDdnY2QkND\ncfv2bdy9exf16tUTHctKcXEx9u/fj7Zt26Jdu3bIzc3F2bNn0bdvX9HRrKgl52+//YbNmzejc+fO\nGDRoEK5cuYLvv/8e48ePFx3NQukZr127VunvAwMDaylJ9UVGRuIf//gH/Pz8anW/0pbA6dOnkZOT\ng7KyMsu2AQMGCExka+/evdi8eTPu3r2LFStWQKfT4V//+hdmz54tOhqRKhQXF0Or1Vo+4N29exd6\nvR4+Pj6Ck9maO3cu5s2bV+v7Vd5H31qwYsUKZGRkoGXLlpbDLiXavn07Fi1ahDlz5gAAgoODUVhY\nKDiVrV9//RVJSUnIzc1FWVkZTCYTXFxcFHfIrZacRUVF+P77720+pLz77rsCU1lTQ0YAWLRoEebO\nnWtVAosXL8aCBQsEJ7P18ssv45NPPsHjjz8ONzc3y/YePXo4db9SlkBqaiqWLl2qyOGfe7m6usLT\n09NqmxJL65NPPsHw4cPRtm1bReYzU0vOpUuXonHjxujSpYtic6ohIwDcuXMHHh4elp89PT0t1wgp\nzfHjx3H8+HFcuXLF6jVlCTiBv7+/6AjV4u3tDZ1OZznBtW/fPkVmd3d3R1hYmOgYVVJLzps3b+KN\nN94QHaNSashoVlxcbBn+KSoqglJHwI8dO4a4uDi4u7vX6n7r/P3vf/97re5RAX777Tds27YNN2/e\nREZGBtLT05Geno42bdqIjmaldevWiI2NhU6nw65du5CamorIyEjFnRi+fv067ty5g6CgINFRKqWW\nnOfOnUO7du3g5eUlOsoDqSEjUH40vWrVKuj1epw7dw6rV6/G4MGD0bJlS9HRbBw/fhzh4eG1fmQl\n5YnhlStXVrj9rbfequUkVTMajdDpdADKzwko8dB7woQJKCkpgaenJ9zc3BQ71q6WnAsWLEB6ejra\nt29vNTaspPF2NWQ0O3PmjOXq+x49eqBjx46CE1UsPj7eMhPw3tfU2RNWpCwBtYiJibH5T1XRNtEe\nNB1PadPw1JJz7969FW5X0lRWNWRUG1EfTqU8JwCUz7/PzMzEnTt3LNvCw8MFJrKVk5Njs818VKAk\nSnsTfRC15FTDG6kaMgKAXq/H5s2bcfHiRasTwnPnzhWYqmJVvdnv3r0b/fr1c/h+pSyB7du3Y+fO\nnSgoKECbNm1w7tw5dOzYUTElsHPnTuzatQs6nQ6zZs2ybNfr9QgODhaYrGJ5eXlISkrCxYsXrUq1\nNtY9sYdacpaVlWHPnj3IzMy0euNS0nClGjIC5Z+umzRpAp1Oh1GjRmHPnj1o1aqV6FgP5YcffnBK\nCShvgLkW7Nq1CwsXLkRAQADee+89LFy40GYqpkjdunXDmDFj0LBhQ4wdO9byNXXqVEyfPl10PBur\nVq1C165dAQDvvPMOQkJCFFOo91JLzvj4eJw/fx7Hjx9HUFAQ0tPTa33GSFXUkBEoP5oePXo0PDw8\nEBYWhpkzZ+LcuXOiYz0UZ43cS1kCbm5u8PT0hMlkgslkQrNmzXDlyhXRsSwCAwPRqVMnLF26FB07\ndrR8KfXiths3bqBfv37QaDRo164d3nrrLUUug62WnGlpaYiMjETdunXx0ksvYf78+bWyrrw91JAR\n+H2hO1dXV5SUlMDV1RXFxcWCUz0cZy12KOVwkIeHB+7evYvmzZvjiy++gL+/v6IWEktKSsKYMWMQ\nExNT4e+VdmLY/B/N09MTeXl5qF+/viL/o6klp/kTtUajgcFggFarRVFRkeBU1tSQEQCCgoJQUlKC\nsLAwvPfee9BqtaodDnIWKUtgwoQJuHv3LsaNG4cvv/wSOTk5mDx5suhYFiEhIQCcf6Wgo3To0AEl\nJSUYMGAAoqKi4Obmht69e4uOZUMtOevVq4eSkhJ0794dCxcuhLe3d60vKlYVNWQEyof9AODFF19E\nmzZtcPPmTXTv3l1wqofjrOEg6aaIGo1GfPPNNxg5cqToKI8MvV5vWYo7Ly8Per0ezZo1E5zKllpy\nGo1GaDQaGI1GHDhwAHq9Hn369FHUcudqyGhWXFyM1NRUAEDbtm0VuXicmV6vx9WrVys8WsnMzESL\nFi0cvk/pSgAAZs2ahejoaNExHigpKanS348ZM6aWklTNZDLh3XffxbJly0RHqZRachqNRixZsgQz\nZ84UHeWB1JDR7OjRo4iPj0erVq1gMpmQmZmJSZMmoVevXqKj2UhOTkZCQgI0Gg3i4uKQnp6ODRs2\nOP11lnI4yHzbxvDwcKtZQfcuNCWSUnJUh4uLCwICAlBSUqK45SzupZacGo0GN27csHzSViI1ZDRb\nv3495s+fb5lafeXKFSxZskSRJbBhwwZER0dj4cKFAGC54ZWzSVkCSr9t48svv1ytx23cuBHDhw93\ncpqqeXl5ISoqCo8//rhVqSrpiAVQT862bdvio48+QlhYmFVOJZ0jUkNGoHwm4L3X1gQFBSlyKqtZ\ngwYNrH6+d/kIZ5GyBJTyZl9Tx44dU0QJNG3aFE2bNhUdo0pqyXnx4kUAwI8//mi1XUlvsGrICAA9\ne/bEpk2b0K9fP5hMJuzZswehoaEoLS2FyWRS1FG3p6cnCgsLLVNBz5w5g7p16zp9v1KeE1i9ejVe\nffXVKrcp3YwZM7BkyRLRMZCdnY3GjRtXuU00teQkxxk1alSlv1fSB8K0tDQkJCQgNzcXzZs3x5Ur\nVxAVFeX8Ka0mCc2YMcNm2/Tp0wUkqZmK/hwiVJRDKdnupZac77//frW2iaSGjGp08+ZNU3Jysun4\n8eOmkpKSWtmnVMNBhw8fxuHDh5Gbm2t1IdatW7cUdVioFsXFxSguLkZpaanV1aJ6vR63b98WmMya\nWnKa3X/nK6PRiJKSEkFpKqaGjGqk1WrRpUsXyy07DQaD09+bpCqBoKAg9OjRA2lpaVZjl1qtFp07\ndxaY7OGYBI/kHThwAN999x0KCgqsptxqtVoMGTJEYDJrasm5ZcsWfPvtt9Dr9Xj99dct2w0GA555\n5hmByX6nhoxqdeTIEaxZswb5+flW250+ZFUrxxsKc+PGjUp/n5CQUEtJHqysrKzKoYqioqJaSlO5\njRs3Vvr7zMzMWkpSOaXnvHnzpiknJ8cUHR1tys3NtXxV9e+1Nqkho1q9/fbbptTUVFNZWVmt7lfZ\nk3ydpKp54uarC0XSaDRV3hRbKVc+Dhs2rNLfP+hmGbVN6Tm1Wi0aNmyImTNnIjAw0PJ1/7/Xe5cX\nr21qyKhWvr6+aNOmTa1feyHVcJDaBAUFYe7cuejdu7fVXGxn327O0UwqmYCmlpzm8WIlU0NGpRk4\ncCDWr1+PXr16WV3L0KRJE6fulyWgYEajEU2bNkV2drboKDXirCVwHY05HUcNGZUmPz8f3333HX76\n6SfL0YCLi4vTb3rEElAwpd2liYic5/vvv0dsbCx8fX1rdb9SnhOoilLWQzEYDFi/fj1iY2MBlF/Y\ndOzYMcGp7KeWYRbmdBw1ZFSawMDAWi8AQNIS0Ol0lhOuKSkp2Lx5s9UcZ6WsMJqQkICysjJkZmYC\nAPz9/S3rHimF0WjE119/XeljBg4cWEtpKvfLL79Uuk0pOavStm1b0RGqpIaMStO6dWv885//xNGj\nR5GcnGz5cjYpS2DZsmXQaDTIzc1FQkICcnJyEBcXJzqWjUuXLuGVV16xuiOW0j5haTSaKm/R6Iyb\nYz+MdevWVbpNdM4ffvih0i+ziRMnCkxZ7tChQ9Dr9QDK57EvWLAAFy5csPxeCRnVJiMjA0VFRfjP\nf/6DrVu3Wr6cTcpzAhqNBq6urkhOTkZERASGDBmiyBu437+CYGlpqaJug2mm9KW5r169Cp1OB71e\nb/XJSq/Xw2AwCExmLT09HUD5Fc7nzp2zXMD4yy+/oFOnToqaFbZx40b84Q9/QFpaGk6ePIlBgwYh\nMTERH3zwgehoqjV37lwh+5WyBEpLS1FYWIjjx49j9OjRouM8UIcOHbBp0ybcuXMHZ86cwbZt2xAa\nGio6lg2lL819/vx5/PTTTygqKrL6ZOXl5YVx48YJTGbNPBEgOjoaH374IRo2bAgAyM3NRWJiosho\nNsxHp6dOnUK/fv0QFhZWK59aH2UPGvpx9sqsUpbACy+8gKlTp6Jz586WGzco8bZ4o0ePxpYtW+Dl\n5YWkpCT07NkTQ4cOFR3LhlLe7B+kb9++6Nu3L/bu3Yu+ffuKjlOlvLw8SwEAQMOGDXHt2jWBiSp2\n6NAhHDx4EFFRUQCAu3fvCk6kbveWaGlpKTIzM9GqVSuWgKMZjUb4+flh9erVlm2BgYGYPXu2uFAP\n4OrqimHDhlV5pasS6HQ6ZGdnIzQ0FLdv38bdu3cVdwevhg0b4vbt2/D09MTu3buRlpaGoUOHWr3h\nKkGDBg3wzTffoH///gCAPXv22NxsRLQJEyZg8+bN6N+/Pxo2bIgrV66gU6dOomOp2v3DQZcvX8aW\nLVucvl/pTgxrNBqbT67mcwRKc+vWLSQlJWHmzJmYOXMmkpKScOvWLdGxbOzduxdLlizBmjVrAJRf\n9KLEe/kmJibCw8MDWVlZ2Lp1KwICArBq1SrRsWy8/fbbuHjxIqZNm4a//vWvyMzMxNtvvy06loXR\naERKSgpmzJiBQYMGASi/un38+PGCkz1amjRpgoyMDKfvR3nvfLWgefPmSEtLQ5s2bURHqdSqVavg\n5eWF1157DUD5J8KVK1di2rRpgpNZ2759OxYtWoQ5c+YAAIKDg1FYWCg4la06derAxcUFJ06cQERE\nBJ5//nkcOXJEdCwbfn5+ivs7vpd5RtjIkSNFR3mk3HtOwGQyIT09HXXq1HH6fqUsgYyMDMyePRuN\nGjWyms2ilOsDzLKysqw+Ubdv3x5/+ctfBCaqmKurq9XrCCjngrt7lZWVITU1FceOHcMbb7wBAIqa\nbVXVnHAl3bpR6TPC1OjecwIajQaNGjXCu+++6/T9SlkC5k/WSufr64vi4mLLaqE3btyAn5+f4FS2\nvL29odPpLOvF7Nu3D/7+/oJT2Ro1ahTi4+PRuXNnNG3aFDqdDo0aNRIdy6Kq2TVKKgGlzwhTI1FT\nRKW8x7BaLFu2DOfPn8cTTzwBoPyTYkhICAICAgAAY8aMERnPQqfTITY2FtnZ2fDx8YG7uzuioqIU\n9QZLpFSijwClPBLQ6/XYvHkzLl68aLVev6gmfpAmTZpYLSNrni2iNMHBwVi4cCF0Op3lZyUOBxkM\nBmzcuBGnT58GAHTp0gXDhw9X5BBGSkqKJWe3bt3QtWtXwYlsqWFGmBqIPgKU8kjgo48+QpMmTXDw\n4EGMGjUKe/bsQatWrfDKK6994fsAABhVSURBVK+IjmaXjRs3Yvjw4aJjICYmxmbssqJtoq1atQpl\nZWV47rnnAAC7d+8GoLzVWrds2YKffvoJTz/9NADg4MGDCA8Px+DBgwUn+93evXuxefNm3L17FytW\nrIBOp8O//vUvRU61psop7+NaLcjJycHo0aPh4eGBsLAwzJw5E+fOnRMdy25KWVE0JyfHZpv5qEBJ\n0tPTERkZiZCQEISEhODNN9+0Wu9GKfbt24cPPvjAco3IBx98gH379omOZcU8I8x8kaVSZ4SpTUpK\nCtatW4d169bh1KlTtbJPKYeDzNcEuLq6oqSkBHXr1kVxcbHgVPYTfRC3c+dO7Nq1Czqdzup2gnq9\nHsHBwQKTVcxkMlkuFgPKh4dEv4YVMZlM8PLysvzs5eWluJxqmRGmJvcfAa5Zs6ZWjgClLIGgoCCU\nlJQgLCwM7733HrRaLVq1aiU6lt1E372pW7duCAoKQmJiIsaOHWvZ7uXlhebNmwtMVrFnnnkG77//\nPv7whz8AAA4fPozw8HDBqWy1bt0aK1eutJwD2r17N1q3bi04lTW1zAhTE/MRoPkDwPPPP4/Zs2c7\nvQSkPCdwr3PnzkGv16N79+61cmGGI0VFRWHx4sWiY6hKSkqK5TC7a9eu6N69u+BEtm7fvl3hCez7\nP3mLxBlhjjdt2jQsXbq0ym2OJn0JqNmMGTOwZMkSYftPSkrCmDFjEBMTU+HvlXZimBzLaDQqfkaY\nmqxcuRIArI4ATSaT0ycuSFUCEyZMqHAIxWQywcXFBZ999pmAVA+2evVqvPrqqw/cdu+FZCL897//\nRc+ePbF3794Kf6+0FTtnz56NqKgoyzTGkpISfPjhh5g3b57gZNa2bduGfv36QavVYsWKFUhLS8Nr\nr72Gbt26iY5moZYZYWpy+/ZtfPPNN5a73dXWEaBU5wQWLVokOoJdKpqxdPbsWcv3IgsAAHr27AlA\neW/2D3L79m2reez16tVT7IJ8L774In755RcUFRXhzTffxOeff66oElDLjDA10Wg0Qi4AlaoEAgMD\nRUeolsOHD+Pw4cPIzc21Gmq5deuWoi5sSkpKqvT3Srmi2cxkMsFgMFhew9u3b6OsrExwKlvmYZUz\nZ84gLCwM7du3V8zsILXNCFOTN998E6Ghoejbty9CQkJqbb9SlcC9/2gropQF5IKCgtCjRw+kpaVZ\nXS2o1WottxxUAiUVUnU8/fTT+OCDD/DHP/4RAPDjjz/imWeeEZzKlru7OzZv3oyDBw/iH//4B0wm\nk2Ju2KK2GWFqsnz5chw4cACrV6/GrVu3EB4ejvDwcKfPupLqnMC9QykV6dixYy0lqZ6SkpJH4jJ8\npVzZDJQPtZjXanniiScUOUVUp9Nhx44d6NChA5588klcvXoVhw8fxksvvSQ6GtWSS5cuYdu2bdi/\nfz++/PJLp+5LqhK43+3btwFAUVPv7rV27VqMGDECHh4emDdvHjIyMjBx4kT06dNHdDS7qGUq62ef\nfYbXX39ddIwqLVmyBDNmzBCyb84Icy6j0YgTJ05g7969OHfuHHr27In//d//deo+pRoOMsvJyUFs\nbCwyMzMBAC1btsTkyZPx2GOPiQ12n9OnT2PcuHFITk6Gn58fpk6diujoaNWVgFo+Z6SmpoqOUC15\neXnC9m0eq1bSstaPijVr1uDQoUNo2rQpwsPDMXnyZLi7uzt9v1KWQHx8PPr3749nn30WQPkQQXx8\nvGIXvzp79ix69eoFPz8/4VcJPww1ZlYyka+n2maEqYm3tzcWLFhgWSr+fs6aEi5lCRQXF6Nfv36W\nn5999lls375dYKKK+fj4ICEhASkpKRg6dCjKysoUdScsko/aZoSpybBhwyr9/YIFC5wyrCplCWg0\nGuh0OsuUNp1Op8irHadMmYL9+/cjPDwc9erVQ25uLl588UXRseymluEgqpraZoQ9Spz1/0jKEvjT\nn/6EOXPmoEWLFjCZTLh06RIiIyNFx7Lh4+ODgQMHQqfTISsrC8HBwYo7DDcajZg1a1aln1Def//9\nWkz08JT4QaAiIhdqe/nll6v1OCXNCHtUOGsYUMoS6N69O2JiYiwnAtu2bSv86tuKpKenY+nSpXBz\nc4PJZEJZWRmmTZumqBVPNRoNPD09UVpa+sCTWEp6bU+fPo3s7GwMHDgQhYWFVhc5KeU6kbNnz6JV\nq1bw9PTE7t27kZaWhqFDh6Jhw4YAIGxmkD2OHTvGElAJdXz0cRCDwWD58vDwQOfOndG5c2d4eHjA\nYDCIjmdj9erVePPNN7F8+XLExsZalg9QmqCgIMydOxfffvstfvjhB8uX0mzevBnffPON5fxPWVkZ\nVq1aJTiVrcTERHh4eCArKwtbt25FQECAInNWhkOAjsfhIAcYN25cpb//6quvailJ9dy+fRtdunSx\n/Ny5c2esWbNGYKKKGY1GNG3aFNnZ2aKjVOrgwYOIjo7G3/72NwDlwypKXDuoTp06cHFxwYkTJxAR\nEYHnn38eR44cER3LLpwR5ni9evVyyvNKVQLmN/mNGzfCzc0Nzz33HEwmE3bt2qWYy/Lv5eHhgTNn\nzqBTp04AyocJlHhiTmn36H0Qd3d3y13lzJT4ZlVWVobU1FQcO3YMb7zxBgBwVpgEioqKsGbNGly/\nfh3z5s3DxYsX8euvvyIiIgIAMGLECKfsV6rhILNjx45h8ODB0Gq1qFu3LgYPHoyjR4+KjmXjtdde\nQ1xcHKZMmYIpU6YgLi4O48ePFx3LhsFgwPr16xEbGwsAyM7OVsz9j+/l7++P8+fPw8XFBUajERs3\nbkSTJk1Ex7IxatQoxMfHo23btmjatCl0Op3qbtbC4SD7ffrppwgJCcHNmzcBAI0bN8aOHTucvl+p\njgTMSktLcfXqVct/rKtXr6K0tFRwKls3b95EdHQ0ioqKAAD169dHVlaW4FS2EhIS4Ovra7kC29/f\nH8uXL3fa4evDGj9+PFasWIFLly5h7NixCAkJwTvvvCM6lo3Q0FCEhoZafg4ODsZf//pXgYl+V9W5\nM/ORqlpmhClJfn4+IiIisHPnTgDl93GujSNVKUtg9OjReO+99yyzbDIyMjBp0iTBqWwlJSVh8eLF\nqF+/PoDyIYF169Ypbh0e8xTbkydPAihfi0mJnwQbNGiA999/33KDeaWuGVXVsIBI1T2vpqQZYWpx\n/+1tzUcEziZlCTz55JMICQmxTBFt166d1T9a0XfsMjPf8cxMo9EocmzYzc3N6ufS0lJF5bx8+XKl\nv1fakNCnn36K7t27W4YCGjdujI8//lgRJaC282pq0qtXL8THx+PWrVvYu3cvfvjhB8vSNs4kZQkA\n5UMr5nVQ7uesy7Pt5eXlhdTUVLRt2xZA+QJnSjwx3KFDB2zatAl37tzBmTNnsG3bNqvhDNEqm//v\n4uKCFStW1GKaqokaFrDHsWPHrP6PDB48GFFRUVUufUAPNmTIEOzfvx83b95EcnIynn/++VpZLFLa\nEqiMUoYyxowZgw8//BBNmzYFUP6Jdtq0aYJT2Ro9ejS2bNkCLy8vJCUloWfPnhg6dKjoWBZxcXGi\nI9hF1LCAPdRyXk1tnnnmmVq/0RFLoAJK+dTVrl07xMTE4LfffrP8rMSbzLi6umLYsGGK/xSolpuj\nixoWsIdazqupgehF+VgCClevXj3Fr91+69YtbNy4Eb/88guA8ovahg8fDi8vL8HJrFV0c3QlXuAm\naljAHk8++STat2+PtLQ0ALbn1aj6RA/xSn1nsQeZMWMGlixZIjqGasTExMDLy8uyPPeePXtw8+ZN\nxQxdmW+OfvnyZauTwOZ1g6KiogSmIyqXnZ2Nxo0bV7nN0XgkUAGlzW9XuqysLCxbtszyc/v27fGX\nv/xFYCJrark5uuhhgeqYMGFChcOl5plsn332mYBUj4bY2FibCSkVbXM0KUtA1OXZjypfX1+rabU3\nbtyAn5+f4FS/CwwMRGBgIIYMGYKOHTta/W7fvn2KGWoRPSxQHYsWLRId4ZFTXFyM4uJilJaWWk1n\n1uv1lvugO5OUJaDkedhq5O3tjenTp+OJJ54AACQnJyMkJMTyyVYJn2AB4LvvvrN5w69omyjmtfof\nNCygBIGBgZbvy8rKoNPpAJRf1Xz/rCaqngMHDuC7775DQUGB1XRmrVaLIUOGOH3/UpaAGuZhq0mT\nJk2sxtr79+8vMI2t9PR0pKamori42GqJa71er8gLnEQNC9hDDfe6UItBgwZh0KBB2LRpk5AZdlKW\ngBrmYatJVXebEn2Xqfz8fFy4cAEGgwHp6emW7V5eXopaAVX0sIA9zPe6MC91/ssvv+Dzzz/H/Pnz\nBSdTL/PaW/eqjSnMUpaAGuZhP0pE32XKvCDbyZMn0a1bN2E5qiJ6WMAearnXhZpUNIXZPNzmTFKW\ngBrmYT9KlDILuWvXrvjxxx9x+vRpy8/9+/dXzFCg6GEBe6jlXhdqYJ7CrNPpMGvWLMv2e2996kxS\nlgAg5vJsWSnlTfaLL75ARkYG+vbtCwD46aefcPXqVcWcuDYTNSxgj1dffRUxMTE25wTIfqKnMEtV\nAmqYh03Ok5KSgsWLF1vOCT311FOYOXOm4v7eRQ0L2KNNmzaIjY21mh10/13bqHrMU5iXLl0KAJbz\nP7W11LlUf2s8XBVDKcNB9y/N7eLiophsgPhhAXvodDoEBASgWbNmSElJQXJyMp577jlFrm2lFjk5\nOYiNjbUcCbZs2RKTJ0/GY4895tT9ctkIqrHVq1fj1VdffeA2pdyfYe3atbh06ZLVcFCzZs2sDsFF\nunbtGnJzc5GYmIgJEyZYtpuHBTQa5dwNdvr06YiOjkZ+fj7mzZuHrl27orCwkEtw1MD8+fPx9NNP\nWyap7N27FwcOHMDs2bOdul+pjgTudfLkSWRmZuLOnTuWbbxS+OGcO3fOZtvZs2ct3yuhAIDy4b6d\nO3da7icdGhqK5557TnCq34keFrCHRqOBq6srkpOTERERgSFDhmD69OmiY6lacXGxZf0tAHj22Wex\nfft2p+9XyhL44osvkJ6ejqysLISGhuLnn3+2mu5G1XP48GEcPnwYubm5iImJsWy/deuWIofeNBoN\nIiIiFH9luKhhAXuUlpaisLAQx48fx+jRo0XHeSRoNBrodDrL0J9Op6uVoz8pSyA5ORlLlizBzJkz\nMWnSJIwYMQKffvqp6FiqExQUhB49eiAtLc1quWutVovOnTsLTFaxgoICfP755zhz5gwAoFOnTnjt\ntdfg6+srOJm1+Ph49O/f32pYID4+3unDAvZ44YUXMHXqVHTu3BmtW7dGTk4OtFqt6Fiq9qc//Qlz\n5sxBixYtYDKZLPfudjYpS8Dd3d0yQ+Tu3bvw8/PD9evXBadSnxYtWqBFixbo2bOnKk4IrlixAh06\ndLCcq9izZw9WrFihqDdXQNywgD2ee+45q6G0wMBAq9dx9+7dVn8Gqlr37t0RExNjufd527Zta2Uo\nVTlnmmqRp6cnDAYD2rdvj7i4OKxduxbu7u6iY6nWpk2boNfrUVZWhjlz5mDs2LHYt2+f6Fg2CgoK\nMGLECPj5+cHPzw/Dhw9HQUGB6Fg2zMMCZrU1LFAT5nMEZveu0UTKJuWRwJQpU1CnTh2MHTsW27Zt\nQ25urqIuxFGb06dPY9y4cUhOToafnx+mTp2K6OhoxV2F3ahRI5v74gYFBQlOZUvUsIAjcdKh/Y4e\nPYr4+Hi0atUKJpMJq1atwqRJk5x+fxMpS2D16tWYNGkSXF1dsW/fPhQXF6Nx48YYPHiw6Giqdvbs\nWfTq1Qt+fn6KuUoYgOWkdWlpKaZPn46QkBAAwPnz5y3fK4moYQFHUtLfv1qsX78e8+fPt5wYvnLl\nCpYsWcIScAadTgetVosjR46gc+fO+J//+R/87W9/Ywk8JB8fHyQkJCAlJQVDhw5FWVkZjEaj6FgW\n9560DgsLs3z/9NNPi4hDVCE3NzeriwKDgoJqZZhayhIoKysDUP7J9fHHH4e7uzs/udTAlClTsH//\nfoSHh6NevXrIzc3Fiy++KDqWhfnisKp89tlneP31150bphpEDQs4EoeDqs9gMAAAevbsiU2bNqFf\nv34wmUzYs2cPQkNDnb5/KUugcePGWLhwIbKzs/HnP/8ZpaWloiOpmo+PDwYOHAidToesrCwEBwdX\n+41XSczDL6KJGhawl16vx9WrVyu8kYyS7tOgdOPGjbP6+auvvrL62dkXsUpZApGRkUhJSUGLFi3g\n6emJ/Px8vPLKK6JjqRbvMuVYooYF7JGcnIyEhARoNBrExcUhPT0dGzZswMyZMwGUTx+m6rn/Tb+2\nSVkC7u7uVp+qzFMG6eHwLlOOIXpYwB4bNmxAdHQ0Fi5cCACWC8ZIfaQsAXIs3mXKMUQPC9irQYMG\nVj+7ubkJSkI1wRKgGntU7jIl+oIs0cMC9vD09ERhYaFlQsWZM2dQt25dwanoYXApaaqxe88JAOVL\ncSj1nMDp06eRnZ2NgQMHorCwUJFr9atBWloaEhISkJubi+bNm+PKlSuIiopS5N85VY4lQDV26tQp\nNG/eHEVFRQCA+vXrIysrS3GLyG3evBknTpxAQUEBYmNjcf36dfzzn//kuYuHpNfr8euvv8JkMqF9\n+/Y8ElApZS9IQqqQlJQEHx8fNGvWDM2aNYO3tzfWrVsnOpaNgwcPYvbs2Zb1+f39/XHr1i3BqdRL\nq9WiS5cu6NSpE1xdXS0ntkldeE6Aauz+2zZqNBpFXTFs5u7ubnMfXF4k+HCOHDmCNWvWID8/32q7\nms5rUDmWANWYl5cXUlNT0bZtWwDlF10p8cSwv78/zp8/DxcXFxiNRvzf//0fmjRpIjqWKiUlJVnO\n+4g+oU41wxKgGhszZgw+/PBDNG3aFABw+fJlTJs2TXAqW+PHj8eKFStw6dIljB07FiEhIZg8ebLo\nWKrk6+uLNm3aiI5BDsATw+QQJSUl+O233wAA7dq1U/RNZgwGA0wmkyLv3asWBw8eRFZWFnr16mV1\nNTOPrNSHJUDSmD17ts1MoIq2UdW2bt2Kr7/+GvXq1bMMB7m4uGDFihWCk5G9OBxE0rh/oUCj0YiS\nkhJBadTt+++/R2xsrOLuz0z2YwnQI2/Lli349ttvodfrrZaKNhgMeOaZZwQmU6/AwEAWwCOCw0H0\nyNPr9SgpKUFiYiImTJhg2e7l5aXocxdKtnbtWuTn5+Opp56yWjPo3hv4kDqwBIjIbvPmzatw+9y5\nc2s5CdUUS4CkkZeXh6SkJFy8eBF37tyxbOfJTJIZzwmQNFatWoWnn34aFy9exDvvvIMdO3bgscce\nEx1LlZKTkyvczuEg9WEJkDRu3LiBfv364bvvvkO7du3Qpk0bvP/++3j55ZdFR1OdrVu3Wr4vLS1F\nZmYmWrVqxRJQIZYAScO8bpCnpyfy8vJQv359FBcXC06lTveP/V++fBlbtmwRlIZqgiVA0ujQoQNK\nSkowYMAAREVFwc3NDb179xYd65HQpEkTZGRkiI5BD4EnhklKeXl50Ov1aNasmegoqnTvOQGTyYT0\n9HQkJydj0aJFAlPRw+CRAEkjJiYG7777LgAgICDAZhtV373nBDQaDRo1asTXUaVYAiSNnJwcm206\nnU5AEvXj9QCPDpYAPfJ27tyJXbt2QafTYdasWZbter0eQUFBApOpz4OmhppxdpD6sATokdetWzcE\nBQUhMTERY8eOBVA+rVGr1XJNfDvdOwxUEZaA+vDEMElj2bJleOONN+Dq6orp06ejuLgYL730EgYP\nHiw6GpEwvC8cSePKlSvQarVITk5Gp06d8Mknn2Dfvn2iY6lWSkoK1q1bh3Xr1uHUqVOi49BDYgmQ\nNMrKygAAZ8+eRY8ePeDh4cEbzT+kLVu2YN26dahbty7q1q2LNWvW8GIxleI5AZJG48aNsXDhQmRn\nZ+PPf/6zzU1mqPr27duHDz74AF5eXgCA559/HrNnz+bQmgqxBEgakZGRSElJQYsWLeDp6Yn8/Hy8\n8soromOpkslkshQAUH5vBp5eVCeeGCYiu61cuRIA0L9/fwDA7t27YTKZ8NZbb4mMRQ+BJUBEdrt1\n6xY2bdqE06dPAwC6dOmC4cOHw9PTU3AyshdLgIjsNmHCBISGhqJv374ICQkRHYdqgCVARHYrKSnB\ngQMHsHfvXty6dQvh4eEIDw+Hv7+/6GhkJ5YAEdXIpUuXsG3bNuzfvx9ffvml6DhkJ84OIqKHYjQa\nceLECezduxfnzp1DeHi46Ej0EHgkQER2W7NmDQ4dOoSmTZsiPDwcTz75JNzd3UXHoofAIwEispu3\ntzcWLFhguS8DqRePBIiIJMa1g4iIJMYSICKSGEuAiEhiLAEiIon9P5Mv6v+qzgFYAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if using linear kernel, these make sense to look at (not otherwise, why?)\n",
    "print(model.coef_)\n",
    "weights3 = pd.Series(model.coef_[0],index=X_train.columns)\n",
    "weights3.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "nANPYoqN7OuQ",
    "outputId": "e4c4aa1e-7ed4-41ff-9129-253f928eef66"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ML7331\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.862\n",
      "[[4311  293]\n",
      " [ 535  861]]\n"
     ]
    }
   ],
   "source": [
    "# scale attributes by the training set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train) # find scalings for each column that make this zero mean and unit std\n",
    "# the line of code above only looks at training data to get mean and std and we can use it \n",
    "# to transform new feature data\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test)\n",
    "\n",
    "# train the model just as before\n",
    "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(X_train_scaled, y_train)  # train object\n",
    "\n",
    "y_hat = svm_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Mini-Project SVMLR Classification-Copy1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
