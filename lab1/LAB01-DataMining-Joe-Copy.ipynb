{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LAB01-DataMining-Joe-Copy.ipynb","provenance":[],"collapsed_sections":["24YU-KPljDwC","eezSJdUbX8md","oi7ieVxOZdeq"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/jjschueder/7331DataMiningNotebooks/blob/master/lab1/LAB01-DataMining-Joe%20Copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xOfxcWSajDqP"},"source":["# Assignment 1"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tgb7l65KjDqT"},"source":[" ### Team:  \n","Joseph Schueder,\n","Armando Vela,\n","Daniel Clark,\n","Jeff Washburn"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wYk89jjvjDqV"},"source":["##Business Understanding\n","\n","Introduction - The Iowa Liquor Sales dataset is an API from Google’s Bigquery which contains the wholesale purchases by retail stores in the Iowa area.  The dataset includes the spirit purchase details by product, date of purchase, and location the item was purchased from an Iowa Class “E” liquor license holder (retail stores) . The timeframe of this data starts from January 1, 2012 through 2019. As part of the study commissioned by the Iowa Department of Commerce, all alcoholic sales within the state were logged into the Department system, and in turn, published as open data by the State of Iowa. The dataset contains detail on the name, product, quantity and location of the individual container or package sale between the wholesaler (vendor) and the retailer.  \n","\n","1. Set Objectives: We are a whiskey wholesaler and we have targeted the state of Iowa for our market analysis of what opportunities are to sell to retailers around the state. Before doing so, our goal will be to identify and predict what opportunities there are in the Iowa liquor market.  Questions will include, which categories of alcholol are going to sell the most in each market, what parts of the year are going to have higher whiskey sales as opposed to lower whiskey sales to optimize advertising dollars, and what features of a town are defining characteristics of a large whiskey seller. \n","\n","2. Product Project Plan: To meet our goals, we will first use the Google Bigquery API to access the publicly available Iowa Liquor Sales data via python and Jupyter Notebook. Since the dataset is over 17 million lines of data, we will focus 2019 sales the for this analysis. From here, we will define a random subset to grant us 400,000 observations, address missing values and begin to build models that could help us answer questions based on markets likely to sell more whiskey. For our data on times of the year when we will sell more whiskey, we will need to create a subset of a full year’s data to build a time series model. For the town features, we will need to include additional information about the zip codes of Iowa (such as population, income, ect) to get more demographic detail on each market to assist with a program for a clustering problem. For each of these problems, we will create a training and testing data set to help tune our predictions. \n","\n","3. Business Success Criteria - For our prediction models of market sales, we will consider our model successful if we are able to classify our alcohol type with a strong precision, recall, accuracy,  and F1 score using a cross validation. Ideally, if we are dealing with eight alcohol types, we will want to be able to predict whiskey accurately over 12.5% of the time.  \n"," * Classification - 'Introduction to Data Mining' book - pages 173 to 196.  Estimating the generalization error of a model during training. The estimated error helps the learning algorithm to do model selection; i.e., to find a model of the right complexity that is not susceptible to over fitting. Once the model bas been constructed, it can be applied to the test set to predict the class labels of previously unseen records. It is often useful to measure the performance of the model on the test set because such a measure provides an unbiased estimate of its generalization error. The accuracy or error rate computed from the test set can also be used to compare the relative performance of different classifiers on the same domain. However, is order to do this, the class labels of the test records must be known.  Some of the methods commonly used to evaluate the performance of a classifier are.\n","    * Holdout Method In the holdout method, the original data with labeled examples is partitioned into two disjoint sets, called the training and the test sets, respectively. A classification model is then induced from the training set and its performance is evaluated on the test set. The proportion of data reserved for training and for testing is typically at the discretion of the analyst (e.g., 50-50 or two-thirds for training and one-third for testing). The accuracy of the classifier can be estimated based on the accuracy of the induced model on the test set. \n","     * Other methods that may be used Cross-Validation, Random subsampling, and bootstrap. \n"," \n"," * Regression - From the sales prediction problem, we will run a linear regression technique against the remaining features. For this technique, we will use Root Mean Square Error to evaluate the effectiveness. A strong criteria for performance would be if we can get within a certain RMSE. We may also use R-squared as a relative measure of fit and OLS. Reference to SMU MSDS class 6371 Units 9 through 11 will be used for evlaution methods. Lack of fit tests, scatterplot of residual, studentized residuals and other fit diagnostics will all be utilized. \n"," \n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6Ol2Ku56jDqX"},"source":["## Data Meaning Type\n","\n","The initial data set is 4.63GB with 17.7 million rows.  This was too large for our systems to handle, so we took a subset of the data.  Please refer to the Exceptional Work on how we analyzed the full data set, which included a combination of BigQuery queries, and visualizing that data in order to come up with our subset which we saved as a csv file in our github repository"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iIykmxBCrcM7"},"source":["### Load Python Packages"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nbe-oTWwjDqb","colab":{}},"source":["# Import necessary python packages\n","try:\n","    from collections import abc as collections_abc\n","except ImportError:  # Python 2.7\n","    import collections as collections_abc\n","\n","    import copy\n","import functools\n","import gzip\n","import io\n","import itertools\n","import json\n","import math\n","import os\n","import tempfile\n","import uuid\n","import warnings\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import seaborn as sns\n","import numpy as np\n","#import altair as alt\n","import matplotlib.pyplot as plt\n","import re\n","import warnings\n","warnings.simplefilter('ignore', DeprecationWarning)\n","\n","# Imports the Google Cloud client library\n","#from google.cloud import storage\n","from google.oauth2 import service_account\n","from google.cloud import bigquery"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8VzJsCilrxi_"},"source":["### Load Data from github\n","\n","So we will be querying the 2019 data and subsetting a random sample of 400,000 rows within the 2 million sales that happened that year for our analysis"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AN-ug53fjDqq","colab":{}},"source":["# Read csv from disk\n","#df =  pd.read_csv(r'/Users/jjschued/Documents/Github/7331DataMiningNotebooks/lab1/iowa_subset_2019_400k_random_rows.csv', nrows = 100000)\n","#df =  pd.read_csv(r'/Users/danielclark/Desktop/SMU/data_mining/7331DataMiningNotebooks/lab1/iowa_subset_2019_400k_random_rows.csv', nrows = 50000)\n","\n","# read csv from github directly\n","url_dataset = 'https://github.com/jjschueder/7331DataMiningNotebooks/blob/master/lab1/iowa_subset_2019_400k_random_rows.csv?raw=true'\n","#df = pd.read_csv(url_dataset, nrows=50000)\n","df = pd.read_csv(url_dataset)\n","\n","# verify data read in\n","df.head(5)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WynDvfV4zEzj"},"source":["### Columns and Descriptions\n","\n","Below are the 24 columns found in the data set along with description of each "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3ooA9j-SsWrR","colab":{}},"source":["df.info()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-qW1-cqvzf2p"},"source":["Detailed Description of each field - referenced from the [data.iowa.gov](https://data.iowa.gov/Sales-Distribution/Iowa-Liquor-Sales/m3tr-qhgy) site that describes the dataset\n","\n","*   invoice_and_item_number (text) - Invoice and item associated with the liquor order.  This is unique identifier \n","*   date (date) - Date of when the order was placed\n","*   store_number (int) - Unique number assigned to the retail store that placed the order\n","*   store_name (text) - Name of the retail store that placed the order\n","*   address (text) - Address of the retail store that placed the order\n","*   city (text) - City of the retail store that placed the order\n","*   zip_code (float) - Zip code of the retail store that placed the order\n","*   store_location (text) - Lat/Long of retail store that placed the order\n","*   county_number (float) - Iowa county number for which the retail store that placed the order resides\n","*   county (text) - County name for which the retail store is located that placed the order\n","*   category (float) - Category code for the liquor that was ordered\n","*   category_name (text) - Category of the liquor that was ordered\n","*   vendor_number (int) - The vendor number of the company for the brand of liquor ordered \n","*   vendor_name (text) - The vendor name of the company for the brand of liquor ordered\n","*   item_number (int) - Item number for individual liquor product ordered\n","*   item_description (text) - Description of the liquor item ordered\n","*   pack (int) - The number of bottles in a case for the liquor ordered\n","*   bottle_volume_ml (int) - Volume of each liquor bottle ordered in milliliters\n","*   state_bottle_cost (float) - The amount that Alcoholic Beverages Division paid for each bottle of liquor ordered\n","*   state_bottle_retail (float) - The amount the store paid for each bottle of liquor ordered\n","*   bottles_sold (int) - Number of bottles of liquor ordered by the retail store\n","*   sale_dollars (float) - Total cost of liquor ordered (bottles_sold * state_bottle_retail)\n","*   volume_sold_liters (float) - Total volume of liquor ordered in liters (bottle_volume_ml * bottles_sold / 1000)\n","*   volume_sold_gallons (float) - Total volume of liquor ordered in gallons (bottle_volume_ml * bottles_sold / 3785.411784)\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0Pqwl1tXjDqZ"},"source":["## Data Quality  \n","Verify data quality: Explain any missing values, duplicate data, and outliers. Are those mistakes? How do you deal with these problems? Give justifications for your methods.\n","\n","Running a df.columns.values function, confirms the 24 features that we referenced in our Data understanding phase. This now allows us to move forward with our data cleaning. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"J6jgiMesjDq8","colab":{}},"source":["df.columns.values"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vNmrMEbljDrD"},"source":["### Data Cleaning\n","\n","In our data cleaning step, we need to perform a few specific data cleaning operations to:\n","1.   Convert our features to the correct continuous, ordinal and categorical features\n","  * Replace the values for pack, bottle_volume_ml, store_number, store_name, address, city, zip_code, county_number, county, category, category_name, vendor_number, vendor_name, item_number and item_description into categorical variables so they register as a non-null object in our model\n","\n","2.   Address the missing values\n","  *   The data has a few fields that are missing data. These missing values primarily are centered around location related information and liquor categorization. Some cleanup will be done by referencing external sources with store name and item description to infer address information. \n","  *   Replace all \"?\", which our dataset denotes as null, into \"-1\" values (not strings). From here, we will convert state_bottle_cost, state_bottle_retail, sale_dollars, volume_sold_liters, and volume_sold_gallons into continuous variables so they register as floats.\n","\n","3.  Check on duplicates.  \n","4.  Create a category that simplifies our alcohol categories to specific genres like whiskey, vodka, tequilla, ect.\n","5.   Categorize our store locations into a few easily discernable buckets\n","6.   Create a month and date column for opportunities to time and date analysis\n","7.   Convert the varaible \"bottles_sold\" into ordinal features so they register as an integer value in our models  \n","8. Identify outliers and normalize them so that they don't skew our analysis and models.\"\n","\n","Using a df.types function helps to verify this. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"20oVQQRhjDrG","colab":{}},"source":["df.dtypes"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JOs6ROqH7odu"},"source":["The following will do some cleanup on values and categorize store, category, and dates into more summarized values"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VIezayftjDrL","colab":{}},"source":["#upper case category name for matching later\n","df['category_name'] = df['category_name'].str.upper()\n","#df['category_name'][40:45]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xjqMmEus5EYP","colab":{}},"source":["#upper case category name for matching later\n","df['item_description'] = df['item_description'].str.upper()\n","#df['item_description'][40:45]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TyCj4E6HjDrT","colab":{}},"source":["#convert nan to blanks\n","df = (df.replace(r'^\\s*$', np.nan, regex=True))\n","df = (df.replace(np.nan, 'blank', regex=True))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gFfjj_sCUyY9","colab_type":"text"},"source":["### Missing Values  \n","The below section will first look for blank address info. Find the Storenames of those blank addresses and finally assign based on external address research. It becomes obvious that the data entry personnel in LeMars, Ankney and Clear lake require retraining."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hoxmXjaWEK5G","colab":{}},"source":["#blank address info adress info \n","df['counter'] = df['sale_dollars']/df['sale_dollars']\n","dfc = df.copy()\n","dfc = dfc[dfc['address']=='blank']\n","df_grouped = dfc.groupby(by=['store_name'])\n","sales_rateq = df_grouped.counter.sum()\n","dfsr = pd.DataFrame(sales_rateq)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZbwsuWlfVHIi","colab_type":"code","colab":{}},"source":["dfsr.sort_values(by='counter', ascending=False).head(20)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8C1byq4OVN2h","colab_type":"code","colab":{}},"source":["df.loc[df['store_name'] =='Hy-Vee Food Store #2 / State Ankeny', 'address'] = '2510 SW State St'\n","df.loc[df['store_name'] =='Hy-Vee Food Store #2 / State Ankeny', 'city']\t= 'Ankeny'\n","df.loc[df['store_name'] =='Hy-Vee Food Store #2 / State Ankeny', 'zip_code']\t= '50023'\n","df.loc[df['store_name'] =='Hy-Vee Food Store #2 / State Ankeny', 'store_location'] ='POINT (-93.621824 41.705188)'\n","df.loc[df['store_name'] =='Hy-Vee Food Store #2 / State Ankeny', 'county_number'] ='77'\n","df.loc[df['store_name'] =='Hy-Vee Food Store #2 / State Ankeny', 'county'] ='POLK'\n","df.loc[df['store_name'] == 'Quick Shop / Clear Lake', 'address'] = '904 N 8th St'\t\n","df.loc[df['store_name'] == 'Quick Shop / Clear Lake','city']\t= 'Clear Lake'\t\n","df.loc[df['store_name'] == 'Quick Shop / Clear Lake', 'zip_code']\t= '50428'\t\n","\n","df.loc[df['store_name'] == 'Quick Shop / Clear Lake', 'store_location'] ='POINT (-93.378772 43.142868)'\t\n","df.loc[df['store_name'] == 'Quick Shop / Clear Lake', 'county_number'] ='17'\n","df.loc[df['store_name'] == 'Quick Shop / Clear Lake', 'county']= 'Cerro Gord'\n","\n","df.loc[df['store_name'] == 'Lake Liquors Wine and Spirits', 'address'] = '910 Hwy 18 W'\n","df.loc[df['store_name'] == 'Lake Liquors Wine and Spirits', 'city']\t= 'Clear Lake'\t\n","df.loc[df['store_name'] == 'Lake Liquors Wine and Spirits', 'zip_code'] = '50428'\t\n","df.loc[df['store_name'] == 'Lake Liquors Wine and Spirits', 'store_location'] ='POINT (-93.613385 43.105949)'\t\n","df.loc[df['store_name'] == 'Lake Liquors Wine and Spirits', 'county_number'] ='17'\t\n","df.loc[df['store_name'] == 'Lake Liquors Wine and Spirits', 'county'] = 'CERRO GORD'\n","\n","df.loc[df['store_name'] == 'Hy-Vee Wine and Spirits / Algona', 'address'] = '1516 Highway 169'\n","df.loc[df['store_name'] == 'Hy-Vee Wine and Spirits / Algona', 'city']\t= 'North Algona'\t\n","df.loc[df['store_name'] == 'Hy-Vee Wine and Spirits / Algona', 'zip_code']= '50511'\t\n","df.loc[df['store_name'] == 'Hy-Vee Wine and Spirits / Algona', 'store_location'] ='POINT (-94.236003 43.081288)'\t\n","df.loc[df['store_name'] == 'Hy-Vee Wine and Spirits / Algona', 'county_number'] ='55'\t\n","df.loc[df['store_name'] == 'Hy-Vee Wine and Spirits / Algona', 'county'] = 'KOSSUTH'\n","\n","df.loc[df['store_name'] == 'Hy-Vee Wine and Spirits / Lemars', 'address'] = '1201 12th Ave SW'\t\n","df.loc[df['store_name'] == 'Hy-Vee Wine and Spirits / Lemars', 'city']\t= 'Le Mars'\n","df.loc[df['store_name'] == 'Hy-Vee Wine and Spirits / Lemars', 'zip_code']\t= '51031'\t\n","df.loc[df['store_name'] == 'Hy-Vee Wine and Spirits / Lemars', 'store_location'] = 'POINT (-96.18335000000002 42.778257)'\t\n","df.loc[df['store_name'] == 'Hy-Vee Wine and Spirits / Lemars', 'county_number'] = '75'\t\n","df.loc[df['store_name'] == 'Hy-Vee Wine and Spirits / Lemars', 'county'] = 'PLYMOUTH'\n","\n","\n","df.loc[df['store_name'] == 'The Music Station', 'address'] = '2001 West Court'\n","df.loc[df['store_name'] == 'Hometown Foods / Stuart', 'city']\t= 'Cedar Falls'\n","df.loc[df['store_name'] == 'Hometown Foods / Stuart', 'zip_code'] = '50647'\t\n","df.loc[df['store_name'] == 'Hometown Foods / Stuart', 'store_location'] ='POINT (-92.462826 42.537839)'\t\n","df.loc[df['store_name'] == 'Hometown Foods / Stuart', 'county_number'] ='7'\t\n","df.loc[df['store_name'] == 'Hometown Foods / Stuart', 'county'] = 'BLACK HAWK'\n","\n","df.loc[df['store_name'] == 'Hometown Foods / Stuart', 'address'] = '611 S Division St'\n","df.loc[df['store_name'] == 'Hometown Foods / Stuart', 'city']\t= 'Stuart'\t\n","df.loc[df['store_name'] == 'Hometown Foods / Stuart', 'zip_code'] = '50250'\t\n","df.loc[df['store_name'] == 'Hometown Foods / Stuart', 'store_location'] ='POINT (-94.318443 41.49759900000001)'\n","df.loc[df['store_name'] == 'Hometown Foods / Stuart', 'county_number'] ='1'\t\n","df.loc[df['store_name'] == 'Hometown Foods / Stuart', 'county'] = 'Adair'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yNJx11U9VUxr","colab_type":"text"},"source":["The below section will first look for blank liquor category info. Find the Item Descriptions of those blank categories and finally assign based on external market research."]},{"cell_type":"code","metadata":{"id":"pP-1L7SOVUQj","colab_type":"code","colab":{}},"source":["#blank  info category info \n","df['counter'] = df['sale_dollars']/df['sale_dollars']\n","dfc = df.copy()\n","dfc = dfc[dfc['category_name']=='blank']\n","df_grouped = dfc.groupby(by=['item_description'])\n","sales_rateq = df_grouped.counter.sum()\n","dfsr = pd.DataFrame(sales_rateq)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rWhEgFdjXHvF","colab_type":"code","colab":{}},"source":["dfsr.sort_values(by='counter', ascending=False).head(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U_GbINH6XL5Y","colab_type":"code","colab":{}},"source":["#do the cleanup\n","df.loc[df['category_name'].str.contains('blank') & df['item_description'].str.contains('99'), 'category_name'] = 'American Vodkas'\n","df.loc[df['category_name'].str.contains('blank') & df['item_description'].str.contains('Eddy'), 'category_name'] = 'American Vodkas'\n","df.loc[df['category_name'].str.contains('blank') & df['item_description'].str.contains('Rum'), 'category_name'] = 'Flavored Rum'\n","df.loc[df['category_name'].str.contains('blank') & df['item_description'].str.contains('Liquer'), 'category_name'] = 'American Cordials and Liquers'\n","df.loc[df['category_name'].str.contains('blank') & df['item_description'].str.contains('Bourbon'), 'category_name'] = 'Straight Rye Whiskies'\n","df.loc[df['category_name'].str.contains('blank') & df['item_description'].str.contains('Ever'), 'category_name'] = 'Neutral Grain Spirits'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UrbgCVymjDra","colab":{}},"source":["#Start with everything going into Other, and then look for keyword to put into specific category\n","df['liquor_category'] = 'Other'\n","df.loc[df['category_name'].str.contains('GINS'), 'liquor_category'] = 'GIN'\n","df.loc[df['category_name'].str.contains('GINS'), 'liquor_category'] = 'GIN'\n","df.loc[df['category_name'].str.contains('GIN'), 'liquor_category'] = 'GIN'\n","df.loc[df['category_name'].str.contains('RUMS'), 'liquor_category'] = 'RUM'\n","df.loc[df['category_name'].str.contains('RUM'), 'liquor_category'] = 'RUM'\n","df.loc[df['category_name'].str.contains('SCOTCH'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['category_name'].str.contains('WHISKIES'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['category_name'].str.contains('WHISKY'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['category_name'].str.contains('WHISKEY'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['category_name'].str.contains('RYE'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['category_name'].str.contains('AMARETTO'), 'liquor_category'] = 'AMARETTO'\n","df.loc[df['category_name'].str.contains('BOURBON'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['category_name'].str.contains('LIQUEURS'), 'liquor_category'] = 'LIQUEUR'\n","df.loc[df['category_name'].str.contains('LIQUEUR'), 'liquor_category'] = 'LIQUEUR'\n","df.loc[df['category_name'].str.contains('VODKAS'), 'liquor_category'] = 'VODKA'\n","df.loc[df['category_name'].str.contains('VODKA'), 'liquor_category'] = 'VODKA'\n","df.loc[df['category_name'].str.contains('BRANDY'), 'liquor_category'] = 'BRANDY'\n","df.loc[df['category_name'].str.contains('BRANDIES'), 'liquor_category'] = 'GIN'\n","df.loc[df['category_name'].str.contains('CREME'), 'liquor_category'] = 'SCHNAPPS'\n","df.loc[df['category_name'].str.contains('SCHNAPPS'), 'liquor_category'] = 'SCHNAPPS'\n","df.loc[df['category_name'].str.contains('TEQUILA'), 'liquor_category'] = 'TEQUILA'\n","df.loc[df['category_name'].str.contains('TEQUILAS'), 'liquor_category'] = 'TEQUILA'\n","\n","\n","\n","#get a few stray not available categories per internet this is tequila\n","df.loc[df['item_description'] == 'Herradura Gold Reposado 6pak', 'liquor_category'] = \"Tequila\"\n","df.loc[df['item_description'] == 'Chambord Liqueur w/2 Glasses', 'liquor_category'] = \"Liquers\"\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GB_4XzbD5EYe","colab":{}},"source":["#get some others by going to item description and doing same translation as above\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('GINS'), 'liquor_category'] = 'GIN'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('GINS'), 'liquor_category'] = 'GIN'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('GIN'), 'liquor_category'] = 'GIN'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('RUMS'), 'liquor_category'] = 'RUM'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('RUM'), 'liquor_category'] = 'RUM'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('SCOTCH'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('WHISKIES'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('WHISKY'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('WHISKEY'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('RYE'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('AMARETTO'), 'liquor_category'] = 'AMARETTO'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('BOURBON'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('LIQUEURS'), 'liquor_category'] = 'LIQUEUR'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('LIQUEUR'), 'liquor_category'] = 'LIQUEUR'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('VODKAS'), 'liquor_category'] = 'VODKA'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('VODKA'), 'liquor_category'] = 'VODKA'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('BRANDY'), 'liquor_category'] = 'BRANDY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('BRANDIES'), 'liquor_category'] = 'GIN'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('CREME'), 'liquor_category'] = 'SCHNAPPS'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('SCHNAPPS'), 'liquor_category'] = 'SCHNAPPS'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('TEQUILA'), 'liquor_category'] = 'TEQUILA'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('TEQUILAS'), 'liquor_category'] = 'TEQUILA'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('JOSE'), 'liquor_category'] = 'TEQUILA'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('PATRON'), 'liquor_category'] = 'TEQUILA'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('JAMESON'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('CROWN'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('BEAM'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('DANIELS'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('MORGAN'), 'liquor_category'] = 'RUM'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('JOHNNIE WALKER'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('GENTLEMAN'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('1800'), 'liquor_category'] = 'TEQUILA'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('BUSHMIL'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('KNOB'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('TORTILLA'), 'liquor_category'] = 'TEQUILA'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('GOOSE'), 'liquor_category'] = 'VODKA'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('MARGARITA'), 'liquor_category'] = 'TEQUILA'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('TRIPLE SEC'), 'liquor_category'] = 'LIQUEUR'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"83QSdS-Y5EYj","colab":{}},"source":["#upper case category name for matching later\n","df['store_name'] = df['store_name'].str.upper()\n","\n","#df['store_name'][40:45]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MlArdWxEjDrf","colab":{}},"source":["#grouping all the store locations into parent stores\n","df['store_parent'] = 'Other'\n","df.loc[df['store_name'].str.contains('HY-VEE'), 'store_parent'] = 'Hy-Vee'\n","df.loc[df['store_name'].str.contains('WAL-MART'), 'store_parent'] = 'Wal-Mart'\n","df.loc[df['store_name'].str.contains('SAM'), 'store_parent'] = 'SamsClub'\n","df.loc[df['store_name'].str.contains('Fareway'), 'store_parent'] = 'Fareway'\n","df.loc[df['store_name'].str.contains('KUM'), 'store_parent'] = 'Kum&Go'\n","df.loc[df['store_name'].str.contains('CVS'), 'store_parent'] = 'CVS'\n","df.loc[df['store_name'].str.contains('TARGET'), 'store_parent'] = 'Target'\n","df.loc[df['store_name'].str.contains('CASEY'), 'store_parent'] = 'Caseys'\n","df.loc[df['store_name'].str.contains('DAHL'), 'store_parent'] = 'Dahls'\n","df.loc[df['store_name'].str.contains('QUIK'), 'store_parent'] = 'QuikTrip'\n","df.loc[df['store_name'].str.contains('WALGREEN'), 'store_parent'] = 'Walgreens'\n","df.loc[df['store_name'].str.contains('SMOKIN'), 'store_parent'] = 'SmokingJoes'\n","#labored conversion of dates to month year and month year by converting to strings\n","df['month'] = pd.DatetimeIndex(df['date']).month\n","df['year'] = pd.DatetimeIndex(df['date']).year\n","\n","df.loc[df['month'] ==1 , 'month'] = 'Jan'\n","df.loc[df['month'] ==2 , 'month'] = 'Feb'\n","df.loc[df['month'] ==3 , 'month'] = 'Mar'\n","df.loc[df['month'] ==4 , 'month'] = 'Apr'\n","df.loc[df['month'] ==5 , 'month'] = 'May'\n","df.loc[df['month'] ==6 , 'month'] = 'Jun'\n","df.loc[df['month'] ==7 , 'month'] = 'Jul'\n","df.loc[df['month'] ==8 , 'month'] = 'Aug'\n","df.loc[df['month'] ==9 , 'month'] = 'Sep'\n","df.loc[df['month'] ==10 , 'month'] = 'Oct'\n","df.loc[df['month'] ==11 , 'month'] = 'Nov'\n","df.loc[df['month'] ==12 , 'month'] = 'Dec'\n","\n","\n","df.loc[df['year'] ==2012 , 'year'] = '2012'\n","df.loc[df['year'] ==2013 , 'year'] = '2013'\n","df.loc[df['year'] ==2014 , 'year'] = '2014'\n","df.loc[df['year'] ==2015 , 'year'] = '2015'\n","df.loc[df['year'] ==2016 , 'year'] = '2016'\n","df.loc[df['year'] ==2017 , 'year'] = '2017'\n","df.loc[df['year'] ==2018 , 'year'] = '2018'\n","df.loc[df['year'] ==2019 , 'year'] = '2019'\n","\n","#merge year and month together\n","df['monthyear'] = df['month'] + \"-\" + df['year']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5QHtbwKljDrj","colab":{}},"source":["df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LAw13P82jDrn"},"source":["At the far right of the above dataset, you can see the 5 new columns we created and thier respective values. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"shBCdTeDjDro","colab":{}},"source":["# replace '?' with -1, we will deal with missing values later\n","df = df.replace(to_replace='?',value=-1) \n","\n","categorical_features = ['city', 'county',  'category_name','vendor_name', 'store_number', 'item_description','store_parent', \n","                        'monthyear', 'liquor_category', 'county_number', 'vendor_number', 'item_number']\n","\n","# let's start by first changing the numeric values to be floats\n","continuous_features = ['state_bottle_cost', 'state_bottle_retail', 'sale_dollars', 'volume_sold_liters', 'volume_sold_gallons', 'bottles_sold']\n","\n","# and the oridnal values to be integers\n","ordinal_features = ['pack', 'bottle_volume_ml']\n","\n","# use the \"astype\" function to change the variable type\n","df[continuous_features] = df[continuous_features].astype(np.float64)\n","df[ordinal_features] = df[ordinal_features].astype(np.int64)\n","df[categorical_features] = df[categorical_features].astype(object)\n","df.info() # now our data looks better!!"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZPAwJH9AAXaA","colab":{}},"source":["# will get summary of continuous or the nominals\n","dfstats = df.describe()\n","\n","# let's set those values to NaN, so that Pandas understand they are missing\n","df = df.replace(to_replace=-1,value=np.nan) # replace -1 with NaN (not a number)\n","#print (df.info())\n","df[categorical_features] = df[categorical_features].astype(object)\n","dfstats2 = df.describe() # scroll over to see the values\n","\n","categorical_features = ['city', 'county',  'category_name','vendor_name', 'store_number', 'item_description','store_parent', \n","                        'monthyear', 'liquor_category', 'county_number', 'vendor_number', 'item_number']\n","\n","# let's start by first changing the numeric values to be floats\n","continuous_features = ['state_bottle_cost', 'state_bottle_retail', 'sale_dollars', 'volume_sold_liters', 'volume_sold_gallons', 'bottles_sold']\n","\n","# and the oridnal values to be integers\n","ordinal_features = ['pack', 'bottle_volume_ml']\n","\n","# use the \"astype\" function to change the variable type\n","df[continuous_features] = df[continuous_features].astype(np.float64)\n","df[ordinal_features] = df[ordinal_features].astype(np.int64)\n","df[categorical_features] = df[categorical_features].astype(object)\n","df['store_number'] = df['store_number'].astype(object)\n","df.info() # now our data looks better!!"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PQW8ysAkjDry"},"source":["Here, you can see that our cleaning has addressed all nulls down to zero so we can begin analysis. The count code below helps to show that there is zero nulls in our dataset."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RJrfloH2jDr0","colab":{}},"source":["dfna = df[df.isna().any(axis=1)]\n","dfna.isna().sum()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nrorpa8pXb2e","colab_type":"text"},"source":[" ### Check for duplicates\n","\n"," No Duplicates are present"]},{"cell_type":"code","metadata":{"id":"WYQFEB75XZcq","colab_type":"code","colab":{}},"source":["duplicateRowsDF = df[df.duplicated()]\n"," \n","print(\"Duplicate Rows except first occurrence based on all columns are :\")\n","duplicateRowsDF"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nPugj6FkjDr4"},"source":["### Validate Categorical Features\n","\n","The next task will be for us to look into our categorical features with over 30 unique values, and we will be dropping any columns that have more than 30 uniques. The reason we are doing this is that we will ultimately have trouble with our predictions as these values will likely ultimately have unique attributes to a specific combination of observations. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aVall7c0jDr5","colab":{}},"source":["#Unique Value Threshold (Per Column)\n","#Delete Columns >  uniqueThreshold unique values prior to one-hot encoding. \n","#(each unique value becomes a new column during one-hot encoding)\n","uniqueThreshold = 30\n","# in each column of dataframe\n","uniqueValues = df.nunique()\n","uniqueValues"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nliSAAQ8jDr9","colab":{}},"source":["#Isolate continuous and categorical data types\n","#These are indexers into the schoolData dataframe and may be used similar to the schoolData dataframe \n","D_boolean = df.loc[:, (df.dtypes == bool) ]\n","D_nominal = df.loc[:, (df.dtypes == object)]\n","D_continuous = df.loc[:, (df.dtypes != bool) & (df.dtypes != object)]\n","print (\"Boolean Columns: \", D_boolean.shape[1])\n","print (\"Nominal Columns: \", D_nominal.shape[1])\n","print (\"Continuous Columns: \", D_continuous.shape[1])\n","print (\"Columns Accounted for: \", D_nominal.shape[1] + D_continuous.shape[1] + D_boolean.shape[1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9G0uqkV4eBlM","colab_type":"text"},"source":["### One Hot Encoding of Categorical Features"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RnupWglCjDsA","colab":{}},"source":["#Delete categorical columns with > 30 unique values (Each unique value becomes a column during one-hot encoding)\n","oneHotUniqueValueCounts = df[D_nominal.columns].apply(lambda x: x.nunique())\n","oneHotUniqueValueCols = oneHotUniqueValueCounts[oneHotUniqueValueCounts >= uniqueThreshold].index"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PZI-JdDbjDsD","colab":{}},"source":["oneHotUniqueValueCounts\n","oneHotUniqueValueCols"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YA8TwFrrjDsG","colab":{}},"source":["oneHotUniqueValueCols"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NO68ru6ZjDsK","colab":{}},"source":["onehotlist = oneHotUniqueValueCols.tolist()\n","onehotlist"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cRLLyoTQjDsO","colab":{}},"source":["#one hot encoding\n","dfenc = df.copy()\n","dfenc.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JqvYvwLkjDsS","colab":{}},"source":["dfenc.drop(onehotlist, axis=1, inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FG13HsBdjDsX","colab":{}},"source":["dfenc.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oQGMCJocjDsd","colab":{}},"source":["#'month', 'year', 'county_number',\n","#Isolate continuous and categorical data types\n","#These are indexers into the schoolData dataframe and may be used similar to the schoolData dataframe \n","dfenc_boolean = dfenc.loc[:, (dfenc.dtypes == bool) ]\n","dfenc_nominal = dfenc.loc[:, (dfenc.dtypes == object)]\n","dfenc_continuous = dfenc.loc[:, (dfenc.dtypes != bool) & (df.dtypes != object)]\n","print (\"Boolean Columns: \", dfenc_boolean.shape[1])\n","print (\"Nominal Columns: \", dfenc_nominal.shape[1])\n","print (\"Continuous Columns: \", dfenc_continuous.shape[1])\n","print (\"Columns Accounted for: \", dfenc_nominal.shape[1] + dfenc_continuous.shape[1] + dfenc_boolean.shape[1])\n","\n","one_hot_df = pd.concat([pd.get_dummies(dfenc[col],prefix=col) for col in dfenc_nominal.columns], axis=1)\n","one_hot_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"daXDHH8RjDsh","colab":{}},"source":["df1hotmerge = pd.merge(dfenc, one_hot_df, left_index=True, right_index=True)\n","df1hotmerge.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hJ-AExI3jDsl"},"source":["Encoding table has 51 columns "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mj55a9J5jDsn"},"source":["On the one hot encoding dataset, we are going to drop the colums, vendor_number, item_number, and store_number as they will be redundant to other features in our dataset.\n","\n","From here, lets see how big our dataset gets when we onehot our categorical variables. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4v76ILArjDso","colab":{}},"source":["df[df.isnull().any(axis=1)][df.columns[df.isnull().any()]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Yx6ks9cIjDsr","colab":{}},"source":["# this python magics will allow plot to be embedded into the notebook\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore', DeprecationWarning)\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"c_Ea-uAIjDsv","colab":{}},"source":["df['liquor_category'].value_counts()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LSvni7XnjDsy"},"source":["Looking at a quick count of our categories, we can see that Vodka appears the most often in our dataet, at over 150k times followed by Rum with over 95k instances. \n","\n","Below, we created a column called cost_per_liter and isolated the sales that exceeded $30,000. There were 9 total values with the majority being Vodka varieties. However, looking at cost per liter for each, we can see that these sales were driven more by volume rather than by expensiveness of the alcohol."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jVWPMJakjDsz","colab":{}},"source":["# selecting rows based on condition\n","exp_df = df[df['sale_dollars'] > 30000]\n","\n","exp_df['cost_per_liter'] = exp_df['sale_dollars']/exp_df['volume_sold_liters']\n","\n","exp_df[['sale_dollars', 'volume_sold_liters', 'cost_per_liter', 'liquor_category', 'store_parent']]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fpsjeGcmtbyT"},"source":["### Addressing Outliers  \n","As we have seen, some of these alcohol sales are ranging into the tens of thousands of dollars, which would suggest there are outliers int his dataset. To look into this further we are going to review the sales_dollars feature, cost_per_liter feature, state_bottle_cost feature, bottles_sold and volume_sold features. Firstly, running a box plot with sales dollars, we can't really see the boxes due to how the outliers are ranging up to $50,000. To address this we will need to do a log transform on the continuous features with outliers."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"S4GzBUEmjDtN","colab":{}},"source":["# display boxplot of sale_dollars grouped by liquor_category\n","plt.style.use('ggplot')\n","ax = df.boxplot(column = 'sale_dollars', by = 'liquor_category', figsize=(14,7))\n","plt.xticks(rotation=45)\n","ax"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0-KyHIZ-jDtS"},"source":["This box plot is graphing the distribution sale_dollars with the different categories of liquor we have available. Here, we can see there is a significant number of outliers across all categories, so much that you can't really see the boxes on each category. This would suggest we would want to look into a transform."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ALOVk8FkjDtT","colab":{}},"source":["# perform log transformation on sale_dollars due to significant outliers\n","df['sale_dollars_trans'] = np.log(df['sale_dollars'])\n","\n","# display boxplot of logged sale dollars grouped by liquor_category\n","gx = df.boxplot(column = 'sale_dollars_trans', by = 'liquor_category', figsize=(14,7))\n","plt.xticks(rotation=45)\n","gx"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QJG5QRWDjDtX"},"source":["This is much more helpful for us to see how our distribution of categories compares to one another. Vodka and Whiskey are still showing a wider range of outliers, however Liquer tends to have a wider bounding than the other categories, which suggests that it has a wide variety of pricing. On average, tequila looks to have the higher medium sale value, which suggest that more money is being spent on tequilla on average. \n","\n","Using Sales dollars trans will help address outliers in the future."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SLpP2nVPjDtn","colab":{}},"source":["# create new feature of cost_per_liter\n","df['cost_per_liter'] = df['sale_dollars']/df['volume_sold_liters']\n","\n","# display boxplot of cost_per_liter grouped by liquor_category\n","bx = df.boxplot(column = 'cost_per_liter', by = 'liquor_category', figsize=(14,7))\n","plt.xticks(rotation=45)\n","bx"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"X28mjeKajDtr"},"source":["Looking at the cost per liter aggregate column. As we discussed previously, cost per liter is calculated via a calculation of total sales_dollars divided by the total volume_sold_ml. The idea of this calculation is to see the varying price of the liquors if we normalize by the volume and sale of the liquors in our set. \n","\n","Here, we can see that our distribution is right skewed with a large outlier for whiskey which is going for over 1750 per liter. Looking further into this datapoint, we can see that this datapoint represents Johnnie Walker Blue. \n","\n","That said, with the distribution of alcohol types, outside of Johnnie walker blue, we cans see that our cost per liter is going to have a greater than tenfold range, so, i would suggest we create a transform there as well. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"X7EEWHkYjDtt","colab":{}},"source":["df['cost_per_liter_trans'] = np.log(df['cost_per_liter'])\n","\n","zx = df.boxplot(column = 'cost_per_liter_trans', by = 'liquor_category', figsize=(14,7))\n","plt.xticks(rotation=45)\n","zx"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1QIX8VDKjDtv"},"source":["This new box plot shows some interesting insight into the distribution and the value placed on alcohol in our dataset. \n","\n","Gin and Tequilla - even with outliers, it is going to have a faily consistent price per liter. \n","Liquer - Similar case as GIn, however, it's outliers go a little farther out. \n","Other- as expected, has a very wide range with very few outliers. Since this represents all types of alcohol not covered in the other categories, the box plot shape is expected. \n","\n","Whiskey - Has a faily consistent bounding, however the number out outliers on either side is very large and larger than the other categories. "]},{"cell_type":"code","metadata":{"id":"MM-Kd2HeHkpL","colab_type":"code","colab":{}},"source":["#['pack', 'bottle_volume_ml', 'state_bottle_cost', 'bottles_sold', 'sale_dollars_trans', 'volume_sold_liters']\n","\n","# display boxplot of sale_dollars grouped by liquor_category\n","plt.style.use('ggplot')\n","bx = df.boxplot(column = 'state_bottle_cost', by = 'liquor_category', figsize=(14,7))\n","plt.xticks(rotation=45)\n","bx\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PiDay8S-IXN9","colab_type":"code","colab":{}},"source":["df['state_bottle_cost_trans'] = np.log(df['state_bottle_cost'])\n","\n","plt.style.use('ggplot')\n","cx = df.boxplot(column = 'state_bottle_cost_trans', by = 'liquor_category', figsize=(14,7))\n","plt.xticks(rotation=45)\n","cx"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pA0XRxLbIkse","colab_type":"text"},"source":["Looking at state bottle cost, we saw some serious skewing that occured due to outliers, so we decided to transofrm the state bottle cost by the log of the value to help normalize the distribution. Doing so helped to make our box plots cleaner and easier to analyze. \n","\n","Looking at the state bottle cost distribution, we can see there is a similar case with skewing that we would need to transform by the log and create a new category called state_bottle_cost_trans.\n","\n","Next we will do the same thing with the bottles_sold category, which appears to have outliers as well."]},{"cell_type":"code","metadata":{"id":"9b0pnRiCJHnu","colab_type":"code","colab":{}},"source":["# display boxplot of sale_dollars grouped by liquor_category\n","plt.style.use('ggplot')\n","dx = df.boxplot(column = 'bottles_sold', by = 'liquor_category', figsize=(14,7))\n","plt.xticks(rotation=45)\n","dx"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2d70-soeJkDq","colab_type":"code","colab":{}},"source":["df['bottles_sold_trans'] = np.log(df['bottles_sold'])\n","\n","plt.style.use('ggplot')\n","cx = df.boxplot(column = 'bottles_sold_trans', by = 'liquor_category', figsize=(14,7))\n","plt.xticks(rotation=45)\n","cx"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UYh27B4tKrHK","colab_type":"text"},"source":["Next we are going to look at Volume Sold Liters and how that is distributed among our categories. looking at the relationships, we can see there are some outliers that need to be addressed which we will do via a log function. "]},{"cell_type":"code","metadata":{"id":"AJWI_MylK7Ws","colab_type":"code","colab":{}},"source":["# display boxplot of voume sold grouped by liquor_category\n","plt.style.use('ggplot')\n","ex = df.boxplot(column = 'volume_sold_liters', by = 'liquor_category', figsize=(14,7))\n","plt.xticks(rotation=45)\n","ex"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OeU3rXs4LFJR","colab_type":"code","colab":{}},"source":["df['volume_sold_liters_trans'] = np.log(df['volume_sold_liters'])\n","\n","plt.style.use('ggplot')\n","fx = df.boxplot(column = 'volume_sold_liters_trans', by = 'liquor_category', figsize=(14,7))\n","plt.xticks(rotation=45)\n","fx"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zAri_sc2Lj6L","colab_type":"text"},"source":["Now this will be much easier for us to work with. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"49NU7KnojDs5"},"source":["## Simple Statistics\n","\n","The df.describe funciton below provides some simple statistcs for the numeric values in the table. \n","\n","Reviewing the 'pack' & 'bottle_volume_ml' variable statistics, we can see that the average transactional sale was about a 12 pack with 960 ml per bottle.  Furthermore, reviewing the 'state_bottle_cost' and 'state_bottle_retail' variables the average cost per bottle is about 10.22 while the average retail price is 15.35. With that said, this goes to align with what a typical box of liquor bottles tend to look like (at 12 per pack) in which a $5 profit is anticipated per bottle.\n","\n","Another point to consider is the median values are smaller than the mean values. This suggests that our distribution of our sample population is right skewed. \n","\n","Lastly, there are a number of outliers within the dataset in which we may need to perform a log tranformation to address.  For example, the 'sale_dollars' variable has max sale amount of 50,186 but the 75th quartile is only at 152.  Also, within the 'volume_sold_liters\" variable the max amount is 6,615 liters but the 75th quartile is only 10.5 liters.  Further updats will need to be done to identify and address the outliers within our model.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WpWu4zSEjDtD","colab":{}},"source":["df.describe()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7p3RMJXJ4A1m","colab_type":"text"},"source":["To further view and analyze the outliers, the scatter plot below easily shows the sales dollars against volume sold by liters (normalized for outliers).  Also, the table that follows shows the top 10 items listed within sale_dollars and volume_sold liters."]},{"cell_type":"code","metadata":{"id":"ehhkM5CX4A16","colab_type":"code","colab":{}},"source":["# display scatterplot of x=volume_sold_liters, y= sale_dollars\n","plt.style.use('ggplot')\n","sns.scatterplot(x=df.volume_sold_liters_trans, y=df.sale_dollars_trans)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uhMzdVcj4A2E","colab_type":"code","colab":{}},"source":["# top 10 table for sale_dollars\n","df.nlargest(10, 'sale_dollars')['item_description'].reset_index()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H5nZU3lj4A2T","colab_type":"code","colab":{}},"source":["# top 10 table for volume_sold_liters\n","df.nlargest(10, 'volume_sold_liters')['item_description'].reset_index()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"egglMnwDjDtJ"},"source":["Some additional interesting facts can be found in the mode section. Vodka has the largest number of sales, and the small package stores combined take up more sales than a single big-box retailer. \n","\n","The most common pack size is 12 pack, which is efficient for shipping and the most common bottle size is 750 ml. \n","\n","December 2019 is the most popular month for alcohol sales, which suggest that people drink heavily that time of year. :)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ruDObLebjDtF","colab":{}},"source":["dfenc.mode()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2wyCFl6CjDtL"},"source":["## Visualize Attributes\n","The following section shows our cross tabulations of the relationships we found with our 2019 liquor data. The bar charts and box plots are able to show the distribution of our data and a comparative between categorical variables in our set. \n","\n"]},{"cell_type":"code","metadata":{"id":"RX7DP07rXpaw","colab_type":"code","colab":{}},"source":["df['cost_per_liter'] = df['sale_dollars']/df['volume_sold_liters']\n","df['grossmargin'] = 1 - df['state_bottle_cost']/df['state_bottle_retail']\n","df_grouped = df.groupby(by=['liquor_category'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nY4PNTpjXtNk","colab_type":"code","colab":{}},"source":["sales_rateq = df_grouped.bottles_sold.sum()\n","sales_rated = df_grouped.sale_dollars.sum()\n","sales_ratecpl = df_grouped.cost_per_liter.mean()\n","salesgm = df_grouped.grossmargin.mean()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QiJY5JY9XxNi","colab_type":"code","colab":{}},"source":["dfsr = pd.DataFrame(sales_rateq)\n","dfsdol = pd.DataFrame(sales_rated)\n","dfscpl = pd.DataFrame(sales_ratecpl)\n","dfsg = pd.DataFrame(salesgm)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rKRH44asXzJH","colab_type":"code","colab":{}},"source":["salesbyliquor = pd.merge(dfsr, dfsdol, how = 'left', on='liquor_category')\n","salesbyliquor = pd.merge(salesbyliquor, dfscpl, how = 'left', on='liquor_category')\n","salesbyliquor = pd.merge(salesbyliquor, dfsg, how = 'left', on='liquor_category')\n","salesbyliquor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_n39MXoeX2sA","colab_type":"code","colab":{}},"source":["salesbyliquor = salesbyliquor.reset_index()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ciI_vKvijDtz"},"source":["The plots below show various views of the data. The top left shows the grouped average cost per liter by the type of liquor in our dataset. Coming in at over 70 dollars per liter, Liqeuer is the most expensive alcohol in our dataset followed by Whiskey at $45. For Whiskey, some of that can come from the Johnnie Walker Blue we discussed previously, the common theme is that whiskey tends to be more expensive liter for liter than the other types of alcohol.\n","\n","Looking at an aggregate of our different alcohol categories in the top right chart below, we can see that Vodka generated the highest number of sales in our dataset at close to 2.5 million followed by Rum at closer to 1.5 million. This chart seems to show that Vodka and Rum are the two highest-selling alcohols in the state of Iowa in 2019 with Whiskey coming in 3rd. \n","\n","In the bottom right chart the quantity sold by category is shown. While liqeuer had the highest average cost per liter, the vodka tended to have the highest sale quantity per purchase among all the alcohol types. This can be attributed to the volume in which vodka can be made and shipped, which likely affected the volume of sale.\n","\n","On the bottom left, we can see that the gross margin is consistent among all the categories, which suggest that this could be related to a tax associated with the alcohol sales. We do not think profit is included in this database."]},{"cell_type":"code","metadata":{"id":"KghxJTnVX5Mr","colab_type":"code","colab":{}},"source":["fig, axs = plt.subplots(2, 2, figsize=(18, 18))\n","sales_rate = salesbyliquor.sort_values(by='sale_dollars', ascending = False)\n","names = salesbyliquor.sort_values(by='cost_per_liter', ascending=False)['liquor_category'].head(10)\n","values = salesbyliquor.sort_values(by='cost_per_liter', ascending=False)['cost_per_liter'].head(10)\n","names2 = salesbyliquor.sort_values(by='sale_dollars', ascending=False)['liquor_category'].head(10)\n","values2 = salesbyliquor.sort_values(by='sale_dollars', ascending=False)['sale_dollars'].head(10)\n","names3 = salesbyliquor.sort_values(by='grossmargin',  ascending=False)['liquor_category'].head(10)\n","values3 = salesbyliquor.sort_values(by='grossmargin',  ascending=False)['grossmargin'].head(10)\n","names4 = salesbyliquor.sort_values(by='bottles_sold',  ascending=False)['liquor_category'].head(10)\n","values4 =salesbyliquor.sort_values(by='bottles_sold',  ascending=False)['bottles_sold'].head(10)\n","axs[0, 0].bar(names, values)\n","axs[0, 0].set_title('Cost Per Liter')\n","axs[0, 0].set_xticklabels(names, rotation=20, horizontalalignment='right')\n","axs[0, 1].bar(names2, values2)\n","axs[0, 1].set_title('Sales Dollars')\n","axs[0, 1].set_xticklabels(names2, rotation=20, horizontalalignment='right')\n","axs[1, 0].bar(names3, values3)\n","axs[1, 0].set_title('Gross Margin')\n","axs[1, 0].set_xticklabels(names3, rotation=20, horizontalalignment='right')\n","axs[1, 1].bar(names4, values4)\n","axs[1, 1].set_title('Qty Sold')\n","axs[1, 1].set_xticklabels(names4, rotation=20, horizontalalignment='right')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Hiugn1cpjDtm"},"source":["For our stores in our dataset, as we discussed previously, we decided to focus on the big box retailers as our starting point, and lumped in the smaller stores into a category called \"other\". As we can see, the other column drove the greatest overall sales at over 2.5 million, however Hy-Vee in Iowa was a close second at 2.3 million in sales. In the state of Iowa, Hy-Vee is a widely popular grocery store chain sells groceries and alocholic beverages.\n","\n","This same theme is apparent in the QTY sold between retailers in the bottom right. However, interestingly Kum & Go is the retailer with the highest cost per liter. When reviewing the gross margins between the store, our dataset is consistent, which reinforces our hypothesis that this figure represents tax."]},{"cell_type":"code","metadata":{"id":"r28kVx84YIXw","colab_type":"code","colab":{}},"source":["df['cost_per_liter'] = df['sale_dollars']/df['volume_sold_liters']\n","df['grossmargin'] = 1 - df['state_bottle_cost']/df['state_bottle_retail']\n","df_grouped = df.groupby(by=['store_parent'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zn3dZlwHYKaV","colab_type":"code","colab":{}},"source":["sales_rateq = df_grouped.bottles_sold.sum()\n","sales_rated = df_grouped.sale_dollars.sum()\n","sales_ratecpl = df_grouped.cost_per_liter.mean()\n","salesgm = df_grouped.grossmargin.mean()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qST79BCuYMgB","colab_type":"code","colab":{}},"source":["dfsr = pd.DataFrame(sales_rateq)\n","dfsdol = pd.DataFrame(sales_rated)\n","dfscpl = pd.DataFrame(sales_ratecpl)\n","dfsg = pd.DataFrame(salesgm)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"icuP4Cw2YOiD","colab_type":"code","colab":{}},"source":["salesbyparent = pd.merge(dfsr, dfsdol, how = 'left', on='store_parent')\n","salesbyparent = pd.merge(salesbyparent, dfscpl, how = 'left', on='store_parent')\n","salesbyparent = pd.merge(salesbyparent, dfsg, how = 'left', on='store_parent')\n","salesbyparent"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F5bLLDOhYQtI","colab_type":"code","colab":{}},"source":["salesbyparent = salesbyparent.reset_index()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rx3clKiiYV1p","colab_type":"code","colab":{}},"source":["fig, axs = plt.subplots(2, 2, figsize=(18, 18))\n","sales_rate = salesbyparent.sort_values(by='sale_dollars', ascending = False)\n","names = salesbyparent.sort_values(by='cost_per_liter', ascending=False)['store_parent'].head(10)\n","values = salesbyparent.sort_values(by='cost_per_liter', ascending=False)['cost_per_liter'].head(10)\n","names2 = salesbyparent.sort_values(by='sale_dollars', ascending=False)['store_parent'].head(10)\n","values2 = salesbyparent.sort_values(by='sale_dollars', ascending=False)['sale_dollars'].head(10)\n","names3 = salesbyparent.sort_values(by='grossmargin',  ascending=False)['store_parent'].head(10)\n","values3 = salesbyparent.sort_values(by='grossmargin',  ascending=False)['grossmargin'].head(10)\n","names4 = salesbyparent.sort_values(by='bottles_sold',  ascending=False)['store_parent'].head(10)\n","values4 =salesbyparent.sort_values(by='bottles_sold',  ascending=False)['bottles_sold'].head(10)\n","axs[0, 0].bar(names, values)\n","axs[0, 0].set_title('Cost Per Liter')\n","axs[0, 0].set_xticklabels(names, rotation=20, horizontalalignment='right')\n","axs[0, 1].bar(names2, values2)\n","axs[0, 1].set_title('Sales Dollars')\n","axs[0, 1].set_xticklabels(names2, rotation=20, horizontalalignment='right')\n","axs[1, 0].bar(names3, values3)\n","axs[1, 0].set_title('Gross Margin')\n","axs[1, 0].set_xticklabels(names3, rotation=20, horizontalalignment='right')\n","axs[1, 1].bar(names4, values4)\n","axs[1, 1].set_title('Qty Sold')\n","axs[1, 1].set_xticklabels(names4, rotation=20, horizontalalignment='right')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NjeDs_91L6Qb","colab_type":"text"},"source":["Looking back at our box plot distribution of transformed sale price, we can see that gin had the narrowest box plot which suggests that the distrobution is slim between sales. Whiskey had the greatest number of outliers, and Vodka appeared to be most right skewed. Suggesting that there were a lot of outliers driving Vodka sales. "]},{"cell_type":"code","metadata":{"id":"w0x8ry7xMDnc","colab_type":"code","colab":{}},"source":["zx = df.boxplot(column = 'cost_per_liter_trans', by = 'liquor_category', figsize=(14,7))\n","plt.xticks(rotation=45)\n","zx"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3g_g4rQvjDvQ"},"source":["\n","### Store Location Analysis\n","For big box retailers, we focused on Hy-Vee."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vio6XiNRjDvQ","colab":{}},"source":["hv_df = pd.get_dummies(df['store_parent'], drop_first=False)\n","\n","hv_df = pd.concat([df, hv_df], axis = 1, sort=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YBaZgHIBjDvS","colab":{}},"source":["hv_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TRG972dOjDvV","colab":{}},"source":["hv_grouped = hv_df.groupby(by=['liquor_category', 'Hy-Vee']).median()\n","hv_grouped"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C32EuO-chexw","colab_type":"text"},"source":["Look at Hy-Vee in comparison to not Hy-Vee (all other stores)\n","\n","Roughly 280K transactions were attributed to stores other than Hy-Vee while roughly 120k transactions were attributed to Hy-Vee."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ukpUkURmjDvW","colab":{}},"source":["import seaborn as sns\n","cmap = sns.diverging_palette(220, 10, as_cmap=True) # one of the many color mappings\n","sns.countplot(x='Hy-Vee', data=hv_df);"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OHgCzErujDvZ","colab":{}},"source":["chart=sns.catplot(x='liquor_category', col='Hy-Vee', kind='count', data=hv_df)\n","chart.set_xticklabels(rotation=45, ha='right')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lkZnWaoVjDve"},"source":["In the two plots below, we can see the categorical sales tended to remain relatively consistent between Hy-Vee stores as opposed to other liquor stores in the area. This would suggest that Hy-Vee isn't buying liquor differently than anyone else in the state. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aUZvCEz2jDvb","colab":{}},"source":["pd.crosstab(hv_df.liquor_category, hv_df['Hy-Vee'], margins=True).style.background_gradient(cmap='autumn_r')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ynZ8o80ajDvr"},"source":["We were curious to see if HyVee Charged Higher Prices than the competitors. Looking at the cost per liter (which would normalize liquor cost), it appears that Hy-Vee had much higher prices.  "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yKMQd39GjDvf","colab":{}},"source":["sns.catplot('Hy-Vee', \"sale_dollars_trans\", kind='point', data=hv_df)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6oMiRAI7jDvl","colab":{}},"source":["sns.catplot('Hy-Vee', \"cost_per_liter_trans\", kind='point', data=hv_df)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a_-SCsPbgf7-","colab_type":"text"},"source":["However, grouping by category, we can see that this might have been due to the volume of whiskey sales Hy-Vee had compared to non-hy-vee stores. The costs are pretty consistent."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0DO5VlTijDvn","colab":{}},"source":["sns.catplot('Hy-Vee','cost_per_liter_trans',hue='liquor_category', kind='point', data=hv_df);"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jQKI8G0uf7Rj","colab_type":"text"},"source":["Now comparing against Small Liquor stores vs large big-box stores, using the same code as above but with Other instead of Hy-Vee.\n","\n","With 0 being Big Box Stores and 1 Being Small Retailers, we can see that consistently, Small Chains are charging higher prices."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Cj-wAvlvjDvs","colab":{}},"source":["sns.catplot('Other','cost_per_liter_trans',hue='liquor_category', kind='point', data=hv_df);"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"It4qaLANjDvy"},"source":["## Explore Joint Attributes\n","Visualize relationships between attributes: Look at the attributes via scatter plots, correlation, cross-tabulation, group-wise averages, etc. as appropriate. Explain any interesting relationships.  \n","\n","The next section dives deeper into the relationsihps between all the variables in our dataset as well as some of the key relationships found between our features. This will be a starting point for us to better understand if we can begin to think about addressing and removing highly correlated features in our set. \n","\n","To measure this, we will be able to run grid plots and heat maps with each feature against one another. The plots that are highly coorelated will be closer to 1 while the plots that are highly negatively correlated will be closer to -1. \n","\n","Looking at a heat map of our correlation plot, we can see some interesting occurances happening in the bottom right corner with regards to the volume stats as well as the sales stats. We are seeing cases of volume_sold_gallons and liters having a 0.85 correlation to bottles sold. Which makes sense, because the greater the volume of sales would suggest the greater number of bottles in the purchase. \n","\n","In addition, these volume stats are highly correlated at 0.85 to sale dollars. While this is expected as it costs more to get more whiskey, it's interesting as there tends to be somewhwat of a minimal affect with regards to volume discounts. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jxsWqforjDvy","colab":{}},"source":["# plot the correlation matrix using seaborn\n","# https://towardsdatascience.com/visualizing-data-with-pair-plots-in-python-f228cf529166\n","import seaborn as sns\n","cmap = sns.diverging_palette(220, 10, as_cmap=True) # one of the many color mappings\n","\n","# drop the counter attribute as that was used above when dealing with missing values\n","del df['counter']\n","\n","# show the heatmap\n","sns.set(style=\"darkgrid\") # one of the many styles to plot using\n","f, ax = plt.subplots(figsize=(18, 9))\n","chart=sns.heatmap(df.corr(), cmap=cmap, annot=True)\n","chart.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n","f.tight_layout()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2zbUp6pmjDv3"},"source":["To explore our joint attributes, we are going to run a pairplot matrix grouped by liquor category across our key continuous variables.  First, we will look at the raw data, but due to skewness we will need to reference the transformed to get a better sense of the story being told.\n","\n","Here we can see a couple pair scatter plots that show our coorelations in action. In the bottom right corner, we can see those same highly correlated values visualized in a plot, and broken out by drink type.\n","\n","Interestingly, we can see some clustering start to appear in some of the relationships, particularly between rum, vodka and whiskey as it relates to volume sold and sales data."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EyXP7EIJ5Ee_","colab":{}},"source":["sns.pairplot(dfenc, height=3, hue= 'liquor_category', vars = ['state_bottle_retail', 'sale_dollars', 'bottles_sold', 'volume_sold_liters'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vjYUxXcpzJbQ","colab_type":"text"},"source":["In our transformed pairplot, we can see some slight clustering emerge between our categories and bottles sold, sales and volume sold"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TyiuNfD660hm","colab":{}},"source":["sns.pairplot(df, height=3, hue= 'liquor_category', vars = ['state_bottle_retail', 'sale_dollars_trans', 'bottles_sold_trans', 'volume_sold_liters_trans'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ne6mznuv5EfB","colab":{}},"source":["sns.pairplot(df, height=3, hue= 'liquor_category', vars = ['cost_per_liter_trans', 'sale_dollars_trans'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HT_1JUETjDv6"},"source":["Next, we are going to look at a cross tab and explore the relationships with alcohol type and store.\n","\n","As you can see in the table above, Hy Vee and Other take up the majority of sales, however Other is a stronger Vodka seller while Hyvee sales more whieksy. This is confirmed below with our chart that shows the mix of alcohol sales int he story. For each, Vodka and whiskey are among the top sellers. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZK-8JxsDjDv4","colab":{}},"source":["#cross tab example\n","dfcross = pd.crosstab(df['liquor_category'], df['store_parent'],  margins=True, margins_name=\"Total\")\n","dfcross"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8kh09C0UjDv6","colab":{}},"source":["#Normalized Cross Tab\n","dfcrossnorm = pd.crosstab(df['liquor_category'], df['store_parent'], normalize='columns')\n","dfcrossnorm"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dqD4PPi9jDv_"},"source":["Below is a heatmap showing the concentration of categorical sales around the stores. Vodka is a strong seller in Others followed by Rum and Liqueur "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"A0HQdT1pjDv9","colab":{}},"source":["\n","fig, ax = plt.subplots(figsize=(14,7))\n","chart=sns.heatmap(pd.crosstab([df['liquor_category']], [df['store_parent']]),\n","            cmap=\"YlGnBu\", annot=True, cbar=False, fmt='g')\n","chart.set_xticklabels(chart.get_xticklabels(), rotation=45, horizontalalignment='right')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"W4IdsNgRjDwB"},"source":["## Explore Attributes and Class\n","\n","Refining market to whiskey to gather further information about whiskey vendors. Since our analysis is going to focus strictly on whiskey sales, it will be important to see how the whiskey distribution looks within our dataset.\n","\n","Our goal of exploring attributes and class was to see if there were any relationships between Whiskey purchases and variables within the dataset.  First we analyzed whether or not Whiskey was purchased against 'store_parents' after we analyzed based on location, by county then city.\n","\n"]},{"cell_type":"code","metadata":{"id":"0rtVFziA4A-0","colab_type":"code","colab":{}},"source":["explore_df= df.copy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"He6QXWgk4A-3","colab_type":"code","colab":{}},"source":["explore_df['WHISKY_Y_N'] = 0\n","explore_df.loc[explore_df['liquor_category'].str.contains('WHISK'), 'WHISKY_Y_N'] = 1\n","explore_df.head(5)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l1c3yu0j4A-9","colab_type":"text"},"source":["After reviewing the table below, it is interesting to note that when Whiskey is purchased it is in packs less then 10.  Also, the average sale_dollars for a whiskey purchase is much greater than non-whiskey purchases.  This is further pointed in out in the average state_bottle_costs.\n","\n","Lastly, whiskey purchases tend to have a lower average volume sold then non-whiskey purchases."]},{"cell_type":"code","metadata":{"id":"417fUSih4A_B","colab_type":"code","colab":{}},"source":["explore_df.groupby('WHISKY_Y_N').mean()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1fcsGNGv4A_U","colab_type":"text"},"source":["Based on the table below, Target, Sams Club, & Hy-vee have the highest means when it comes to selling Whiskey in their stores.  In other words, of all the liquor transactions processed within these stores there is about 14 percent chance it is associated to a Whiskey purchase."]},{"cell_type":"code","metadata":{"id":"KsmKovti4A_V","colab_type":"code","colab":{}},"source":["explore_df.groupby('store_parent').mean()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Eia8Aosn4A_W","colab_type":"text"},"source":["As you can see within the table below most whiskey purchases occur in Polk county, with Linn, Johnson, Scott, and Black Hawk following."]},{"cell_type":"code","metadata":{"id":"Zd9UbRZs4A_p","colab_type":"code","colab":{}},"source":["large_county_df = explore_df.groupby('county').sum().reset_index()\n","large_county_df.nlargest(5, 'WHISKY_Y_N')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BSbZcHAY4BAC","colab_type":"text"},"source":["To further breakdown the location of whiskey purchases, we can see that Des Moines leads all other cities with Cedar Rapids coming in second."]},{"cell_type":"code","metadata":{"id":"wsCBxHig4BAC","colab_type":"code","colab":{}},"source":["large_county_df = explore_df.groupby('city').sum().reset_index()\n","large_county_df.nlargest(5, 'WHISKY_Y_N')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"roi_RYIejDt-"},"source":["### Whiskey Specific Analysis\n","\n","The first thing we are going to do is copy the original df into a dfwhiskey dataframe.  After we will be filtering for only the 'WHISKY' liquor category.  Note, the new dfwhiskey datafram should have the same features of the original df except it is only filtered for 'WHISKY' specific transactions. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"x3Kg3j51jDt_","colab":{}},"source":["# copy original df into dfwhiskey dataframe\n","dfwhiskey = df.copy()\n","\n","#filter for only the 'WHISKY' liquor_category\n","dfwhiskey = dfwhiskey[dfwhiskey['liquor_category']=='WHISKY']\n","\n","# Here's the head of our dataset so we can see how it looks\n","dfwhiskey.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iYrPI_azjDuK"},"source":["Next, we are going to do a series of calculations to add new columns to our dataset which provides some insight to the sales data of our whiskies. \n","\n","These include the following new features:\n","- profit = state_bottle_retail / bottles_sold\n","- totalcost = state_bottle_cost * bottles_sold\n","- revenue = state_bottle_retail * bottles_sold\n","- grossmargin = (revenue - totalcost)/revenue\n","\n","Ultimately, this is going to give us a clear view of the profatability, and the market size of whiskey so we can better analyze and predict within the dataset."]},{"cell_type":"code","metadata":{"id":"G2LLDc8p7yVG","colab_type":"code","colab":{}},"source":["#do some calculations for cost and profit\n","dfwhiskey['profit'] = dfwhiskey['state_bottle_retail']*dfwhiskey['bottles_sold'] - dfwhiskey['state_bottle_cost']* dfwhiskey['bottles_sold']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"enGon798jDuS","colab":{}},"source":["dfwhiskey['totalcost'] = dfwhiskey['state_bottle_cost']* dfwhiskey['bottles_sold']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TXsMcziQjDuU","colab":{}},"source":["dfwhiskey['revenue'] = dfwhiskey['state_bottle_retail']*dfwhiskey['bottles_sold']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"V7NhUuLbjDuX","colab":{}},"source":["dfwhiskey['grossmargin'] = (dfwhiskey['revenue'] - dfwhiskey['totalcost']) / dfwhiskey['revenue']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"j7XdUU7IjDua"},"source":["Here, we sorted gross margin of sale within our data set to get a clearer view of how margins tend to look within the sales in our dataset. \n","\n","As we can see, there is a 33% margin that appears across almost all of our sales when you calculate the percentage of what is remaining from the cost over the revenue. We are thiking that is a standard state tax cost for whiskies in the state of Iowa."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"l1-jYNz1jDua","colab":{}},"source":["#lets do the transforms we did earlier in the EDA\n","dfwhiskey['sale_dollars_trans'] = np.log(dfwhiskey['sale_dollars'])\n","dfwhiskey['cost_per_liter_trans'] = np.log(dfwhiskey['cost_per_liter'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"79VWZd8bjDud","colab":{}},"source":["dfwhiskey.sort_values(by='grossmargin', ascending=False).head(5)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0QuMFJUBjDuk"},"source":["Looking at more grossmargin values, we still see the same 33%"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eXK4CSyIjDuk","colab":{}},"source":["dfwhiskey.head(5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"m3pptMnmjDup","colab":{}},"source":["df_grouped = dfwhiskey.groupby(by=['vendor_name'])\n","df_grouped.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6gtu-qb-jDur"},"source":["To look into some aggregate sums within our whiskey dataset, we are going to create new varuables for the sum of bottles sold and sale_dollars, as well as the mean of cost per liter and gross margin. \n","\n","Also, we will create datagrames for each so we can see how the whiskey's distribute in these aggregate figures."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"i330X3MTjDus","colab":{}},"source":["sales_rateq = df_grouped.bottles_sold.sum()\n","sales_rated = df_grouped.sale_dollars.sum()\n","sales_ratecpl = df_grouped.cost_per_liter.mean()\n","salesgm = df_grouped.grossmargin.mean()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"87wvUjrVjDuu","colab":{}},"source":["dfsr = pd.DataFrame(sales_rateq)\n","dfsdol = pd.DataFrame(sales_rated)\n","dfscpl = pd.DataFrame(sales_ratecpl)\n","dfsg = pd.DataFrame(salesgm)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"d9yiq4tSjDux","colab":{}},"source":["dfsr.sort_values(by='bottles_sold', ascending=False).head(10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qJ0bRdANjDu0"},"source":["Looking at the top 10 bottles sold in the whiskey category, we can see that the number one on the list is Pernod Ricard at over 100k bolttles sold, followed distantly by Dieago Americas at 29,500. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9zxAOTP7jDu1","colab":{}},"source":["dfsdol.sort_values(by='sale_dollars', ascending=False).head(10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-QJ1zyZJjDu4"},"source":["As a function of bottles sold, we are seeing a similar distirbution with regards to sale_dollars in our top whiskies. Pernod Richard is nearing 3 million dollars in sales followed by Diageo Americas that is under 2 million dollars in sales. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"POc4h9QGjDu5","colab":{}},"source":["dfscpl.sort_values(by='cost_per_liter', ascending=False).head(10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cPoGmXKXjDu8"},"source":["Interestingly, looking at the high cost per liter vendors, Pactific Edge Wine and Spirits has the highest cost per liter at over 145 dollars, followed by Impex Beverage and Hotaling at just under 125 dollars. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"89F7W-rCjDu8","colab":{}},"source":["salesbyvendor = pd.merge(dfsr, dfsdol, how = 'left', on='vendor_name')\n","salesbyvendor = pd.merge(salesbyvendor, dfscpl, how = 'left', on='vendor_name')\n","salesbyvendor = pd.merge(salesbyvendor, dfsg, how = 'left', on='vendor_name')\n","salesbyvendor"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BQnHcYq6jDu-"},"source":["Next, we are going to merge our datasets so that we can group our measures of bottles sold, sale_dollars, cost_per_liter and gross margin by our 61 vendors, so we can see how they rank in our key finance values. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fJ0F-yxYjDu_","colab":{}},"source":["salesbyvendor.sort_values(by='cost_per_liter', ascending=False).head(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fKVoB6pojDvD","colab":{}},"source":["salesbyvendor.sort_values(by='sale_dollars', ascending=False).head(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YBndy3y_jDvJ","colab":{}},"source":["salesbyvendor.sort_values(by='grossmargin', ascending=False).head(100)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v_E-L_-jZT9d","colab_type":"text"},"source":["Below are some additional plots to help you visualize a more complete dataset on cost per liter as well as sales dollar of our specific whiskies in the study. As discussed before, the Pernod Richard whiskey is the top selling vendor,while Pacific Edge Whiskey has the highest cost per liter, implying they are seeling the most valuable whiskey."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"T7ULXUPItb32","colab":{}},"source":["salesbyvendor = salesbyvendor.reset_index()\n","\n","fig, axs = plt.subplots(2, 2, figsize=(18, 18))\n","sales_rate = salesbyvendor.sort_values(by='sale_dollars', ascending = False)\n","names = salesbyvendor.sort_values(by='cost_per_liter', ascending=False)['vendor_name'].head(10)\n","values = salesbyvendor.sort_values(by='cost_per_liter', ascending=False)['cost_per_liter'].head(10)\n","names2 = salesbyvendor.sort_values(by='sale_dollars', ascending=False)['vendor_name'].head(10)\n","values2 = salesbyvendor.sort_values(by='sale_dollars', ascending=False)['sale_dollars'].head(10)\n","names3 = salesbyvendor.sort_values(by='grossmargin',  ascending=False)['vendor_name'].head(10)\n","values3 = salesbyvendor.sort_values(by='grossmargin',  ascending=False)['grossmargin'].head(10)\n","names4 = salesbyvendor.sort_values(by='bottles_sold',  ascending=False)['vendor_name'].head(10)\n","values4 =salesbyvendor.sort_values(by='bottles_sold',  ascending=False)['bottles_sold'].head(10)\n","axs[0, 0].bar(names, values)\n","axs[0, 0].set_title('Cost Per Liter')\n","axs[0, 0].set_xticklabels(names, rotation=20, horizontalalignment='right')\n","axs[0, 1].bar(names2, values2)\n","axs[0, 1].set_title('Sales Dollars')\n","axs[0, 1].set_xticklabels(names2, rotation=20, horizontalalignment='right')\n","axs[1, 0].bar(names3, values3)\n","axs[1, 0].set_title('Gross Margin')\n","axs[1, 0].set_xticklabels(names3, rotation=20, horizontalalignment='right')\n","axs[1, 1].bar(names4, values4)\n","axs[1, 1].set_title('Qty Sold')\n","axs[1, 1].set_xticklabels(names4, rotation=20, horizontalalignment='right')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"24YU-KPljDwC"},"source":["## New Features\n","\n","Some of the new features that we would like to join in on this data would be census data.  There might be good information correlated between education, population, income groups, age groups, employment that could help classifying which retailers are more likely to sell greater volumes of whiskey.  Because there is so many different types of liquor (over 130 category names), we created a new feature, liquor_category that generalizes the liquor.  This way we can look at whiskey in a general sense against the other liquors.  Also, a new feature that could be created from existing data would be the day of the week from the sale date.  Would use the day of the week to look at sales from a weekday perspective (Monday, Tues...Sat, Sun) perspective.  This way we can aggregate the sales by day of week to help on logistics and prevent stock outs.  Below is the list of new features called out: \n","* Day of the week  \n","* Education  \n","* Median population  \n","* Income groups  \n","* Age groups  \n","* Employment  \n","* Grouping of Liquor Brands  \n","\n","We also created a series of columns which were aggregates of other columns.  These new features were added to provide more insight into the sales data to give better view of the profatability, and the market size of whiskey so we can better analyze and predict within the dataset\n","\n","* Cost Per Liter\n","  * cost_per_liter = sale_dollars / volume_sold_liters\n","  * This helps normalize the costing structure of each of the liquor and have a standard view on pricing.  Since the sale_dollars is based on the number of bottles sold * retail price, we weren't able to compare the cost of liquor effectively\n","* Total Cost\n","  * totalcost = state_bottle_cost * bottles_sold\n","  * Provides total cost of the whiskey and will be used in determining our operating margin\n","* Revenue \n","  * revenue = state_bottle_cost * bottles_sold\n","  * Need to see how much revenue is being generated.  Basic metric used in running any business\n","* Gross Margin\n","  * grossmargin = (revenue - totalcost)/revenue\n","  * Need to see how profitable we are doing in whiskey sales\n","* Log Transform of Sales\n","  * The sale_dollars is heavily right skewed, so performing a log transformation on the data helps normalize the data.\n","* Log Transform of Volume Sold\n","  * The volume_sold_liters is heavily right skewed, performed a log transform on this data as well to normalize the data.\n","* Log Transform of Bottles sold\n","  * The bottles_sold feature with a log transform applied so that it normalizes the distribution\n","* Log Transform of Cost Per Liter\n","  * The Cost_per_liter feature with a log transform applied to normalize the distribution\n","\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HZxUFND0jDwD"},"source":["## Exceptional Work \n","Work that we would like to be evaluated as exceptional work would be what we did around the areas of:\n"," * Tableau Location Analysis\n"," * Feature Reduction using PCA and LDA as well as dropping highly correlated variables\n"," * Time series analysis across the entire 2012 to 2019 dataset via big query\n"," * One hot encoding done on the data \n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wfTlL-Kgtb5M"},"source":["### Tableau Location Analysis\n","We built a tableau dashboard out of the 2019 iowa dataset with interative maps of where the most volume of alcohol was sold as well as the a time series analysis of sales and volume by date over 2019. The map features a caption with the analysis of the visuals.\n","\n","https://public.tableau.com/profile/daniel.clark1522#!/vizhome/WhiskeySaleStory/Story1?publish=yes"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"w6Qf4JChtb5M","colab":{}},"source":["### Remove highly correlated features"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-sRVYJlX5EfZ","colab":{}},"source":["df_corr = df.copy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CU3cnnJP5Efl","colab":{}},"source":["df_corr.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"00iACfhI5Efm","colab":{}},"source":["\n","# Create correlation matrix\n","corr_matrix = df_corr.corr().abs()\n","corr_matrix"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0D6IH9iU5Efo","colab":{}},"source":["upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n","\n","# Select upper triangle of correlation matrix\n","upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n","\n","# Find index of feature columns with correlation greater than 0.95\n","to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n","\n","# courtesy of https://chrisalbon.com/machine_learning/feature_selection/drop_highly_correlated_features/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ekMnenpX5Efs","colab":{}},"source":["to_drop"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"euFQv5HU5Efv"},"source":["Looking at our correlation matrix, we can deem that per our criteria of removing features that have a greater than 95% correlation. As the predictability of one feature will detirmine another, which will cause us to want to do a dimensionality reduction. \n","In our case, we are going to remove state_bottle_retail as it correlates highly with state_bottle_cost, as well as volume_sold_gallons as it correlates perfectly with volume_sold_liters."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5_PKuOOr5Efv","colab":{}},"source":["# Drop features \n","df_corr = df_corr.drop(df_corr[to_drop], axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"em7qXL875Ef1"},"source":["### Feature Reduction using PCA and LDA\n","PCA\n","To run a PCA analysis, we will want to first remove some of the highly correlated variables which may throw off our analysis. This will mean we should run a correlation plot and set our correlation threshold to 0.95, which we will remove variables if we exceed. \n","\n","First lets take a look at our seaborn plot that we will use to run principal component analysis. To get started, we will want to create dummies for each of our categories of alcohol, so that we have a single binary under Whiskey as the sale was a whiskey drink (1) or it was not (0)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8_XjsXjR5Ef4","colab":{}},"source":["df_corr2 = pd.get_dummies(df['liquor_category'], drop_first=False)\n","\n","df_corr = pd.concat([df_corr, df_corr2], axis = 1, sort=False)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6_JtFvSq5Ef5","colab":{}},"source":["# now let's use PCA, and LDA to find the two \"best\" dimensions of this data\n","# these are linear transforms to help project the features into something more understandable\n","\n","from sklearn.decomposition import PCA\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n","\n","#drop the response variable from x\n","# one hot encoding to category\n","features = ['pack', 'bottle_volume_ml', 'state_bottle_cost', 'bottles_sold', 'sale_dollars_trans', 'volume_sold_liters']\n","\n","X = df_corr.loc[:, features].values\n","# run this second line below which compiles all the features that i want to use to predict category, or the column we want to predict\n","#X = X.drop (category, inplace = True)\n","y = df_corr.loc[:, ['WHISKY']].values\n","#target_names = df_corr.store_parent_names\n","\n","pca = PCA(n_components=2)\n","X_pca = pca.fit(X).transform(X) # fit data and then transform it\n","\n","lda = LDA(n_components=2)\n","X_lda = lda.fit(X, y).transform(X) # fit data and then transform it\n","\n","# print the components\n","\n","print ('pca:', pca.components_)\n","print ('lda:', lda.scalings_.T)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Mas915a25Ef7"},"source":["Now what we did here was isolate our categorical variable \"Whiskey\" and fit a pca and LDA model using the continuous variables remaining in the set. Using this, our model will be able to advise on how much we can explain variance using the different principal components. \n","Scaling it in this way allows our model to utilize and compare all variables on the same plane. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PpoY348h5Ef8","colab":{}},"source":["principalDf = pd.DataFrame(data = X_pca\n","             , columns = ['principal component 1', 'principal component 2'])\n","\n","principalDf.describe()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WMSsyY8N5Ef-"},"source":["creating a dataframe of our principal components, we can see that there is quite a range in the values we have, from the negatives to the positives, with also a strong standard deviation. \n","The mean principal component is nearly off the scale due to the effect of outliers. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KGoVUc4E5Ef-","colab":{}},"source":["finalDf = pd.concat([principalDf, df_corr[['WHISKY']]], axis = 1)\n","\n","finalDf.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WkYsmLNM5EgA","scrolled":true,"colab":{}},"source":["fig = plt.figure(figsize = (10,10))\n","ax = fig.add_subplot(1,1,1) \n","ax.set_xlabel('Principal Component 1', fontsize = 15)\n","ax.set_ylabel('Principal Component 2', fontsize = 15)\n","ax.set_title('2 component PCA', fontsize = 20)\n","targets = ['Whiskey', 'Not Whiskey']\n","colors = ['r', 'g', 'b']\n","for target, color in zip(targets,colors):\n","    indicesToKeep = finalDf['WHISKY'] == 0\n","    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n","               , finalDf.loc[indicesToKeep, 'principal component 2']\n","               , c = color\n","               , s = 40)\n","ax.legend(targets)\n","ax.grid()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Q5O6IxeL5EgE"},"source":["Looking at the plot we graphed, we can see the effect of outliers and the fact that non/whiskies have quite a presence in our chart. \n","Our explained variance ratio below shows that we can explain 97% of the variance with one principal component, and less than 3% with the second principal component."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8OytcxnA5EgG","colab":{}},"source":["pca.explained_variance_ratio_"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lk9VZJYX5EgI","colab":{}},"source":["#lets transform our outliers to make them easier to read. \n","\n","finalDf2 = finalDf\n","\n","finalDf2['principal component 1 trans'] = np.log(finalDf['principal component 1'])\n","finalDf2['principal component 2 trans'] = np.log(finalDf['principal component 2'])\n","\n","finalDf2.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5pxZqVRO5EgL","colab":{}},"source":["fig = plt.figure(figsize = (10,10))\n","ax = fig.add_subplot(1,1,1) \n","ax.set_xlabel('Principal Component 1', fontsize = 15)\n","ax.set_ylabel('Principal Component 2', fontsize = 15)\n","ax.set_title('2 component PCA', fontsize = 20)\n","targets = ['Whiskey', 'Not Whiskey']\n","colors = ['r', 'g', 'b']\n","for target, color in zip(targets,colors):\n","    indicesToKeep = finalDf2['WHISKY'] == 1\n","    ax.scatter(finalDf2.loc[indicesToKeep, 'principal component 1 trans']\n","               , finalDf2.loc[indicesToKeep, 'principal component 2 trans']\n","               , c = color\n","               , s = 40)\n","ax.legend(targets)\n","ax.grid()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9AZhzuhe5EgQ"},"source":["To make our chart easier to read, i decided to take a transform of our principal components to normalize their distribution. As you can see, their values separate a lot more in our dataset. However, the non whiskey values play a small presence."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6ZSaWnyJrmFn"},"source":["### Time series analysis across the entire 2012 to 2019 dataset via big query\n","\n","Registered for credentials with Google Cloud and Big Query to be able to query our database and data frame from 17 million datapoints for analysis on our project. \n","\n","In our Visualize Attributes section, we went into a deep dive on the analysis of whiskey as well as Hy-Vee to understand their effect on the dataset.\n","\n","Because the dataset is so large, 17.7 million rows and over 4GB in size, we couldn't pull the entire dataset from BigQuery into Pandas.  \n","\n","So, initial analysis of the entire dataset was done by querying BigQuery\n","\n","First needed to connect to BigQuery, then do a some EDA against the data set by querying BigQuery and visualize those results to determine a good subset of the data."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ryNSlAW1jDqj","colab":{}},"source":["import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore', DeprecationWarning)\n","%matplotlib inline\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","project_id = 'smu-7331-ml'\n","\n","plt.rc('axes', axisbelow=True)\n","\n","# Imports the Google Cloud client library\n","#from google.cloud import bigquery\n","# Instantiates a client for BigQuery Service\n","#bqclient = bigquery.Client()\n","\n","from google.colab import auth\n","auth.authenticate_user()\n","print('Authenticated')\n","\n","from google.cloud import bigquery\n","bqclient = bigquery.Client(project=project_id)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eezSJdUbX8md"},"source":["**Functions**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XXPZZ0DfYDr6"},"source":["**Execute Query** "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"C5HarRC4YFom","colab":{}},"source":["def execute_query(QUERY):\n","    # Run the query and get data from BQ\n","    query_job = bqclient.query(QUERY)\n","    return query_job.to_dataframe()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kE6hFp51YNVj"},"source":["**Exploratory Data Analysis**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2tjdVPbEYX4S"},"source":["**Total data size and column types**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DFKt5Fm3YPsd","colab":{}},"source":["QUERY=\"\"\"\n","    SELECT\n","        count(*) as TotalRows\n","    FROM `bigquery-public-data.iowa_liquor_sales.sales`\n","\"\"\"\n","df=execute_query(QUERY)\n","df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0k8IaWC_Ygqt"},"source":["**Get Columns and Data Types for Columns**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"il3uqQJDYlBi","colab":{}},"source":["QUERY=\"\"\"\n","    SELECT\n","        *\n","    FROM `bigquery-public-data.iowa_liquor_sales.sales`\n","    LIMIT 10\n","\"\"\"\n","df=execute_query(QUERY)\n","df.info()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5I8uQvziYoTK","colab":{}},"source":["pd.set_option('display.max_columns', None)\n","df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wO7-cZAMYxhj"},"source":["Look at distribution of data for each Year-Month"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bWerueFLY2XQ","colab":{}},"source":["# How many rows of data for each month for each year \n","QUERY=\"\"\"\n","SELECT\n","    extract(YEAR from date) as year,\n","    extract(MONTH from date) as month,\n","    count(*) as count\n","FROM `bigquery-public-data.iowa_liquor_sales.sales`\n","group by year, month\n","order by year, month\n","\"\"\"\n","df = execute_query(QUERY)\n","\n","# Plot the results\n","df['period'] = df['year'].map(str) +'-' +df['month'].map(str)\n","#df.groupby(['year', 'month'])['count'].sum().plot(kind='bar', figsize=(20, 8))\n","plot=df.plot(kind='bar', x='period', y='count', figsize=(20,8))\n","#xtick = pd.date_range( start=ts.index.min( ), end=ts.index.max( ), freq='W' )\n","#plot.set_xticks( xtick, minor=True )\n","#plot.grid('off', which='minor', axis='y' )\n","plot.grid('on', axis='y', linestyle='dashed')\n","plt.yticks(np.arange(0, max(df['count']+10000), 20000))\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qfg7V5mPZBsu"},"source":["**Determine the different liquor categories**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ObnMcGEWY9yA","colab":{}},"source":["# How many rows of data for each month for each year \n","QUERY=\"\"\"\n","SELECT\n","    category_name,\n","    count(*) as count\n","FROM `bigquery-public-data.iowa_liquor_sales.sales`\n","group by category_name\n","order by category_name\n","\"\"\"\n","df = execute_query(QUERY)\n","df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VnWQgT1AZNMe"},"source":["Group vodka, rum, whiskey, tequila as separate categories, and everything else as other"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hpstJn3HZHsH","colab":{}},"source":["QUERY=\"\"\"\n","SELECT\n","CASE\n","  WHEN lower(category_name) like '%rum%' then 'Rum'\n","  WHEN lower(category_name) like '%whisk%' then 'Whiskey'\n","  WHEN lower(category_name) like '%vodka%' then 'Vodka'\n","  WHEN lower(category_name) like '%tequila%' then 'Tequila'\n","  WHEN lower(category_name) like '%schnapps%' then 'Schnapps'\n","  WHEN lower(category_name) like '%gin%' then 'Gin'\n","  WHEN lower(category_name) like '%bourbon%' then 'Bourbon'\n","  WHEN lower(category_name) like '%brandies%' then 'Brandies'\n","  WHEN lower(category_name) like '%liqueur%' then 'Liqueur'\n","  WHEN lower(category_name) like '%scotch%' then 'Scotch'\n","  ELSE 'Other'\n","END\n","as CategoryName,\n","extract(Year from date) as Year,\n","extract(month from date) as Month,\n","count(*) as Count\n","FROM\n","  `bigquery-public-data.iowa_liquor_sales.sales`\n","group by year, month, categoryname\n","order by year, month, CategoryName\n","\"\"\"\n","df = execute_query(QUERY)\n","catYear=df.groupby(['CategoryName', 'Year'])['Count'].sum().unstack().plot(kind='bar', stacked=True, figsize=(14,7))\n","catYear.grid('on', axis='y', linestyle='dashed')\n","plt.yticks(np.arange(0, 6000000, 500000))\n","plt.gca().legend(loc='center left', bbox_to_anchor=(1, 0.5))\n","plt.xticks(rotation=45, horizontalalignment='right')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SUKe_jV8ZSde","colab":{}},"source":["yearCat=df.groupby(['Year', 'CategoryName'])['Count'].sum().unstack().plot(kind='bar', stacked=True, figsize=(14,7))\n","yearCat.grid('on', axis='y', linestyle='dashed')\n","plt.yticks(np.arange(0, 3000000, 500000))\n","plt.gca().legend(loc='center left', bbox_to_anchor=(1, 0.5))\n","plt.xticks(rotation=45, horizontalalignment='right')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oi7ieVxOZdeq"},"source":["Subset the data\n","\n","Based on the results above, we decided to go with 400,000 random rows from 2019.\n","\n","Our challenge was with github only allowing a file smaller than 100mb.  So we found that 400k rows came in at 95mb.\n","\n","Because there wasn't a particular sort column, we simply extracted 400k rows from BigQuery by executing the following query:\n","\n","\n","```\n","SELECT\n","  *\n","FROM `bigquery-public-data.iowa_liquor_sales.sales`\n","WHERE\n","date between \"2019-01-01\" and \"2019-12-31\" limit 400000;\n","```\n","\n","Once executed, we were able to save the results (400,000 rows) to a csv, and that is what we are using for our data set\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HIUQqHgrtb6g"},"source":["### One Hot Encoding\n","To be able to put our dataset into a manner that allows us to analyze further, we ran a one hot encoding procedure that isolated the categorical variables and one-hotted the ones that exceeded 30 uniques. This was done in our data cleaning stage earlier in this doc."]}]}