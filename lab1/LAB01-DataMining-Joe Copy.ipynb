{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LAB01-DataMining-Joe Copy.ipynb","provenance":[],"collapsed_sections":["24YU-KPljDwC","eezSJdUbX8md","oi7ieVxOZdeq"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xOfxcWSajDqP"},"source":["# Assignment 1"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tgb7l65KjDqT"},"source":["Discussion Notes:\n","* Whiskey vs Non-Whiskey (Classification) to be used\n","* 400K dataset to be used  \n","\n","Next steps:\n","* Clean up business understanding (reword based on 400k rows - right now it references the 50k rows).  Cite from textbook on how to evaluate the models\n","\n","Todo:\n","* Add any necessary verbiage for each image (text write-up, then image/chart below)\n","* Review each section assigned for appropriate wording\n","\n","* Jeff\n","** Exceptional Work\n","** New Features\n","* Joseph\n","** Reivew the Business Understanding\n","** Data Meaning Type\n","** Data Quality\n","* Armando\n","** Explore Attributes and class section (Move whiskey specific to this section)\n","** Simple Statistics\n","* Daniel\n","** Visualize Attributes (Addressing outliers)\n","** Explore Joint Attributes"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wYk89jjvjDqV"},"source":["### Business Understanding\n","\n","Introduction - The Iowa Liquor Sales dataset is an API from Google’s Bigquery which contains the wholesale purchases by retail stores in the Iowa area.  The dataset includes the spirit purchase details by product, date of purchase, and location the item was purchased from an Iowa Class “E” liquor license holder (retail stores) . The timeframe of this data starts from January 1, 2012 through 2019. As part of the study commissioned by the Iowa Department of Commerce, all alcoholic sales within the state were logged into the Department system, and in turn, published as open data by the State of Iowa. The dataset contains detail on the name, product, quantity and location of the individual container or package sale between the wholesaler (vendor) and the retailer.  \n","\n","1. Set Objectives: We are a new and emerging Whisky brand who specializes in single-malt Rye, and we have targeted the state of Iowa for our next brand expansion. Before doing so, our goal will be to identify and predict which markets are more likely to sell greater volumes of whiskey, so that we can more efficiently spend our marketing dollars and inventory with little waste or buyback. Related questions also include, which brands are going to sell the most in each market, what parts of the year are going to have higher whiskey sales as opposed to lower whiskey sales to optimize advertising dollars, and what features of a town are defining characteristics of a large whiskey seller. \n","\n","2. Product Project Plan: To meet our goals, we will first use the Google Bigquery API to access the publicly available Iowa Liquor Sales data via python and Jupyter Notebook. Since the dataset is over 17 million lines of data, we will focus just on 2 months worth of data to do the cleaning. From here, we will define a subset to grant us 30,000 observations, address missing values and begin to build models that could help us answer questions based on markets likely to sell more whiskey. For our data on times of the year when we will sell more whiskey, we will need to create a subset of a full year’s data to build a time series model. For the town features, we will need to include additional information about the zip codes of iowa (such as population, income, ect) to get more demographic detail on each market to assist with a program for a clustering problem. For each of these problems, we will create a training and testing data set to help tune our predictions. \n","\n","3. Business Success Criteria - For our prediction models of market sales, we will be consider our model successful if we are able to classify our alochol type with a strong precision, recall and accuracy using a cross validation. Ideally, if we are dealing with 5 alcohol types, we will want to be able to predict whiskey accurately over 20% of the time.  \n"," * Classification - 'Introduction to Data Mining' book - pages 173 to 196.  Estimating the generalization error of a model during training. The estimated error helps the learning algorithm to do model selection; i.e., to find a model of the right complexity that is not susceptible to over fitting. Once the model bas been constructed, it can be applied to the test set to predict the class labels of previously unseen records. It is often useful to measure the performance of the model on the test set because such a measure provides an unbiased estimate of its generalization error. The accuracy or error rate computed from the test set can also be used to compare the relative performance of different classifiers on the same domain. However, iu order to do tbis, the class labels of the test records must be knowu. This sectiom reviews some of the methods collliilonly used to evaluate the performance of a classifier.\n","    * Holdout Method In the holdout method, the original data with labeled examples is partitioned into two disjoint sets, called the training and the test sets, respectively. A classification model is then indnced from the training set and its performance is evaluated on the test set. The proportion of data reserved for training and for testiug is typically at the discretion of the aualysts (e.g., 50-50 or twothirds for training and one-third for testing}. The accuracy of the classifier can be estimated based on the accuracy of the induced model on the test set. \n","     * Other methods that may be used Cross-Validation, Random subsampling, and bootstrap. \n"," \n"," * Regression - From the sale price prediction problem, we will run a linear regression technique against the remaining features. For this technique, we will use Root Mean Square Error to evaluate the effectiveness. A strong criteria for performance would be if we can get within $3 as an RMSE. ?? Should we also use R-squared is a relative measure of fit and OLS? Look at 6371 Unit 9 through 11. Lack of fit tests, scatterplot of residual, studentized residuals and other fit diagnostics. \n"," \n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6Ol2Ku56jDqX"},"source":["## Data Meaning Type\n","\n","The initial data set is 4.63GB with 17.7 million rows.  This was too large for our systems to handle, so we took a subset of the data.  Please refer to the Exception Work on how we analyzed the full data set, which included a combination of BigQuery queries, and visualizing that data in order to come up with our subset which we saved as a csv file in our github repository"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iIykmxBCrcM7"},"source":["### Load Python Packages"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nbe-oTWwjDqb","colab":{}},"source":["# Import necessary python packages\n","try:\n","    from collections import abc as collections_abc\n","except ImportError:  # Python 2.7\n","    import collections as collections_abc\n","\n","    import copy\n","import functools\n","import gzip\n","import io\n","import itertools\n","import json\n","import math\n","import os\n","import tempfile\n","import uuid\n","import warnings\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import seaborn as sns\n","import numpy as np\n","#import altair as alt\n","import matplotlib.pyplot as plt\n","import re\n","import warnings\n","warnings.simplefilter('ignore', DeprecationWarning)\n","\n","# Imports the Google Cloud client library\n","#from google.cloud import storage\n","from google.oauth2 import service_account\n","from google.cloud import bigquery"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8VzJsCilrxi_"},"source":["### Load Data from github\n","\n","For our measurement, we will be querying the 2019 and limiting the rows to \n","50,000 for our intial modeling, which we can later expand to see how our model translates to scale."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AN-ug53fjDqq","colab":{}},"source":["# Read csv from disk\n","#df =  pd.read_csv(r'/Users/jjschued/Documents/Github/7331DataMiningNotebooks/lab1/iowa_subset_2019_400k_random_rows.csv', nrows = 100000)\n","#df =  pd.read_csv(r'/Users/danielclark/Desktop/SMU/data_mining/7331DataMiningNotebooks/lab1/iowa_subset_2019_400k_random_rows.csv', nrows = 50000)\n","\n","# read csv from github directly\n","url_dataset = 'https://github.com/jjschueder/7331DataMiningNotebooks/blob/master/lab1/iowa_subset_2019_400k_random_rows.csv?raw=true'\n","#df = pd.read_csv(url_dataset, nrows=50000)\n","df = pd.read_csv(url_dataset)\n","\n","# verify data read in\n","df.head(5)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WynDvfV4zEzj"},"source":["### Columns and Descriptions\n","\n","Below are the 24 columns found in the data set along with description of each "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3ooA9j-SsWrR","colab":{}},"source":["df.info()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-qW1-cqvzf2p"},"source":["Detailed Description of each field - referenced from the [data.iowa.gov](https://data.iowa.gov/Sales-Distribution/Iowa-Liquor-Sales/m3tr-qhgy) site that describes the dataset\n","\n","*   invoice_and_item_number (text) - Invoice and item associated with the liquor order.  This is unique identifier \n","*   date (date) - Date of when the order was placed\n","*   store_number (int) - Unique number assigned to the retail store that placed the order\n","*   store_name (text) - Name of the retail store that placed the order\n","*   address (text) - Address of the retail store that placed the order\n","*   city (text) - City of the retail store that placed the order\n","*   zip_code (float) - Zip code of the retail store that placed the order\n","*   store_location (text) - Lat/Long of retail store that placed the order\n","*   county_number (float) - Iowa county number for which the retail store that placed the order resides\n","*   county (text) - County name for which the retail store is located that placed the order\n","*   category (float) - Category code for the liquor that was ordered\n","*   category_name (text) - Category of the liquor that was ordered\n","*   vendor_number (int) - The vendor number of the company for the brand of liquor ordered \n","*   vendor_name (text) - The vendor name of the company for the brand of liquor ordered\n","*   item_number (int) - Item number for individual liquor product ordered\n","*   item_description (text) - Description of the liquor item ordered\n","*   pack (int) - The number of bottles in a case for the liquor ordered\n","*   bottle_volume_ml (int) - Volume of each liquor bottle ordered in milliliters\n","*   state_bottle_cost (float) - The amount that Alcoholic Beverages Division paid for each bottle of liquor ordered\n","*   state_bottle_retail (float) - The amount the store paid for each bottle of liquor ordered\n","*   bottles_sold (int) - Number of bottles of liquor ordered by the retail store\n","*   sale_dollars (float) - Total cost of liquor ordered (bottles_sold * state_bottle_retail)\n","*   volume_sold_liters (float) - Total volume of liquor ordered in liters (bottle_volume_ml * bottles_sold / 1000)\n","*   volume_sold_gallons (float) - Total volume of liquor ordered in gallons (bottle_volume_ml * bottles_sold / 3785.411784)\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0Pqwl1tXjDqZ"},"source":["## Data Quality  \n","Verify data quality: Explain any missing values, duplicate data, and outliers. Are those mistakes? How do you deal with these problems? Give justifications for your methods."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iM_Np0b9jDqw","colab":{}},"source":["df.info()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cQS7SYDjjDrB"},"source":["Running a df.columns.values function, confirms the 24 features that we referenced in our Data understanding phase. This now allows us to move forward with our data cleaning. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"J6jgiMesjDq8","colab":{}},"source":["df.columns.values"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vNmrMEbljDrD"},"source":["### Data Cleaning\n","\n","In our data cleaning step, we need to perform a few specific data cleaning operations to:\n","1.   Convert our features to the correct continuous, ordinal and categorical features\n","> Replace the values for pack, bottle_volume_ml, store_number, store_name, address, city, zip_code, county_number, county, category, category_name, vendor_number, vendor_name, item_number and item_description into categorical variables so they register as a non-null object in our model\n","\n","2.   Address the missing values\n","> Replace all \"?\", which our dataset denotes as null, into \"-1\" values (not strings). From here, we will convert state_bottle_cost, state_bottle_retail, sale_dollars, volume_sold_liters, and volume_sold_gallons into continuous variables so they register as floats.\n","\n","3.   Create a category that simplifies our alcohol categories to specific genres like whiskey, vodka, tequilla, ect.\n","4.   Categorize our store locations into a few easily discernable buckets\n","5.   Create a month and date column for opportunities to time and date analysis\n","6.   Convert the varaible \"bottles_sold\" into ordinal features so they register as an integer value in our models  \n","\n","Using a df.types function helps to verify this. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"20oVQQRhjDrG","colab":{}},"source":["df.dtypes"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JOs6ROqH7odu"},"source":["The following will do some cleanup on values and categorize store, category, and dates into more summarized values"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VIezayftjDrL","colab":{}},"source":["#upper case category name for matching later\n","df['category_name'] = df['category_name'].str.upper()\n","\n","#df['category_name'][40:45]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xjqMmEus5EYP","colab":{}},"source":["#upper case category name for matching later\n","df['item_description'] = df['item_description'].str.upper()\n","\n","#df['item_description'][40:45]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TyCj4E6HjDrT","colab":{}},"source":["#convert nan to blanks\n","df = (df.replace(r'^\\s*$', np.nan, regex=True))\n","df = (df.replace(np.nan, 'blank', regex=True))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UrbgCVymjDra","colab":{}},"source":["#Start with everything going into Other, and then look for keyword to put into specific category\n","df['liquor_category'] = 'Other'\n","df.loc[df['category_name'].str.contains('GINS'), 'liquor_category'] = 'GIN'\n","df.loc[df['category_name'].str.contains('GINS'), 'liquor_category'] = 'GIN'\n","df.loc[df['category_name'].str.contains('GIN'), 'liquor_category'] = 'GIN'\n","df.loc[df['category_name'].str.contains('RUMS'), 'liquor_category'] = 'RUM'\n","df.loc[df['category_name'].str.contains('RUM'), 'liquor_category'] = 'RUM'\n","df.loc[df['category_name'].str.contains('SCOTCH'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['category_name'].str.contains('WHISKIES'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['category_name'].str.contains('WHISKY'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['category_name'].str.contains('WHISKEY'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['category_name'].str.contains('RYE'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['category_name'].str.contains('AMARETTO'), 'liquor_category'] = 'AMARETTO'\n","df.loc[df['category_name'].str.contains('BOURBON'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['category_name'].str.contains('LIQUEURS'), 'liquor_category'] = 'LIQUEUR'\n","df.loc[df['category_name'].str.contains('LIQUEUR'), 'liquor_category'] = 'LIQUEUR'\n","df.loc[df['category_name'].str.contains('VODKAS'), 'liquor_category'] = 'VODKA'\n","df.loc[df['category_name'].str.contains('VODKA'), 'liquor_category'] = 'VODKA'\n","df.loc[df['category_name'].str.contains('BRANDY'), 'liquor_category'] = 'BRANDY'\n","df.loc[df['category_name'].str.contains('BRANDIES'), 'liquor_category'] = 'GIN'\n","df.loc[df['category_name'].str.contains('CREME'), 'liquor_category'] = 'SCHNAPPS'\n","df.loc[df['category_name'].str.contains('SCHNAPPS'), 'liquor_category'] = 'SCHNAPPS'\n","df.loc[df['category_name'].str.contains('TEQUILA'), 'liquor_category'] = 'TEQUILA'\n","df.loc[df['category_name'].str.contains('TEQUILAS'), 'liquor_category'] = 'TEQUILA'\n","\n","\n","\n","#get a few stray not available categories per internet this is tequila\n","df.loc[df['item_description'] == 'Herradura Gold Reposado 6pak', 'liquor_category'] = \"Tequila\"\n","df.loc[df['item_description'] == 'Chambord Liqueur w/2 Glasses', 'liquor_category'] = \"Liquers\"\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GB_4XzbD5EYe","colab":{}},"source":["#get some others by going to item description and doing same translation as above\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('GINS'), 'liquor_category'] = 'GIN'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('GINS'), 'liquor_category'] = 'GIN'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('GIN'), 'liquor_category'] = 'GIN'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('RUMS'), 'liquor_category'] = 'RUM'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('RUM'), 'liquor_category'] = 'RUM'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('SCOTCH'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('WHISKIES'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('WHISKY'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('WHISKEY'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('RYE'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('AMARETTO'), 'liquor_category'] = 'AMARETTO'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('BOURBON'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('LIQUEURS'), 'liquor_category'] = 'LIQUEUR'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('LIQUEUR'), 'liquor_category'] = 'LIQUEUR'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('VODKAS'), 'liquor_category'] = 'VODKA'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('VODKA'), 'liquor_category'] = 'VODKA'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('BRANDY'), 'liquor_category'] = 'BRANDY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('BRANDIES'), 'liquor_category'] = 'GIN'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('CREME'), 'liquor_category'] = 'SCHNAPPS'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('SCHNAPPS'), 'liquor_category'] = 'SCHNAPPS'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('TEQUILA'), 'liquor_category'] = 'TEQUILA'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('TEQUILAS'), 'liquor_category'] = 'TEQUILA'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('JOSE'), 'liquor_category'] = 'TEQUILA'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('PATRON'), 'liquor_category'] = 'TEQUILA'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('JAMESON'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('CROWN'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('BEAM'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('DANIELS'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('MORGAN'), 'liquor_category'] = 'RUM'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('JOHNNIE WALKER'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('GENTLEMAN'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('1800'), 'liquor_category'] = 'TEQUILA'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('BUSHMIL'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('KNOB'), 'liquor_category'] = 'WHISKY'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('TORTILLA'), 'liquor_category'] = 'TEQUILA'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('GOOSE'), 'liquor_category'] = 'VODKA'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('MARGARITA'), 'liquor_category'] = 'TEQUILA'\n","df.loc[df['liquor_category'].str.contains('Other') & df['item_description'].str.contains('TRIPLE SEC'), 'liquor_category'] = 'LIQUEUR'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"83QSdS-Y5EYj","colab":{}},"source":["#upper case category name for matching later\n","df['store_name'] = df['store_name'].str.upper()\n","\n","#df['store_name'][40:45]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MlArdWxEjDrf","colab":{}},"source":["#grouping all the store locations into parent stores\n","df['store_parent'] = 'Other'\n","df.loc[df['store_name'].str.contains('HY-VEE'), 'store_parent'] = 'Hy-Vee'\n","df.loc[df['store_name'].str.contains('WAL-MART'), 'store_parent'] = 'Wal-Mart'\n","df.loc[df['store_name'].str.contains('SAM'), 'store_parent'] = 'SamsClub'\n","df.loc[df['store_name'].str.contains('Fareway'), 'store_parent'] = 'Fareway'\n","df.loc[df['store_name'].str.contains('KUM'), 'store_parent'] = 'Kum&Go'\n","df.loc[df['store_name'].str.contains('CVS'), 'store_parent'] = 'CVS'\n","df.loc[df['store_name'].str.contains('TARGET'), 'store_parent'] = 'Target'\n","df.loc[df['store_name'].str.contains('CASEY'), 'store_parent'] = 'Caseys'\n","df.loc[df['store_name'].str.contains('DAHL'), 'store_parent'] = 'Dahls'\n","df.loc[df['store_name'].str.contains('QUIK'), 'store_parent'] = 'QuikTrip'\n","df.loc[df['store_name'].str.contains('WALGREEN'), 'store_parent'] = 'Walgreens'\n","df.loc[df['store_name'].str.contains('SMOKIN'), 'store_parent'] = 'SmokingJoes'\n","#labored conversion of dates to month year and month year by converting to strings\n","df['month'] = pd.DatetimeIndex(df['date']).month\n","df['year'] = pd.DatetimeIndex(df['date']).year\n","\n","df.loc[df['month'] ==1 , 'month'] = 'Jan'\n","df.loc[df['month'] ==2 , 'month'] = 'Feb'\n","df.loc[df['month'] ==3 , 'month'] = 'Mar'\n","df.loc[df['month'] ==4 , 'month'] = 'Apr'\n","df.loc[df['month'] ==5 , 'month'] = 'May'\n","df.loc[df['month'] ==6 , 'month'] = 'Jun'\n","df.loc[df['month'] ==7 , 'month'] = 'Jul'\n","df.loc[df['month'] ==8 , 'month'] = 'Aug'\n","df.loc[df['month'] ==9 , 'month'] = 'Sep'\n","df.loc[df['month'] ==10 , 'month'] = 'Oct'\n","df.loc[df['month'] ==11 , 'month'] = 'Nov'\n","df.loc[df['month'] ==12 , 'month'] = 'Dec'\n","\n","\n","df.loc[df['year'] ==2012 , 'year'] = '2012'\n","df.loc[df['year'] ==2013 , 'year'] = '2013'\n","df.loc[df['year'] ==2014 , 'year'] = '2014'\n","df.loc[df['year'] ==2015 , 'year'] = '2015'\n","df.loc[df['year'] ==2016 , 'year'] = '2016'\n","df.loc[df['year'] ==2017 , 'year'] = '2017'\n","df.loc[df['year'] ==2018 , 'year'] = '2018'\n","df.loc[df['year'] ==2019 , 'year'] = '2019'\n","\n","#merge year and month together\n","df['monthyear'] = df['month'] + \"-\" + df['year']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5QHtbwKljDrj","colab":{}},"source":["df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LAw13P82jDrn"},"source":["At the far right of the above dataset, you can see the 5 new columns we created and thier respective values. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"shBCdTeDjDro","colab":{}},"source":["# replace '?' with -1, we will deal with missing values later\n","df = df.replace(to_replace='?',value=-1) \n","\n","categorical_features = ['city', 'county',  'category_name','vendor_name', 'store_number', 'item_description','store_parent', \n","                        'monthyear', 'liquor_category', 'county_number', 'vendor_number', 'item_number']\n","\n","# let's start by first changing the numeric values to be floats\n","continuous_features = ['state_bottle_cost', 'state_bottle_retail', 'sale_dollars', 'volume_sold_liters', 'volume_sold_gallons', 'bottles_sold']\n","\n","# and the oridnal values to be integers\n","ordinal_features = ['pack', 'bottle_volume_ml']\n","\n","# use the \"astype\" function to change the variable type\n","df[continuous_features] = df[continuous_features].astype(np.float64)\n","df[ordinal_features] = df[ordinal_features].astype(np.int64)\n","df[categorical_features] = df[categorical_features].astype(object)\n","df.info() # now our data looks better!!"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZPAwJH9AAXaA","colab":{}},"source":["# will get summary of continuous or the nominals\n","dfstats = df.describe()\n","\n","# let's set those values to NaN, so that Pandas understand they are missing\n","df = df.replace(to_replace=-1,value=np.nan) # replace -1 with NaN (not a number)\n","#print (df.info())\n","df[categorical_features] = df[categorical_features].astype(object)\n","dfstats2 = df.describe() # scroll over to see the values\n","\n","categorical_features = ['city', 'county',  'category_name','vendor_name', 'store_number', 'item_description','store_parent', \n","                        'monthyear', 'liquor_category', 'county_number', 'vendor_number', 'item_number']\n","\n","# let's start by first changing the numeric values to be floats\n","continuous_features = ['state_bottle_cost', 'state_bottle_retail', 'sale_dollars', 'volume_sold_liters', 'volume_sold_gallons', 'bottles_sold']\n","\n","# and the oridnal values to be integers\n","ordinal_features = ['pack', 'bottle_volume_ml']\n","\n","# use the \"astype\" function to change the variable type\n","df[continuous_features] = df[continuous_features].astype(np.float64)\n","df[ordinal_features] = df[ordinal_features].astype(np.int64)\n","df[categorical_features] = df[categorical_features].astype(object)\n","df['store_number'] = df['store_number'].astype(object)\n","df.info() # now our data looks better!!"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PQW8ysAkjDry"},"source":["Here, you can see that our cleaning has addressed all nulls down to zero so we can begin analysis. The count code below helps to show that there is zero nulls in our dataset."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RJrfloH2jDr0","colab":{}},"source":["dfna = df[df.isna().any(axis=1)]\n","dfna.isna().sum()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nPugj6FkjDr4"},"source":["The next task will be for us to look into our categorical features with over 30 unique values, and we will be dropping any columns that have more than 30 uniques. The reason we are doing this is that we will ultimately have trouble with our predictions as these values will likely ultimately have unique attributes to a specific combination of observations. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aVall7c0jDr5","colab":{}},"source":["#Unique Value Threshold (Per Column)\n","#Delete Columns >  uniqueThreshold unique values prior to one-hot encoding. \n","#(each unique value becomes a new column during one-hot encoding)\n","uniqueThreshold = 30\n","# in each column of dataframe\n","uniqueValues = df.nunique()\n","uniqueValues"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nliSAAQ8jDr9","colab":{}},"source":["#Isolate continuous and categorical data types\n","#These are indexers into the schoolData dataframe and may be used similar to the schoolData dataframe \n","D_boolean = df.loc[:, (df.dtypes == bool) ]\n","D_nominal = df.loc[:, (df.dtypes == object)]\n","D_continuous = df.loc[:, (df.dtypes != bool) & (df.dtypes != object)]\n","print (\"Boolean Columns: \", D_boolean.shape[1])\n","print (\"Nominal Columns: \", D_nominal.shape[1])\n","print (\"Continuous Columns: \", D_continuous.shape[1])\n","print (\"Columns Accounted for: \", D_nominal.shape[1] + D_continuous.shape[1] + D_boolean.shape[1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RnupWglCjDsA","colab":{}},"source":["#Delete categorical columns with > 30 unique values (Each unique value becomes a column during one-hot encoding)\n","oneHotUniqueValueCounts = df[D_nominal.columns].apply(lambda x: x.nunique())\n","oneHotUniqueValueCols = oneHotUniqueValueCounts[oneHotUniqueValueCounts >= uniqueThreshold].index"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PZI-JdDbjDsD","colab":{}},"source":["oneHotUniqueValueCounts\n","oneHotUniqueValueCols"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YA8TwFrrjDsG","colab":{}},"source":["oneHotUniqueValueCols"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NO68ru6ZjDsK","colab":{}},"source":["onehotlist = oneHotUniqueValueCols.tolist()\n","onehotlist"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cRLLyoTQjDsO","colab":{}},"source":["#one hot encoding\n","dfenc = df.copy()\n","dfenc.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JqvYvwLkjDsS","colab":{}},"source":["dfenc.drop(onehotlist, axis=1, inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FG13HsBdjDsX","colab":{}},"source":["dfenc.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oQGMCJocjDsd","colab":{}},"source":["#'month', 'year', 'county_number',\n","#Isolate continuous and categorical data types\n","#These are indexers into the schoolData dataframe and may be used similar to the schoolData dataframe \n","dfenc_boolean = dfenc.loc[:, (dfenc.dtypes == bool) ]\n","dfenc_nominal = dfenc.loc[:, (dfenc.dtypes == object)]\n","dfenc_continuous = dfenc.loc[:, (dfenc.dtypes != bool) & (df.dtypes != object)]\n","print (\"Boolean Columns: \", dfenc_boolean.shape[1])\n","print (\"Nominal Columns: \", dfenc_nominal.shape[1])\n","print (\"Continuous Columns: \", dfenc_continuous.shape[1])\n","print (\"Columns Accounted for: \", dfenc_nominal.shape[1] + dfenc_continuous.shape[1] + dfenc_boolean.shape[1])\n","\n","one_hot_df = pd.concat([pd.get_dummies(dfenc[col],prefix=col) for col in dfenc_nominal.columns], axis=1)\n","one_hot_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"daXDHH8RjDsh","colab":{}},"source":["df1hotmerge = pd.merge(dfenc, one_hot_df, left_index=True, right_index=True)\n","df1hotmerge.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hJ-AExI3jDsl"},"source":["Encoding table has 51 columns "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mj55a9J5jDsn"},"source":["On the one hot encoding dataset, we are going to drop the colums, vendor_number, item_number, and store_number as they will be redundant to other features in our dataset.\n","\n","From here, lets see how big our dataset gets when we onehot our categorical variables. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4v76ILArjDso","colab":{}},"source":["df[df.isnull().any(axis=1)][df.columns[df.isnull().any()]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Yx6ks9cIjDsr","colab":{}},"source":["# this python magics will allow plot to be embedded into the notebook\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore', DeprecationWarning)\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"c_Ea-uAIjDsv","colab":{}},"source":["df['liquor_category'].value_counts()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LSvni7XnjDsy"},"source":["Looking at a quick count of our categories, we can see that Vodka appears the most often in our dataet, at over 13,000 times followed by Whisky with over 10,000 instances. \n","\n","Below, we created a column called cost_per_liter and isolated the sales that exceeded $20,000. There were 7 total values with 6 of the 7 being Vodka Varieties. However, note the cost of liter is not that high in relation to to the sale and the volume sold per liters are almost all in the quadruple digits, which suggest these are cheaper alcohols being sold in high volume. 4 of the 7 sales were at Hy-Vee, which we will look at soon. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jVWPMJakjDsz","colab":{}},"source":["# selecting rows based on condition\n","exp_df = df[df['sale_dollars'] > 20000]\n","\n","exp_df['cost_per_liter'] = exp_df['sale_dollars']/exp_df['volume_sold_liters']\n","\n","exp_df[['sale_dollars', 'volume_sold_liters', 'cost_per_liter', 'liquor_category', 'store_parent']]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fpsjeGcmtbyT"},"source":["### Addressing Outliers  \n","Below, we created a column called cost_per_liter and isolated the sales that exceeded $35,000. There were 7 total values with 6 of the 7 being Vodka Varieties. However, note the cost of liter is not that high in relation to to the sale and the volume sold per liters are almost all in the quadruple digits, which suggest these are cheaper alcohols being sold in high volume. 4 of the 7 sales were at Hy-Vee, which we will look at soon."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"S4GzBUEmjDtN","colab":{}},"source":["# display boxplot of sale_dollars grouped by liquor_category\n","plt.style.use('ggplot')\n","ax = df.boxplot(column = 'sale_dollars', by = 'liquor_category', figsize=(14,7))\n","plt.xticks(rotation=45)\n","ax"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0-KyHIZ-jDtS"},"source":["This box plot is graphing the distribution sale_dollars with the different categories of liquor we have available. Here, we can see there is a significant number of outliers across all categories, so much that you can't really see the boxes on each category. This would suggest we would want to look into a transform."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ALOVk8FkjDtT","colab":{}},"source":["# perform log transformation on sale_dollars due to significant outliers\n","df['sale_dollars_trans'] = np.log(df['sale_dollars'])\n","\n","# display boxplot of logged sale dollars grouped by liquor_category\n","gx = df.boxplot(column = 'sale_dollars_trans', by = 'liquor_category', figsize=(14,7))\n","plt.xticks(rotation=45)\n","gx"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QJG5QRWDjDtX"},"source":["This is much more helpful for us to see how our distribution of categories compares to one another. Vodka and Whiskey are still showing a wider range of outliers, however Liquer tends to have a wider bounding than the other categories, which suggests that it has a wide variety of pricing. On average, tequila looks to have the higher medium sale value, which suggest that more money is being spent on tequilla on average. \n","\n","Using Sales dollars trans will help address outliers in the future."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SLpP2nVPjDtn","colab":{}},"source":["# create new feature of cost_per_liter\n","df['cost_per_liter'] = df['sale_dollars']/df['volume_sold_liters']\n","\n","# display boxplot of cost_per_liter grouped by liquor_category\n","bx = df.boxplot(column = 'cost_per_liter', by = 'liquor_category', figsize=(14,7))\n","plt.xticks(rotation=45)\n","bx"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"X28mjeKajDtr"},"source":["Looking at the cost per liter aggregate column. As we discussed previously, cost per liter is calculated via a calculation of total sales_dollars divided by the total volume_sold_ml. The idea of this calculation is to see the varying price of the liquors if we normalize by the volume and sale of the liquors in our set. \n","\n","Here, we can see that our distribution is right skewed with a large outlier for whiskey which is going for over 1750 per liter. Looking further into this datapoint, we can see that this datapoint represents Johnnie Walker Blue. \n","\n","That said, with the distribution of alcohol types, outside of Johnnie walker blue, we cans see that our cost per liter is going to have a greater than tenfold range, so, i would suggest we create a transform there as well. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"X7EEWHkYjDtt","colab":{}},"source":["df['cost_per_liter_trans'] = np.log(df['cost_per_liter'])\n","\n","zx = df.boxplot(column = 'cost_per_liter_trans', by = 'liquor_category', figsize=(14,7))\n","plt.xticks(rotation=45)\n","zx"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1QIX8VDKjDtv"},"source":["This new box plot shows some interesting insight into the distribution and the value placed on alcohol in our dataset. \n","\n","Gin and Tequilla - even with outliers, it is going to have a faily consistent price per liter. \n","Liquer - Similar case as GIn, however, it's outliers go a little farther out. \n","Other- as expected, has a very wide range with very few outliers. Since this represents all types of alcohol not covered in the other categories, the box plot shape is expected. \n","\n","Whiskey - Has a faily consistent bounding, however the number out outliers on either side is very large and larger than the other categories. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"49NU7KnojDs5"},"source":["## Simple Statistics\n","\n","The df.describe funciton below provides some simple statistcs for the numeric values in the table. \n","\n","Reviewing the 'pack' & 'bottle_volume_ml' variable statistics, we can see that the average transactional sale was about a 12 pack with 960 ml per bottle.  Furthermore, reviewing the 'state_bottle_cost' and 'state_bottle_retail' variables the average cost per bottle is about 10.22 while the average retail price is 15.35. With that said, this goes to align with what a typical box of liquor bottles tend to look like (at 12 per pack) in which a $5 profit is anticipated per bottle.\n","\n","Another point to consider is the median values are smaller than the mean values. This suggests that our distribution of our sample population is right skewed. \n","\n","Lastly, there are a number of outliers within the dataset in which we may need to perform a log tranformation to address.  For example, the 'sale_dollars' variable has max sale amount of 50,186 but the 75th quartile is only at 152.  Also, within the 'volume_sold_liters\" variable the max amount is 6,615 liters but the 75th quartile is only 10.5 liters.  Further updats will need to be done to identify and address the outliers within our model.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WpWu4zSEjDtD","colab":{}},"source":["df.describe()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7p3RMJXJ4A1m","colab_type":"text"},"source":["To further view and analyze the outliers, the scatter plot below easily shows points the associated points. Also, the table that follows shows the top 10 items listed within sale_dollars and volume_sold liters."]},{"cell_type":"code","metadata":{"id":"ehhkM5CX4A16","colab_type":"code","colab":{}},"source":["# display scatterplot of x=volume_sold_liters, y= sale_dollars\n","plt.style.use('ggplot')\n","sns.scatterplot(x=df.volume_sold_liters, y= df.sale_dollars)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uhMzdVcj4A2E","colab_type":"code","colab":{}},"source":["# top 10 table for sale_dollars\n","df.nlargest(10, 'sale_dollars')['item_description'].reset_index()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H5nZU3lj4A2T","colab_type":"code","colab":{}},"source":["# top 10 table for volume_sold_liters\n","df.nlargest(10, 'volume_sold_liters')['item_description'].reset_index()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"egglMnwDjDtJ"},"source":["Some additional interesting facts can be found in the mode section. Vodka has the largest number of sales, and the small package stores combined take up more sales than a single big-box retailer. \n","\n","The most common pack size is 12 pack, which is efficient for shipping and the most common bottle size is 750 ml. \n","\n","December 2019 is the most popular month for alcohol sales, which suggest that people drink heavily that time of year. :)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ruDObLebjDtF","colab":{}},"source":["dfenc.mode()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2wyCFl6CjDtL"},"source":["## Visualize Attributes\n","Visualize the most interesting attributes (at least 5 attributes, your opinion on what is interesting). Important: Interpret the implications for each visualization. Explain for each attribute why the chosen visualization is appropriate.  \n","\n","The following section shows our cross tabulations of the relationships we found with our 2019 liquor data. The bar charts and box plots are ablet o show the distribution of our data and a comparative between categorical variables in our set. \n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"todLi_-DjDtX","colab":{}},"source":["# Plotting a Horizontal barchart of sale_dollars grouped by liquor_category\n","plt.style.use('ggplot')\n","plt.figure(figsize=(14,7))\n","df_grouped = df.groupby(by=['liquor_category'])\n","sales_rate = df_grouped.sale_dollars.sum()\n","ax = sales_rate.plot(kind='barh')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"OGNvTU9DjDte"},"source":["Looking at an agregate of our different alcohol categories, we can see that Whiskey generated the highest number of sales in our datase at close to 2.5 million followed by vodka at closer to 2 million. This chart seems to show that Vodka and Whiskey are the two most highest selling alcohols in the state of Iowa in 2019 with no one liquor coming close. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Zs0n7bxpjDti","colab":{}},"source":["# Plotting a Horizontal barchart of sale_dollars grouped by store_parent\n","plt.style.use('ggplot')\n","plt.figure(figsize=(14,7))\n","df_grouped = df.groupby(by=['store_parent'])\n","sales_rate = df_grouped.sale_dollars.sum()\n","ax = sales_rate.plot(kind='barh')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Hiugn1cpjDtm"},"source":["For our stores in our dataset, as we discussed previously, we decided to focus on the big box retailers as our starting point, and lumped in the smaller stores into a category called \"other\". As we can see, the other column drove the greatest overall sales at over 4 million, however the Hy Vee in iowa was close to it at nearly 3.5 million in sales. In the state of Iowa, Hy Vee is a widely popular grocery store chain in Iowa that sales alocholic beverages as per the laws in Iowa. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RMsPnQtNjDtw","colab":{}},"source":["# Start by just plotting what we previsously grouped!\n","plt.style.use('ggplot')\n","plt.figure(figsize=(14,7))\n","df_grouped = df.groupby(by=['liquor_category'])\n","sales_rate = df_grouped.cost_per_liter.mean()\n","ax = sales_rate.plot(kind='barh')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ciI_vKvijDtz"},"source":["This plot shows the grouped average cost per liter by the type of liquor in our dataset. Coming in at over 50 dollars per liter, whiskey is the most expensive alcohol in our dataset. However, some of that can come from the Johnnie Walker Blue we discussed previously, the common theme is that whiskey tends to be more expensive liter for liter than the other types of alcohol."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"49wwdLM_jDt0","colab":{}},"source":["# Start by just plotting what we previsously grouped!\n","plt.style.use('ggplot')\n","plt.figure(figsize=(14,7))\n","df_grouped = df.groupby(by=['liquor_category'])\n","sales_rate = df_grouped.sale_dollars.mean()\n","ax = sales_rate.plot(kind='barh')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XZOMj74ajDt6"},"source":["While whiskey had the highest average cost per liter, the vodka tended to have the highest sale value per purchase among all the alcohol types. This can be attributed to the volume in which vodka can be made and shipped, which likely affected the volume of sale. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6nvs4FpAjDt7","colab":{}},"source":["# Start by just plotting what we previsously grouped!\n","plt.style.use('ggplot')\n","plt.figure(figsize=(14,7))\n","df_grouped = df.groupby(by=['liquor_category'])\n","sales_rate = df_grouped.bottles_sold.mean()\n","ax = sales_rate.plot(kind='barh')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HtfToHYajDt9"},"source":["Looking at the average bottles sold per pack by way of the liquor categories in our dataset, tequila had the highest amount with over 20 bottles sold per purchase on average. This can be followed by vodka which was referenced earlier."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"roi_RYIejDt-"},"source":["### Whiskey Specific Analysis\n","\n","Refining market to whiskey to gather further information about whiskey vendors. Since our analysis is going to focus strictly on whiskey sales, it will be important to see how the whiskey distribution looks within our dataset.  \n","\n","The first thing we are going to do is copy the original df into a dfwhiskey dataframe.  After we will be filtering for only the 'WHISKY' liquor category.  Note, the new dfwhiskey datafram should have the same features of the original df except it is only filtered for 'WHISKY' specific transactions. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"x3Kg3j51jDt_","colab":{}},"source":["# copy original df into dfwhiskey dataframe\n","dfwhiskey = df.copy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hu1CS8vWjDuG","colab":{}},"source":["# filter for only the 'WHISKY' liquor_category\n","dfwhiskey = dfwhiskey[dfwhiskey['liquor_category']=='WHISKY']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1lzXYRhljDuB"},"source":["Here's the head of our dataset so we can see how it looks."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eYO4ZqSqjDuC","colab":{}},"source":["dfwhiskey.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iYrPI_azjDuK"},"source":["Next, we are going to do a series of calculations to add new columns to our dataset which provides some insight to the sales data of our whiskies. \n","\n","These include the following new features:\n","- profit = state_bottle_retail / bottles_sold\n","- totalcost = state_bottle_cost * bottles_sold\n","- revenue = state_bottle_retail * bottles_sold\n","- grossmargin = (revenue - totalcost)/revenue\n","\n","Ultimately, this is going to give us a clear view of the profatability, and the market size of whiskey so we can better analyze and predict within the dataset."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FwWEbS0ujDuP","colab":{}},"source":["#do some calculations for cost and profit\n","dfwhiskey['profit'] = dfwhiskey['state_bottle_retail']*dfwhiskey['bottles_sold'] - dfwhiskey['state_bottle_cost']* dfwhiskey['bottles_sold']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"enGon798jDuS","colab":{}},"source":["dfwhiskey['totalcost'] = dfwhiskey['state_bottle_cost']* dfwhiskey['bottles_sold']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TXsMcziQjDuU","colab":{}},"source":["dfwhiskey['revenue'] = dfwhiskey['state_bottle_retail']*dfwhiskey['bottles_sold']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"V7NhUuLbjDuX","colab":{}},"source":["dfwhiskey['grossmargin'] = (dfwhiskey['revenue'] - dfwhiskey['totalcost']) / dfwhiskey['revenue']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"j7XdUU7IjDua"},"source":["Here, we sorted gross margin of sale within our data set to get a clearer view of how margins tend to look within the sales in our dataset. \n","\n","As we can see, there is a 33% margin that appears across almost all of our sales when you calculate the percentage of what is remaining from the cost over the revenue. We are thiking that is a standard state tax cost for whiskies in the state of Iowa."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"l1-jYNz1jDua","colab":{}},"source":["#lets do the transforms we did earlier in the EDA\n","dfwhiskey['sale_dollars_trans'] = np.log(dfwhiskey['sale_dollars'])\n","dfwhiskey['cost_per_liter_trans'] = np.log(dfwhiskey['cost_per_liter'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"79VWZd8bjDud","colab":{}},"source":["dfwhiskey.sort_values(by='grossmargin', ascending=False).head(5)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0QuMFJUBjDuk"},"source":["Looking at more grossmargin values, we still see the same 33%"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eXK4CSyIjDuk","colab":{}},"source":["dfwhiskey.head(5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"m3pptMnmjDup","colab":{}},"source":["df_grouped = dfwhiskey.groupby(by=['vendor_name'])\n","df_grouped.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6gtu-qb-jDur"},"source":["To look into some aggregate sums within our whiskey dataset, we are going to create new varuables for the sum of bottles sold and sale_dollars, as well as the mean of cost per liter and gross margin. \n","\n","Also, we will create datagrames for each so we can see how the whiskey's distribute in these aggregate figures."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"i330X3MTjDus","colab":{}},"source":["sales_rateq = df_grouped.bottles_sold.sum()\n","sales_rated = df_grouped.sale_dollars.sum()\n","sales_ratecpl = df_grouped.cost_per_liter.mean()\n","salesgm = df_grouped.grossmargin.mean()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"87wvUjrVjDuu","colab":{}},"source":["dfsr = pd.DataFrame(sales_rateq)\n","dfsdol = pd.DataFrame(sales_rated)\n","dfscpl = pd.DataFrame(sales_ratecpl)\n","dfsg = pd.DataFrame(salesgm)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"d9yiq4tSjDux","colab":{}},"source":["dfsr.sort_values(by='bottles_sold', ascending=False).head(10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qJ0bRdANjDu0"},"source":["Looking at the top 10 bottles sold in the whiskey category, we can see that the number one on the list is Pernod Ricard at over 100k bolttles sold, followed distantly by Dieago Americas at 29,500. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9zxAOTP7jDu1","colab":{}},"source":["dfsdol.sort_values(by='sale_dollars', ascending=False).head(10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-QJ1zyZJjDu4"},"source":["As a function of bottles sold, we are seeing a similar distirbution with regards to sale_dollars in our top whiskies. Pernod Richard is nearing 3 million dollars in sales followed by Diageo Americas that is under 1 million dollars in sales. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"POc4h9QGjDu5","colab":{}},"source":["dfscpl.sort_values(by='cost_per_liter', ascending=False).head(10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cPoGmXKXjDu8"},"source":["Interestingly, looking at the high cost per liter vendors, Pactific Edge Wine and Spirits has the highest cost per liter at over 115 dollars, followed by Impex Beverage and Hotaling at just over 100 dollars. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"89F7W-rCjDu8","colab":{}},"source":["salesbyvendor = pd.merge(dfsr, dfsdol, how = 'left', on='vendor_name')\n","salesbyvendor = pd.merge(salesbyvendor, dfscpl, how = 'left', on='vendor_name')\n","salesbyvendor = pd.merge(salesbyvendor, dfsg, how = 'left', on='vendor_name')\n","salesbyvendor"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BQnHcYq6jDu-"},"source":["Next, we are going to merge our datasets so that we can group our measures of bottles sold, sale_dollars, cost_per_liter and gross margin by our 61 vendors, so we can see how they rank in our key finance values. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fJ0F-yxYjDu_","colab":{}},"source":["salesbyvendor.sort_values(by='cost_per_liter', ascending=False).head(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fKVoB6pojDvD","colab":{}},"source":["salesbyvendor.sort_values(by='sale_dollars', ascending=False).head(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YBndy3y_jDvJ","colab":{}},"source":["salesbyvendor.sort_values(by='grossmargin', ascending=False).head(100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PXgVEnQijDvL","colab":{}},"source":["# Start by just plotting what we previsously grouped!\n","#plt.style.use('ggplot')\n","#sales_rate = dfsdol.sort_values(by='sale_dollars', ascending=False).head(10)\n","#ax = sales_rate.plot(kind='bar', figsize=(14,7))\n","#ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n","\n","# Start by just plotting what we previsously grouped!\n","#plt.style.use('ggplot')\n","#sales_rate = dfscpl.sort_values(by='cost_per_liter', ascending=False).head(20)\n","#ax = sales_rate.plot(kind='bar', figsize=(14,7))\n","#ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tMEGXfgMxqQ2","colab":{}},"source":["salesbyvendor = salesbyvendor.reset_index()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"T7ULXUPItb32","colab":{}},"source":["fig, axs = plt.subplots(2, 2, figsize=(18, 18))\n","sales_rate = salesbyvendor.sort_values(by='sale_dollars', ascending = False)\n","names = salesbyvendor.sort_values(by='cost_per_liter', ascending=False)['vendor_name'].head(10)\n","values = salesbyvendor.sort_values(by='cost_per_liter', ascending=False)['cost_per_liter'].head(10)\n","names2 = salesbyvendor.sort_values(by='sale_dollars', ascending=False)['vendor_name'].head(10)\n","values2 = salesbyvendor.sort_values(by='sale_dollars', ascending=False)['sale_dollars'].head(10)\n","names3 = salesbyvendor.sort_values(by='grossmargin',  ascending=False)['vendor_name'].head(10)\n","values3 = salesbyvendor.sort_values(by='grossmargin',  ascending=False)['grossmargin'].head(10)\n","names4 = salesbyvendor.sort_values(by='bottles_sold',  ascending=False)['vendor_name'].head(10)\n","values4 =salesbyvendor.sort_values(by='bottles_sold',  ascending=False)['bottles_sold'].head(10)\n","axs[0, 0].bar(names, values)\n","axs[0, 0].set_title('Cost Per Liter')\n","axs[0, 0].set_xticklabels(names, rotation=20, horizontalalignment='right')\n","axs[0, 1].bar(names2, values2)\n","axs[0, 1].set_title('Sales Dollars')\n","axs[0, 1].set_xticklabels(names2, rotation=20, horizontalalignment='right')\n","axs[1, 0].bar(names3, values3)\n","axs[1, 0].set_title('Gross Margin')\n","axs[1, 0].set_xticklabels(names3, rotation=20, horizontalalignment='right')\n","axs[1, 1].bar(names4, values4)\n","axs[1, 1].set_title('Qty Sold')\n","axs[1, 1].set_xticklabels(names4, rotation=20, horizontalalignment='right')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3g_g4rQvjDvQ"},"source":["Above are some additional plots to help you visualize a more complete dataset on cost per liter as well as sales dollar of our specific whiskeis in the study. As discussed before, the Pernod Richard whiskey is the top selling vendor,while Pacific Edge Whiskey has the highest cost per liter, ensinuating they are seeling the most valueable whiskey. \n","\n","### Store Location Analysis\n","If we are interested in big box retailers, lets look into Hy-Vee."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vio6XiNRjDvQ","colab":{}},"source":["hv_df = pd.get_dummies(df['store_parent'], drop_first=False)\n","\n","hv_df = pd.concat([df, hv_df], axis = 1, sort=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YBaZgHIBjDvS","colab":{}},"source":["hv_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TRG972dOjDvV","colab":{}},"source":["hv_grouped = hv_df.groupby(by=['liquor_category', 'Hy-Vee']).median()\n","hv_grouped"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ukpUkURmjDvW","colab":{}},"source":["import seaborn as sns\n","cmap = sns.diverging_palette(220, 10, as_cmap=True) # one of the many color mappings\n","sns.countplot(x='Hy-Vee', data=hv_df);"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lMBpYNGsjDvY"},"source":["Over 30k sales in our dataset were attributed to stores other than Hy-Vee, while the remaining 20k are from Hy-Vee"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OHgCzErujDvZ","colab":{}},"source":["chart=sns.catplot(x='liquor_category', col='Hy-Vee', kind='count', data=hv_df)\n","chart.set_xticklabels(rotation=45, ha='right')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aUZvCEz2jDvb","colab":{}},"source":["pd.crosstab(hv_df.liquor_category, hv_df['Hy-Vee'], margins=True).style.background_gradient(cmap='autumn_r')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lkZnWaoVjDve"},"source":["In the two plots above, we can see the categorical sales tended to remain relatively consistent between Hy-Vee stores as opposed to other liquor stores in the area. This would suggest that Hy-Vee isn't buying liquor differently than anyone else in the state. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yKMQd39GjDvf","colab":{}},"source":["sns.catplot('Hy-Vee', \"sale_dollars_trans\", kind='point', data=hv_df)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6oMiRAI7jDvl","colab":{}},"source":["sns.catplot('Hy-Vee', \"cost_per_liter_trans\", kind='point', data=hv_df)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0DO5VlTijDvn","colab":{}},"source":["sns.catplot('Hy-Vee','cost_per_liter_trans',hue='liquor_category', kind='point', data=hv_df);"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ynZ8o80ajDvr"},"source":["I was curious to see if HyVee Charged Higher Prices than the competitors. Looking at the cost per liter (which would normalize liquor cost), It appears that Hy-Vee had much higher prices. However, grouping by category, we can see that this might have been dur to the volume of whiskey sales Hy-Vee had compared to non-hy-vee stores. The costs are pretty consistent. \n","\n","Lets try this with Small Liquor stores vs large big-box stores, using the same code as above but with Other instead of Hy-Vee."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Cj-wAvlvjDvs","colab":{}},"source":["sns.catplot('Other','cost_per_liter_trans',hue='liquor_category', kind='point', data=hv_df);"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uybAteaCjDvx"},"source":["With 0 being Big Box Stores and 1 Being Small Retailers, we can see that consistently, Small Chains are charging higher prices. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"It4qaLANjDvy"},"source":["## Explore Joint Attributes\n","Visualize relationships between attributes: Look at the attributes via scatter plots, correlation, cross-tabulation, group-wise averages, etc. as appropriate. Explain any interesting relationships.  \n","\n","The next section dives deeper into the relationsihps between all the variables in our dataset as well as some of the key relationships found between our features. This will be a starting point for us to better understand if we can begin to think about addressing and removing highly correlated features in our set. \n","\n","To measure this, we will be able to run grid plots and heat maps with each feature against one another. The plots that are highly coorelated will be closer to 1 while the plots that are highly negatively correlated will be closer to -1. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jxsWqforjDvy","colab":{}},"source":["# plot the correlation matrix using seaborn\n","import seaborn as sns\n","cmap = sns.diverging_palette(220, 10, as_cmap=True) # one of the many color mappings\n","\n","sns.set(style=\"darkgrid\") # one of the many styles to plot using\n","f, ax = plt.subplots(figsize=(14, 7))\n","chart=sns.heatmap(df.corr(), cmap=cmap, annot=True)\n","chart.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n","f.tight_layout()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-5Ck_o5UjDv0"},"source":["Looking at a heat map of our coorelation plot, we can see some interesting occurances happening in the bottom right corner with regards to the volume stats as well as the sales stats. We are seeing cases of volume_sold_gallons and liters having a 0.93 coorelation to bottles sold. Which makes sense, because the greater the volume of sales would suggest the greater number of bottles in the purchase. \n","\n","In addition, these volume stats are highly correlated at 0.85 to sale dollars. While this is expected as it costs more to get more whiskey, it's interesting as there tends to be somewhwat of a minimal affect with regards to volume discounts. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gPMyQl34jDv1","colab":{}},"source":["# now try plotting some of the previous plots, way more visually appealing!!\n","#https://towardsdatascience.com/visualizing-data-with-pair-plots-in-python-f228cf529166\n","import seaborn as sns\n","\n","sns.set(style=\"darkgrid\") # one of the many styles to plot using\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"w7UY6taw5Ee9","colab":{}},"source":["dfenc.dtypes\n","df.dtypes"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EyXP7EIJ5Ee_","colab":{}},"source":["sns.pairplot(dfenc, height=3, hue= 'liquor_category', vars = ['state_bottle_retail', 'sale_dollars', 'bottles_sold', 'volume_sold_liters'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TyiuNfD660hm","colab":{}},"source":["sns.pairplot(df, height=3, hue= 'liquor_category', vars = ['state_bottle_retail', 'sale_dollars_trans', 'bottles_sold', 'volume_sold_liters'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ne6mznuv5EfB","colab":{}},"source":["#sns.pairplot(dfenc, height=3, hue= 'liquor_category', vars = ['state_bottle_retail', 'sale_dollars', 'bottles_sold', 'volume_sold_liters'], diag_kind = 'kde')\n","sns.pairplot(df, height=3, hue= 'liquor_category', vars = ['cost_per_liter_trans', 'sale_dollars_trans'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2zbUp6pmjDv3"},"source":["Here we can see a couple pair scatter plots that show our coorelations in action. In the bottom right corner, we can see those same highly correlated values visualized in a plot, and broken out by drink type.\n","\n","Interestingly, we can see some clustering start to appear in some of the relationships, particularly between tequila and whiskey as it relates to volume sold and sales data.\n","\n","![image.png](attachment:image.png)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZK-8JxsDjDv4","colab":{}},"source":["#cross tab example\n","dfcross = pd.crosstab(df['liquor_category'], df['store_parent'],  margins=True, margins_name=\"Total\")\n","dfcross"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HT_1JUETjDv6"},"source":["Next, we are going to look at a cross tab and explore the relationships with alcohol type and store.\n","\n","As you can see in the table above, Hy Vee and Other take up the majority of sales, however Other is a stronger Vodka seller while Hyvee sales more whieksy. This is confirmed below with our chart that shows the mix of alcohol sales int he story. For each, Vodka and whiskey are among the top sellers. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8kh09C0UjDv6","colab":{}},"source":["#Normalized Cross Tab\n","dfcrossnorm = pd.crosstab(df['liquor_category'], df['store_parent'], normalize='columns')\n","dfcrossnorm"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"A0HQdT1pjDv9","colab":{}},"source":["\n","fig, ax = plt.subplots(figsize=(14,7))\n","chart=sns.heatmap(pd.crosstab([df['liquor_category']], [df['store_parent']]),\n","            cmap=\"YlGnBu\", annot=True, cbar=False, fmt='g')\n","chart.set_xticklabels(chart.get_xticklabels(), rotation=45, horizontalalignment='right')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dqD4PPi9jDv_"},"source":["Next is a heatmap which shows the relationship between Vodka and Whiskey amontst the stores, which provides a visual representaiton of the data above. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"C-YkPSAWjDwA","colab":{}},"source":["#group wise average\n","df_grouped = df.groupby(by=['store_parent','liquor_category', ]).mean()\n","df_grouped"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"W4IdsNgRjDwB"},"source":["## Explore Attributes and Class\n","Our goal of exploring attributes and class was to see if there were any relationships between Whiskey purchases and variables within the dataset.  First we analyzed whether or not Whiskey was purchased against 'store_parents' after we analyzed based on location, by county then city.\n","\n"]},{"cell_type":"code","metadata":{"id":"0rtVFziA4A-0","colab_type":"code","colab":{}},"source":["explore_df= original_df.copy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"He6QXWgk4A-3","colab_type":"code","colab":{}},"source":["explore_df['WHISKY_Y_N'] = 0\n","explore_df.loc[explore_df['liquor_category'].str.contains('WHISK'), 'WHISKY_Y_N'] = 1\n","explore_df.head(5)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l1c3yu0j4A-9","colab_type":"text"},"source":["After reviewing the table below, it is interesting to note that when Whiskey is purchased it is in packs less then 10.  Also, the average sale_dollars for a whiskey purchase is much greater than non-whiskey purchases.  This is further pointed in out in the average state_bottle_costs.\n","\n","Lastly, whiskey purchases tend to have a lower average volume sold then non-whiskey purchases."]},{"cell_type":"code","metadata":{"id":"417fUSih4A_B","colab_type":"code","colab":{}},"source":["explore_df.groupby('WHISKY_Y_N').mean()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1fcsGNGv4A_U","colab_type":"text"},"source":["Based on the table below, Target, Sams Club, & Hy-vee have the highest means when it comes to selling Whiskey in their stores.  In other words, of all the liquor transactions processed within these stores there is about 14 percent chance it is associated to a Whiskey purchase."]},{"cell_type":"code","metadata":{"id":"KsmKovti4A_V","colab_type":"code","colab":{}},"source":["explore_df.groupby('store_parent').mean()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Eia8Aosn4A_W","colab_type":"text"},"source":["As you can see within the table below most whiskey purchases occur in Polk county, with Linn, Johnson, Scott, and Black Hawk following."]},{"cell_type":"code","metadata":{"id":"Zd9UbRZs4A_p","colab_type":"code","colab":{}},"source":["large_county_df = explore_df.groupby('county').sum().reset_index()\n","large_county_df.nlargest(5, 'WHISKY_Y_N')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BSbZcHAY4BAC","colab_type":"text"},"source":["To further breakdown the location of whiskey purchases, we can see that Des Moines leads all other cities with Cedar Rapids coming in second."]},{"cell_type":"code","metadata":{"id":"wsCBxHig4BAC","colab_type":"code","colab":{}},"source":["large_county_df = explore_df.groupby('city').sum().reset_index()\n","large_county_df.nlargest(5, 'WHISKY_Y_N')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"24YU-KPljDwC"},"source":["## New Features\n","\n","Some of the new features that we would like to join in on this data would be census data.  There might be good information correlated between education, population, income groups, age groups, employment that could help classifying which retailers are more likely to sell greater volumes of whiskey.  Because there is so many different types of liquor (over 130 category names), we created a new feature, liquor_category that generalizes the liquor.  This way we can look at whiskey in a general sense against the other liquors.  Also, a new feature that could be created from existing data would be the day of the week from the sale date.  Would use the day of the week to look at sales from a weekday perspective (Monday, Tues...Sat, Sun) perspective.  This way we can aggregate the sales by day of week to help on logistics and prevent stock outs.  Below is the list of new features called out: \n","* Day of the week  \n","* Education  \n","* Median population  \n","* Income groups  \n","* Age groups  \n","* Employment  \n","* Grouping of Liquor Brands  \n","\n","We also created a series of columns which were aggregates of other columns.  These new features were added to provide more insight into the sales data to give better view of the profatability, and the market size of whiskey so we can better analyze and predict within the dataset\n","\n","* Cost Per Liter\n","  * cost_per_liter = sale_dollars / volume_sold_liters\n","  * This helps normalize the costing structure of each of the liquor and have a standard view on pricing.  Since the sale_dollars is based on the number of bottles sold * retail price, we weren't able to compare the cost of liquor effectively\n","* Total Cost\n","  * totalcost = state_bottle_cost * bottles_sold\n","  * Provides total cost of the whiskey and will be used in determining our operating margin\n","* Revenue \n","  * revenue = state_bottle_cost * bottles_sold\n","  * Need to see how much revenue is being generated.  Basic metric used in running any business\n","* Gross Margin\n","  * grossmargin = (revenue - totalcost)/revenue\n","  * Need to see how profitable we are doing in whiskey sales\n","* Log Transform of Sales\n","  * The sale_dollars is heavily right skewed, so performing a log transformation on the data helps normalize the data.\n","* Log Transform of Volume Sold\n","  * The volume_sold_liters is heavily right skewed, performed a log transform on this data as well to normalize the data.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HZxUFND0jDwD"},"source":["## Exceptional Work \n","Work that we would like to be evaluated as exceptional work would be what we did around the areas of:\n"," * Tableau location analysis\n"," * Ascertain subset data from Google's BigQuery\n"," * One hot encoding done on the data \n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wfTlL-Kgtb5M"},"source":["### Tableau Location Analysis\n","We built a tableau dashboard out of the 2019 iowa dataset with interative maps of where the most volume of alcohol was sold as well as the a time series analysis of sales and volume by date over 2019. The map features a caption with the analysis of the visuals.\n","\n","https://public.tableau.com/profile/daniel.clark1522#!/vizhome/WhiskeySaleStory/Story1?publish=yes"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"w6Qf4JChtb5M","colab":{}},"source":["### Remove highly correlated features"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-sRVYJlX5EfZ","colab":{}},"source":["df_corr = df.copy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CU3cnnJP5Efl","colab":{}},"source":["df_corr.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"00iACfhI5Efm","colab":{}},"source":["\n","# Create correlation matrix\n","corr_matrix = df_corr.corr().abs()\n","corr_matrix"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0D6IH9iU5Efo","colab":{}},"source":["upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n","\n","# Select upper triangle of correlation matrix\n","upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n","\n","# Find index of feature columns with correlation greater than 0.95\n","to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n","\n","# courtesy of https://chrisalbon.com/machine_learning/feature_selection/drop_highly_correlated_features/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ekMnenpX5Efs","colab":{}},"source":["to_drop"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"euFQv5HU5Efv"},"source":["Looking at our correlation matrix, we can deem that per our criteria of removing features that have a greater than 95% correlation. As the predictability of one feature will detirmine another, which will cause us to want to do a dimensionality reduction. \n","In our case, we are going to remove state_bottle_retail as it correlates highly with state_bottle_cost, as well as volume_sold_gallons as it correlates perfectly with volume_sold_liters."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5_PKuOOr5Efv","colab":{}},"source":["# Drop features \n","df_corr = df_corr.drop(df_corr[to_drop], axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"em7qXL875Ef1"},"source":["PCA\n","To run a PCA analysis, we will want to first remove some of the highly correlated variables which may throw off our analysis. This will mean we should run a correlation plot and set our correlation threshold to 0.95, which we will remove variables if we exceed. \n","\n","First lets take a look at our seaborn plot that we will use to run principal component analysis. To get started, we will want to create dummies for each of our categories of alcohol, so that we have a single binary under Whiskey as the sale was a whiskey drink (1) or it was not (0)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8_XjsXjR5Ef4","colab":{}},"source":["df_corr2 = pd.get_dummies(df['liquor_category'], drop_first=False)\n","\n","df_corr = pd.concat([df_corr, df_corr2], axis = 1, sort=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6_JtFvSq5Ef5","colab":{}},"source":["# now let's use PCA, and LDA to find the two \"best\" dimensions of this data\n","# these are linear transforms to help project the features into something more understandable\n","\n","from sklearn.decomposition import PCA\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n","\n","#drop the response variable from x\n","# one hot encoding to category\n","features = ['pack', 'bottle_volume_ml', 'state_bottle_cost', 'bottles_sold', 'sale_dollars_trans', 'volume_sold_liters']\n","\n","X = df_corr.loc[:, features].values\n","# run this second line below which compiles all the features that i want to use to predict category, or the column we want to predict\n","#X = X.drop (category, inplace = True)\n","y = df_corr.loc[:, ['WHISKY']].values\n","#target_names = df_corr.store_parent_names\n","\n","pca = PCA(n_components=2)\n","X_pca = pca.fit(X).transform(X) # fit data and then transform it\n","\n","lda = LDA(n_components=2)\n","X_lda = lda.fit(X, y).transform(X) # fit data and then transform it\n","\n","# print the components\n","\n","print ('pca:', pca.components_)\n","print ('lda:', lda.scalings_.T)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Mas915a25Ef7"},"source":["Now what we did here was isolate our categorical variable \"Whiskey\" and fit a pca and LDA model using the continuous variables remaining in the set. Using this, our model will be able to advise on how much we can explain variance using the different principal components. \n","Scaling it in this way allows our model to utilize and compare all variables on the same plane. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PpoY348h5Ef8","colab":{}},"source":["principalDf = pd.DataFrame(data = X_pca\n","             , columns = ['principal component 1', 'principal component 2'])\n","\n","principalDf.describe()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WMSsyY8N5Ef-"},"source":["creating a dataframe of our principal components, we can see that there is quite a range in the values we have, from the negatives to the positives, with also a strong standard deviation. \n","The mean principal component is nearly off the scale due to the effect of outliers. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KGoVUc4E5Ef-","colab":{}},"source":["finalDf = pd.concat([principalDf, df_corr[['WHISKY']]], axis = 1)\n","\n","finalDf.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WkYsmLNM5EgA","scrolled":true,"colab":{}},"source":["fig = plt.figure(figsize = (10,10))\n","ax = fig.add_subplot(1,1,1) \n","ax.set_xlabel('Principal Component 1', fontsize = 15)\n","ax.set_ylabel('Principal Component 2', fontsize = 15)\n","ax.set_title('2 component PCA', fontsize = 20)\n","targets = ['Whiskey', 'Not Whiskey']\n","colors = ['r', 'g', 'b']\n","for target, color in zip(targets,colors):\n","    indicesToKeep = finalDf['WHISKY'] == 0\n","    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n","               , finalDf.loc[indicesToKeep, 'principal component 2']\n","               , c = color\n","               , s = 40)\n","ax.legend(targets)\n","ax.grid()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Q5O6IxeL5EgE"},"source":["Looking at the plot we graphed, we can see the effect of outliers and the fact that non/whiskies have quite a presence in our chart. \n","Our explained variance ratio below shows that we can explain 97% of the variance with one principal component, and less than 3% with the second principal component."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8OytcxnA5EgG","colab":{}},"source":["pca.explained_variance_ratio_"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lk9VZJYX5EgI","colab":{}},"source":["#lets transform our outliers to make them easier to read. \n","\n","finalDf2 = finalDf\n","\n","finalDf2['principal component 1 trans'] = np.log(finalDf['principal component 1'])\n","finalDf2['principal component 2 trans'] = np.log(finalDf['principal component 2'])\n","\n","finalDf2.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5pxZqVRO5EgL","colab":{}},"source":["fig = plt.figure(figsize = (10,10))\n","ax = fig.add_subplot(1,1,1) \n","ax.set_xlabel('Principal Component 1', fontsize = 15)\n","ax.set_ylabel('Principal Component 2', fontsize = 15)\n","ax.set_title('2 component PCA', fontsize = 20)\n","targets = ['Whiskey', 'Not Whiskey']\n","colors = ['r', 'g', 'b']\n","for target, color in zip(targets,colors):\n","    indicesToKeep = finalDf2['WHISKY'] == 1\n","    ax.scatter(finalDf2.loc[indicesToKeep, 'principal component 1 trans']\n","               , finalDf2.loc[indicesToKeep, 'principal component 2 trans']\n","               , c = color\n","               , s = 40)\n","ax.legend(targets)\n","ax.grid()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9AZhzuhe5EgQ"},"source":["To make our chart easier to read, i decided to take a transform of our principal components to normalize their distribution. As you can see, their values separate a lot more in our dataset. However, the non whiskey values play a small presence."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6ZSaWnyJrmFn"},"source":["### Ascertain Data from BigQuery\n","\n","Registered for credentials with Google Cloud and Big Query to be able to query our database and data frame from 17 million datapoints for analysis on our project. \n","\n","In our Visualize Attributes section, we went into a deep dive on the analysis of whiskey as well as Hy-Vee to understand their effect on the dataset.\n","\n","Because the dataset is so large, 17.7 million rows and over 4GB in size, we couldn't pull the entire dataset from BigQuery into Pandas.  \n","\n","So, initial analysis of the entire dataset was done by querying BigQuery\n","\n","First needed to connect to BigQuery, then do a some EDA against the data set by querying BigQuery and visualize those results to determine a good subset of the data."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ryNSlAW1jDqj","colab":{}},"source":["import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore', DeprecationWarning)\n","%matplotlib inline\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","project_id = 'smu-7331-ml'\n","\n","plt.rc('axes', axisbelow=True)\n","\n","# Imports the Google Cloud client library\n","#from google.cloud import bigquery\n","# Instantiates a client for BigQuery Service\n","#bqclient = bigquery.Client()\n","\n","from google.colab import auth\n","auth.authenticate_user()\n","print('Authenticated')\n","\n","from google.cloud import bigquery\n","bqclient = bigquery.Client(project=project_id)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eezSJdUbX8md"},"source":["#### Functions"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XXPZZ0DfYDr6"},"source":["##### Execute Query"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"C5HarRC4YFom","colab":{}},"source":["def execute_query(QUERY):\n","    # Run the query and get data from BQ\n","    query_job = bqclient.query(QUERY)\n","    return query_job.to_dataframe()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kE6hFp51YNVj"},"source":["#### Exploratory Data Analysis"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2tjdVPbEYX4S"},"source":["##### Total data size and column types"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DFKt5Fm3YPsd","colab":{}},"source":["QUERY=\"\"\"\n","    SELECT\n","        count(*) as TotalRows\n","    FROM `bigquery-public-data.iowa_liquor_sales.sales`\n","\"\"\"\n","df=execute_query(QUERY)\n","df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0k8IaWC_Ygqt"},"source":["##### Get Columns and Data Types for Columns"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"il3uqQJDYlBi","colab":{}},"source":["QUERY=\"\"\"\n","    SELECT\n","        *\n","    FROM `bigquery-public-data.iowa_liquor_sales.sales`\n","    LIMIT 10\n","\"\"\"\n","df=execute_query(QUERY)\n","df.info()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5I8uQvziYoTK","colab":{}},"source":["pd.set_option('display.max_columns', None)\n","df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wO7-cZAMYxhj"},"source":["##### Look at distribution of data for each Year-Month"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bWerueFLY2XQ","colab":{}},"source":["# How many rows of data for each month for each year \n","QUERY=\"\"\"\n","SELECT\n","    extract(YEAR from date) as year,\n","    extract(MONTH from date) as month,\n","    count(*) as count\n","FROM `bigquery-public-data.iowa_liquor_sales.sales`\n","group by year, month\n","order by year, month\n","\"\"\"\n","df = execute_query(QUERY)\n","\n","# Plot the results\n","df['period'] = df['year'].map(str) +'-' +df['month'].map(str)\n","#df.groupby(['year', 'month'])['count'].sum().plot(kind='bar', figsize=(20, 8))\n","plot=df.plot(kind='bar', x='period', y='count', figsize=(20,8))\n","#xtick = pd.date_range( start=ts.index.min( ), end=ts.index.max( ), freq='W' )\n","#plot.set_xticks( xtick, minor=True )\n","#plot.grid('off', which='minor', axis='y' )\n","plot.grid('on', axis='y', linestyle='dashed')\n","plt.yticks(np.arange(0, max(df['count']+10000), 20000))\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qfg7V5mPZBsu"},"source":["##### Determine the different liquor categories"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ObnMcGEWY9yA","colab":{}},"source":["# How many rows of data for each month for each year \n","QUERY=\"\"\"\n","SELECT\n","    category_name,\n","    count(*) as count\n","FROM `bigquery-public-data.iowa_liquor_sales.sales`\n","group by category_name\n","order by category_name\n","\"\"\"\n","df = execute_query(QUERY)\n","df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VnWQgT1AZNMe"},"source":["##### Group vodka, rum, whiskey, tequila as separate categories, and everything else as other"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hpstJn3HZHsH","colab":{}},"source":["QUERY=\"\"\"\n","SELECT\n","CASE\n","  WHEN lower(category_name) like '%rum%' then 'Rum'\n","  WHEN lower(category_name) like '%whisk%' then 'Whiskey'\n","  WHEN lower(category_name) like '%vodka%' then 'Vodka'\n","  WHEN lower(category_name) like '%tequila%' then 'Tequila'\n","  WHEN lower(category_name) like '%schnapps%' then 'Schnapps'\n","  WHEN lower(category_name) like '%gin%' then 'Gin'\n","  WHEN lower(category_name) like '%bourbon%' then 'Bourbon'\n","  WHEN lower(category_name) like '%brandies%' then 'Brandies'\n","  WHEN lower(category_name) like '%liqueur%' then 'Liqueur'\n","  WHEN lower(category_name) like '%scotch%' then 'Scotch'\n","  ELSE 'Other'\n","END\n","as CategoryName,\n","extract(Year from date) as Year,\n","extract(month from date) as Month,\n","count(*) as Count\n","FROM\n","  `bigquery-public-data.iowa_liquor_sales.sales`\n","group by year, month, categoryname\n","order by year, month, CategoryName\n","\"\"\"\n","df = execute_query(QUERY)\n","catYear=df.groupby(['CategoryName', 'Year'])['Count'].sum().unstack().plot(kind='bar', stacked=True, figsize=(14,7))\n","catYear.grid('on', axis='y', linestyle='dashed')\n","plt.yticks(np.arange(0, 6000000, 500000))\n","plt.gca().legend(loc='center left', bbox_to_anchor=(1, 0.5))\n","plt.xticks(rotation=45, horizontalalignment='right')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SUKe_jV8ZSde","colab":{}},"source":["yearCat=df.groupby(['Year', 'CategoryName'])['Count'].sum().unstack().plot(kind='bar', stacked=True, figsize=(14,7))\n","yearCat.grid('on', axis='y', linestyle='dashed')\n","plt.yticks(np.arange(0, 3000000, 500000))\n","plt.gca().legend(loc='center left', bbox_to_anchor=(1, 0.5))\n","plt.xticks(rotation=45, horizontalalignment='right')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oi7ieVxOZdeq"},"source":["#### Subset the data\n","\n","Based on the results above, we decided to go with 400,000 random rows from 2019.\n","\n","Our challenge was with github only allowing a file smaller than 100mb.  So we found that 400k rows came in at 95mb.\n","\n","Because there wasn't a particular sort column, we simply extracted 400k rows from BigQuery by executing the following query:\n","\n","\n","```\n","SELECT\n","  *\n","FROM `bigquery-public-data.iowa_liquor_sales.sales`\n","WHERE\n","date between \"2019-01-01\" and \"2019-12-31\" limit 400000;\n","```\n","\n","Once executed, we were able to save the results (400,000 rows) to a csv, and that is what we are using for our data set\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HIUQqHgrtb6g"},"source":["### One Hot Encoding\n","To be able to put our dataset into a manner that allows us to analyze further, we ran a one hot encoding procedure that isolated the categorical variables and one-hotted the ones that exceeded 30 uniques. This was done in our data cleaning stage earlier in this doc."]}]}